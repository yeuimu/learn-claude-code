#!/usr/bin/env python3
"""
v6_tasks_agent.py - Mini Claude Code: Tasks System (~920 lines)

Core Philosophy: "A Shared Board Every Agent Can See and Update"
================================================================
v5 showed that compression is necessary for long sessions. But compression
wipes in-memory state like TodoWrite's data. More importantly, when agents
go from single to group, task management must evolve from "list" to "system".

Tasks is a complete rethink:
- CRUD operations (not overwrite-only)
- File-based persistence (survives compression and process boundaries)
- Dependency graph (blocks / blockedBy)
- Owner tracking (who's doing what)
- Thread-safe (file locks for concurrent access)

    TASK STATE MACHINE
    ==================

    +----------+   update(status)   +--------------+   update(status)   +-----------+
    | pending  | ----------------> | in_progress  | ----------------> | completed |
    +----------+                    +--------------+                    +-----------+
         |                               |
         |  update(status="deleted")     |  update(status="deleted")
         v                               v
    +-----------+                   +-----------+
    | deleted   |                   | deleted   |
    +-----------+                   +-----------+

    DEPENDENCY GRAPH
    ================

    Task A (blocks: [B])           Task B (blocked_by: [A])
    +-----------+                  +-----------+
    | A: build  |  -- blocks -->   | B: deploy |
    | status:   |                  | status:   |
    | progress  |                  | pending   | (cannot start)
    +-----------+                  +-----------+
         |
         | A completes -> auto-remove A from B.blocked_by
         v
    +-----------+                  +-----------+
    | A: build  |                  | B: deploy |
    | completed |                  | pending   | (can now start)
    +-----------+                  +-----------+

TodoWrite vs Tasks:
    TodoWrite: Model's self-discipline tool (v2: constraints enable)
    Tasks:     Multi-agent coordination protocol (v6: collaboration enables)

Usage:
    python v6_tasks_agent.py
"""

import json
import os
import re
import subprocess
import sys
import time
import threading
from dataclasses import dataclass, field, asdict
from pathlib import Path

from anthropic import Anthropic
from dotenv import load_dotenv

load_dotenv(override=True)


# =============================================================================
# Configuration
# =============================================================================

# When using third-party endpoints (e.g. GLM), clear ANTHROPIC_AUTH_TOKEN
# to prevent the SDK from sending a conflicting authorization header.
if os.getenv("ANTHROPIC_BASE_URL"):
    os.environ.pop("ANTHROPIC_AUTH_TOKEN", None)

WORKDIR = Path.cwd()
SKILLS_DIR = WORKDIR / "skills"
TRANSCRIPT_DIR = WORKDIR / ".transcripts"
TASKS_DIR = WORKDIR / ".tasks"
TASKS_ENABLED = True

client = Anthropic(base_url=os.getenv("ANTHROPIC_BASE_URL"))
MODEL = os.getenv("MODEL_ID", "claude-sonnet-4-5-20250929")


# =============================================================================
# TaskManager - The core addition in v6
# =============================================================================

HIGHWATERMARK_FILE = ".highwatermark"


def _resolve_task_list_id() -> str:
    """Resolution order: CLAUDE_CODE_TASK_LIST_ID env > team_name > session fallback."""
    return (os.environ.get("CLAUDE_CODE_TASK_LIST_ID")
            or os.environ.get("CLAUDE_TEAM_NAME")
            or "default")


@dataclass
class Task:
    id: str
    subject: str
    description: str
    status: str = "pending"
    active_form: str = ""
    owner: str = ""
    blocks: list = field(default_factory=list)
    blocked_by: list = field(default_factory=list)
    metadata: dict = field(default_factory=dict)


class TaskManager:
    """
    File-based task management with dependency tracking.

    Each task is a JSON file in .tasks/ directory. File-level locking
    ensures concurrent safety when multiple agents access the same tasks.

    Why files instead of database?
    - One file per task = fine-grained locking
    - Subagents may be in different processes
    - JSON files are human-readable for debugging
    """

    def __init__(self, tasks_dir: Path = None):
        list_id = _resolve_task_list_id()
        base_dir = tasks_dir or TASKS_DIR
        self.tasks_dir = base_dir / list_id if list_id != "default" else base_dir
        self.tasks_dir.mkdir(parents=True, exist_ok=True)
        self._lock = threading.Lock()
        self._counter = self._load_counter()

    def _load_counter(self) -> int:
        """Load next task ID from highwatermark file, falling back to file scan."""
        hwm_path = self.tasks_dir / HIGHWATERMARK_FILE
        if hwm_path.exists():
            try:
                return int(hwm_path.read_text().strip()) + 1
            except ValueError:
                pass
        existing = list(self.tasks_dir.glob("task_*.json"))
        if not existing:
            return 1
        ids = []
        for f in existing:
            try:
                ids.append(int(f.stem.split("_")[1]))
            except (ValueError, IndexError):
                pass
        return max(ids) + 1 if ids else 1

    def _next_task_id(self) -> int:
        """Get next task ID and persist highwatermark."""
        task_id = self._counter
        self._counter += 1
        hwm_path = self.tasks_dir / HIGHWATERMARK_FILE
        hwm_path.write_text(str(task_id))
        return task_id

    def _task_path(self, task_id: str) -> Path:
        return self.tasks_dir / f"task_{task_id}.json"

    def _save_task(self, task: Task):
        data = asdict(task)
        self._task_path(task.id).write_text(json.dumps(data, indent=2))

    def _load_task(self, task_id: str) -> Task:
        path = self._task_path(task_id)
        if not path.exists():
            return None
        data = json.loads(path.read_text())
        return Task(**data)

    def create(self, subject: str, description: str = "", active_form: str = "", metadata: dict = None) -> Task:
        """Create a new task with auto-incrementing ID."""
        with self._lock:
            task_id = self._next_task_id()
            task = Task(
                id=str(task_id),
                subject=subject,
                description=description,
                active_form=active_form or f"Working on: {subject}",
                metadata=metadata or {},
            )
            self._save_task(task)
            return task

    def get(self, task_id: str) -> Task:
        """Get task by ID."""
        return self._load_task(task_id)

    def update(self, task_id: str, **kwargs) -> Task:
        """
        Update task fields.

        Supports: status, subject, description, active_form, owner, metadata,
                  addBlocks, addBlockedBy
        """
        with self._lock:
            task = self._load_task(task_id)
            if not task:
                return None

            for key in ("status", "subject", "description", "active_form", "owner"):
                if key in kwargs:
                    setattr(task, key, kwargs[key])

            if "metadata" in kwargs and isinstance(kwargs["metadata"], dict):
                task.metadata.update(kwargs["metadata"])

            # Auto-set owner when transitioning to in_progress without one
            if kwargs.get("status") == "in_progress" and not task.owner:
                task.owner = kwargs.get("owner", os.getenv("CLAUDE_AGENT_NAME", "agent"))

            if "addBlocks" in kwargs:
                for blocked_id in kwargs["addBlocks"]:
                    if blocked_id not in task.blocks:
                        task.blocks.append(blocked_id)
                    blocked_task = self._load_task(blocked_id)
                    if blocked_task and task.id not in blocked_task.blocked_by:
                        blocked_task.blocked_by.append(task.id)
                        self._save_task(blocked_task)

            if "addBlockedBy" in kwargs:
                for blocker_id in kwargs["addBlockedBy"]:
                    if blocker_id not in task.blocked_by:
                        task.blocked_by.append(blocker_id)
                    blocker_task = self._load_task(blocker_id)
                    if blocker_task and task.id not in blocker_task.blocks:
                        blocker_task.blocks.append(task.id)
                        self._save_task(blocker_task)

            # When a task completes, clear it from others' blocked_by
            if kwargs.get("status") == "completed":
                self._clear_dependency(task.id)

            self._save_task(task)
            return task

    def _clear_dependency(self, completed_id: str):
        """When a task completes, remove it from all blocked_by lists."""
        for path in self.tasks_dir.glob("task_*.json"):
            try:
                data = json.loads(path.read_text())
                if completed_id in data.get("blocked_by", []):
                    data["blocked_by"].remove(completed_id)
                    path.write_text(json.dumps(data, indent=2))
            except (json.JSONDecodeError, KeyError):
                pass

    def list_all(self) -> list:
        """List all tasks with summary info."""
        tasks = []
        for path in sorted(self.tasks_dir.glob("task_*.json")):
            try:
                data = json.loads(path.read_text())
                tasks.append(Task(**data))
            except (json.JSONDecodeError, KeyError):
                pass
        return tasks

    def delete(self, task_id: str) -> bool:
        """Delete a task."""
        path = self._task_path(task_id)
        if path.exists():
            path.unlink()
            return True
        return False


TASK_MGR = TaskManager()


# =============================================================================
# ContextManager (from v5)
# =============================================================================

def auto_compact_threshold(context_window: int = 200000, max_output: int = 16384) -> int:
    """Dynamic threshold: context_window - min(max_output, 20000) - 13000.
    For a 200K window with 16K output: 200000 - 16384 - 13000 = 170616."""
    output_reserve = min(max_output, 20000)
    return context_window - output_reserve - 13000


MIN_SAVINGS = 20000
MAX_RESTORE_FILES = 5
MAX_RESTORE_TOKENS_PER_FILE = 5000
MAX_RESTORE_TOKENS_TOTAL = 50000
IMAGE_TOKEN_ESTIMATE = 2000


class ContextManager:
    """
    Three-layer context compression to keep conversations within window limits.

    Human working memory is limited too - we don't remember every line of code
    we wrote, just "what we did, why, and current state". Compression mimics
    this cognitive pattern:
    - Micro-compact = short-term memory auto-decay
    - Auto-compact  = detail memory -> concept memory
    - Disk transcript = long-term memory archive
    """

    COMPACTABLE_TOOLS = {"bash", "read_file", "write_file", "edit_file"}
    KEEP_RECENT = 3
    TOKEN_THRESHOLD = auto_compact_threshold()
    MAX_OUTPUT_TOKENS = 40000

    def __init__(self, max_context_tokens: int = 200000):
        self.max_context_tokens = max_context_tokens
        TRANSCRIPT_DIR.mkdir(exist_ok=True)

    @staticmethod
    def estimate_tokens(text: str) -> int:
        # cli.js H2: Math.round(A.length / q) with default divisor q=4
        return len(text) // 4

    def microcompact(self, messages: list) -> list:
        """
        Layer 1: Replace old large tool outputs with placeholders.

        Keeps the tool call structure intact - the model still knows WHAT
        it called, just can't see the old output. It can re-read if needed.
        """
        tool_result_indices = []

        for i, msg in enumerate(messages):
            if msg.get("role") != "user":
                continue
            content = msg.get("content")
            if not isinstance(content, list):
                continue
            for j, block in enumerate(content):
                if isinstance(block, dict) and block.get("type") == "tool_result":
                    tool_name = self._find_tool_name(messages, block.get("tool_use_id", ""))
                    if tool_name in self.COMPACTABLE_TOOLS:
                        tool_result_indices.append((i, j, block))

        # Keep only the most recent KEEP_RECENT, compact the rest
        to_compact = tool_result_indices[:-self.KEEP_RECENT] if len(tool_result_indices) > self.KEEP_RECENT else []

        for i, j, block in to_compact:
            content_str = block.get("content", "")
            if isinstance(content_str, str) and self.estimate_tokens(content_str) > 1000:
                block["content"] = "[Output compacted - re-read if needed]"

        return messages

    def should_compact(self, messages: list) -> bool:
        """Check if context is approaching the window limit.
        Skips compaction if estimated savings are below MIN_SAVINGS."""
        total = sum(self.estimate_tokens(json.dumps(m, default=str)) for m in messages)
        if total <= self.TOKEN_THRESHOLD:
            return False
        # Only compact if we'd save meaningful tokens (recent 5 messages kept)
        recent_size = sum(
            self.estimate_tokens(json.dumps(m, default=str))
            for m in messages[-5:]
        ) if len(messages) > 5 else total
        savings = total - recent_size
        return savings >= MIN_SAVINGS

    def auto_compact(self, messages: list) -> list:
        """
        Layer 2: Summarize entire conversation, preserving recent context.

        1. Save full transcript to disk (never lose data)
        2. Call model to generate chronological summary
        3. Replace old messages with summary, keep recent 5
        4. Restore recently-read files within token limits
        """
        self.save_transcript(messages)

        # Capture file access history before compaction
        restored_files = self.restore_recent_files(messages)

        conversation_text = self._messages_to_text(messages)

        summary_response = client.messages.create(
            model=MODEL,
            system="You are a conversation summarizer. Be concise but thorough.",
            messages=[{
                "role": "user",
                "content": f"Summarize this conversation chronologically. Include: goals, actions taken, decisions made, current state, and pending work.\n\n{conversation_text[:100000]}"
            }],
            max_tokens=2000,
        )

        summary = summary_response.content[0].text

        # Inject summary as user message (preserves system prompt cache)
        recent = messages[-5:] if len(messages) > 5 else messages[-2:]
        result = [
            {"role": "user", "content": f"[Conversation compressed]\n\n{summary}"},
            {"role": "assistant", "content": "Understood. I have the context from the compressed conversation. Continuing work."},
        ]
        # Interleave restored files as user/assistant pairs to maintain valid turn order
        for rf in restored_files:
            result.append(rf)
            result.append({"role": "assistant", "content": "Noted, file content restored."})
        result.extend(recent)
        return result

    def handle_large_output(self, output: str) -> str:
        """
        Handle oversized tool output: save to disk, return preview.
        """
        if self.estimate_tokens(output) <= self.MAX_OUTPUT_TOKENS:
            return output

        filename = f"output_{int(time.time())}.txt"
        path = TRANSCRIPT_DIR / filename
        path.write_text(output)

        preview = output[:2000]
        return f"Output too large ({self.estimate_tokens(output)} tokens). Saved to: {path}\n\nPreview:\n{preview}..."

    def save_transcript(self, messages: list):
        """Append full transcript to disk. The permanent archive."""
        path = TRANSCRIPT_DIR / "transcript.jsonl"
        with open(path, "a") as f:
            for msg in messages:
                f.write(json.dumps(msg, default=str) + "\n")

    def restore_recent_files(self, messages: list) -> list:
        """After auto-compact, re-inject recently-read files into context.
        Scans conversation history for read_file calls and returns restoration
        messages for the most recently accessed files within token limits."""
        file_cache = {}
        for msg in messages:
            if msg.get("role") != "assistant":
                continue
            content = msg.get("content", [])
            if not isinstance(content, list):
                continue
            for block in content:
                if isinstance(block, dict) and block.get("name") == "read_file":
                    path = block.get("input", {}).get("path", "")
                    if path:
                        file_cache[path] = len(file_cache)
                elif hasattr(block, "name") and block.name == "read_file":
                    path = getattr(block, "input", {}).get("path", "")
                    if path:
                        file_cache[path] = len(file_cache)

        restored = []
        total_tokens = 0
        # Sort by access order (most recent last -> reverse for most recent first)
        sorted_paths = sorted(file_cache.keys(), key=lambda p: file_cache[p], reverse=True)
        for path in sorted_paths[:MAX_RESTORE_FILES]:
            try:
                full_path = (WORKDIR / path).resolve()
                if not full_path.is_relative_to(WORKDIR) or not full_path.exists():
                    continue
                content = full_path.read_text()
                tokens = self.estimate_tokens(content)
                if tokens > MAX_RESTORE_TOKENS_PER_FILE:
                    continue
                if total_tokens + tokens > MAX_RESTORE_TOKENS_TOTAL:
                    break
                restored.append({
                    "role": "user",
                    "content": f"[Restored after compact] {path}:\n{content}"
                })
                total_tokens += tokens
            except (OSError, ValueError):
                continue
        return restored

    def _find_tool_name(self, messages: list, tool_use_id: str) -> str:
        """Find tool name from a tool_use_id in message history."""
        for msg in messages:
            if msg.get("role") != "assistant":
                continue
            content = msg.get("content", [])
            if isinstance(content, list):
                for block in content:
                    if hasattr(block, "id") and block.id == tool_use_id:
                        return block.name
                    if isinstance(block, dict) and block.get("id") == tool_use_id:
                        return block.get("name", "")
        return ""

    def _messages_to_text(self, messages: list) -> str:
        """Convert messages to plain text for summarization."""
        lines = []
        for msg in messages:
            role = msg.get("role", "?")
            content = msg.get("content", "")
            if isinstance(content, str):
                lines.append(f"[{role}] {content[:500]}")
            elif isinstance(content, list):
                for block in content:
                    if isinstance(block, dict):
                        if block.get("type") == "tool_result":
                            text = str(block.get("content", ""))[:200]
                            lines.append(f"[tool_result] {text}")
                        elif block.get("type") == "text":
                            lines.append(f"[{role}] {block.get('text', '')[:500]}")
                    elif hasattr(block, "text"):
                        lines.append(f"[{role}] {block.text[:500]}")
        return "\n".join(lines)


CTX = ContextManager()


# =============================================================================
# SkillLoader (from v4)
# =============================================================================

class SkillLoader:
    """Loads and manages skills from SKILL.md files."""

    def __init__(self, skills_dir: Path):
        self.skills_dir = skills_dir
        self.skills = {}
        self.load_skills()

    def parse_skill_md(self, path: Path) -> dict:
        content = path.read_text()
        match = re.match(r"^---\s*\n(.*?)\n---\s*\n(.*)$", content, re.DOTALL)
        if not match:
            return None
        frontmatter, body = match.groups()
        metadata = {}
        for line in frontmatter.strip().split("\n"):
            if ":" in line:
                key, value = line.split(":", 1)
                metadata[key.strip()] = value.strip().strip("\"'")
        if "name" not in metadata or "description" not in metadata:
            return None
        return {"name": metadata["name"], "description": metadata["description"], "body": body.strip(), "path": path, "dir": path.parent}

    def load_skills(self):
        if not self.skills_dir.exists():
            return
        for skill_dir in self.skills_dir.iterdir():
            if not skill_dir.is_dir():
                continue
            skill_md = skill_dir / "SKILL.md"
            if not skill_md.exists():
                continue
            skill = self.parse_skill_md(skill_md)
            if skill:
                self.skills[skill["name"]] = skill

    def get_descriptions(self) -> str:
        if not self.skills:
            return "(no skills available)"
        return "\n".join(f"- {name}: {skill['description']}" for name, skill in self.skills.items())

    def get_skill_content(self, name: str) -> str:
        if name not in self.skills:
            return None
        skill = self.skills[name]
        content = f"# Skill: {skill['name']}\n\n{skill['body']}"
        resources = []
        for folder, label in [("scripts", "Scripts"), ("references", "References"), ("assets", "Assets")]:
            folder_path = skill["dir"] / folder
            if folder_path.exists():
                files = list(folder_path.glob("*"))
                if files:
                    resources.append(f"{label}: {', '.join(f.name for f in files)}")
        if resources:
            content += f"\n\n**Available resources in {skill['dir']}:**\n" + "\n".join(f"- {r}" for r in resources)
        return content

    def list_skills(self) -> list:
        return list(self.skills.keys())


SKILLS = SkillLoader(SKILLS_DIR)


# =============================================================================
# Agent Type Registry (from v3)
# =============================================================================

AGENT_TYPES = {
    "explore": {
        "description": "Read-only agent for exploring code, finding files, searching",
        "tools": ["bash", "read_file"],
        "prompt": "You are an exploration agent. Search and analyze, but never modify files. Return a concise summary.",
    },
    "code": {
        "description": "Full agent for implementing features and fixing bugs",
        "tools": "*",
        "prompt": "You are a coding agent. Implement the requested changes efficiently.",
    },
    "plan": {
        "description": "Planning agent for designing implementation strategies",
        "tools": ["bash", "read_file"],
        "prompt": "You are a planning agent. Analyze the codebase and output a numbered implementation plan. Do NOT make changes.",
    },
}


def get_agent_descriptions() -> str:
    return "\n".join(f"- {name}: {cfg['description']}" for name, cfg in AGENT_TYPES.items())


# =============================================================================
# TodoManager (from v2) - Only used when TASKS_ENABLED=False
# =============================================================================

class TodoManager:
    """Task list manager with constraints (max 20 items, single in_progress)."""

    def __init__(self):
        self.items = []

    def update(self, items: list) -> str:
        validated = []
        in_progress = 0
        for i, item in enumerate(items):
            content = str(item.get("content", "")).strip()
            status = str(item.get("status", "pending")).lower()
            active = str(item.get("activeForm", "")).strip()
            if not content or not active:
                raise ValueError(f"Item {i}: content and activeForm required")
            if status not in ("pending", "in_progress", "completed"):
                raise ValueError(f"Item {i}: invalid status")
            if status == "in_progress":
                in_progress += 1
            validated.append({"content": content, "status": status, "activeForm": active})
        if in_progress > 1:
            raise ValueError("Only one task can be in_progress")
        self.items = validated[:20]
        return self.render()

    def render(self) -> str:
        if not self.items:
            return "No todos."
        lines = []
        for t in self.items:
            mark = "[x]" if t["status"] == "completed" else "[>]" if t["status"] == "in_progress" else "[ ]"
            lines.append(f"{mark} {t['content']}")
        done = sum(1 for t in self.items if t["status"] == "completed")
        return "\n".join(lines) + f"\n({done}/{len(self.items)} done)"


TODO = TodoManager()


# =============================================================================
# System Prompt
# =============================================================================

SYSTEM = f"""You are a coding agent at {WORKDIR}.

Loop: plan -> act with tools -> report.

**Skills available** (invoke with Skill tool when task matches):
{SKILLS.get_descriptions()}

**Subagents available** (invoke with Task tool for focused subtasks):
{get_agent_descriptions()}

Rules:
- Use Skill tool IMMEDIATELY when a task matches a skill description
- Use Task tool for subtasks needing focused exploration or implementation
- Use TaskCreate/TaskUpdate to track multi-step work (preferred over TodoWrite)
- Prefer tools over prose. Act, don't just explain.
- After finishing, summarize what changed."""


# =============================================================================
# Tool Definitions
# =============================================================================

BASE_TOOLS = [
    {"name": "bash", "description": "Run shell command.",
     "input_schema": {"type": "object", "properties": {"command": {"type": "string"}}, "required": ["command"]}},
    {"name": "read_file", "description": "Read file contents.",
     "input_schema": {"type": "object", "properties": {"path": {"type": "string"}, "limit": {"type": "integer"}}, "required": ["path"]}},
    {"name": "write_file", "description": "Write to file.",
     "input_schema": {"type": "object", "properties": {"path": {"type": "string"}, "content": {"type": "string"}}, "required": ["path", "content"]}},
    {"name": "edit_file", "description": "Replace text in file.",
     "input_schema": {"type": "object", "properties": {"path": {"type": "string"}, "old_text": {"type": "string"}, "new_text": {"type": "string"}}, "required": ["path", "old_text", "new_text"]}},
]

# Feature gate: TodoWrite only when Tasks not enabled
TODO_TOOL = {
    "name": "TodoWrite", "description": "Update task list (legacy, prefer TaskCreate/TaskUpdate).",
    "input_schema": {
        "type": "object",
        "properties": {"items": {"type": "array", "items": {"type": "object", "properties": {"content": {"type": "string"}, "status": {"type": "string", "enum": ["pending", "in_progress", "completed"]}, "activeForm": {"type": "string"}}, "required": ["content", "status", "activeForm"]}}},
        "required": ["items"],
    },
}

SUBAGENT_TOOL = {
    "name": "Task",
    "description": f"Spawn a subagent for a focused subtask.\n\nAgent types:\n{get_agent_descriptions()}",
    "input_schema": {
        "type": "object",
        "properties": {
            "description": {"type": "string", "description": "Short task description (3-5 words)"},
            "prompt": {"type": "string", "description": "Detailed instructions for the subagent"},
            "agent_type": {"type": "string", "enum": list(AGENT_TYPES.keys())},
        },
        "required": ["description", "prompt", "agent_type"],
    },
}

SKILL_TOOL = {
    "name": "Skill",
    "description": f"Load a skill to gain specialized knowledge.\n\nAvailable skills:\n{SKILLS.get_descriptions()}",
    "input_schema": {"type": "object", "properties": {"skill": {"type": "string"}}, "required": ["skill"]},
}

# v6: Tasks CRUD tools
TASK_CREATE_TOOL = {
    "name": "TaskCreate",
    "description": "Create a new task to track work.",
    "input_schema": {
        "type": "object",
        "properties": {
            "subject": {"type": "string", "description": "Brief imperative title: 'Fix auth bug'"},
            "description": {"type": "string", "description": "Detailed description of what needs to be done"},
            "activeForm": {"type": "string", "description": "Present continuous form: 'Fixing auth bug'"},
            "metadata": {"type": "object", "description": "Arbitrary key-value metadata"},
        },
        "required": ["subject", "description"],
    },
}

TASK_GET_TOOL = {
    "name": "TaskGet",
    "description": "Get task details by ID.",
    "input_schema": {
        "type": "object",
        "properties": {"taskId": {"type": "string"}},
        "required": ["taskId"],
    },
}

TASK_UPDATE_TOOL = {
    "name": "TaskUpdate",
    "description": "Update a task: status, dependencies, owner.",
    "input_schema": {
        "type": "object",
        "properties": {
            "taskId": {"type": "string"},
            "status": {"type": "string", "enum": ["pending", "in_progress", "completed", "deleted"]},
            "addBlockedBy": {"type": "array", "items": {"type": "string"}, "description": "Task IDs that must complete before this one"},
            "addBlocks": {"type": "array", "items": {"type": "string"}, "description": "Task IDs that this task blocks"},
            "owner": {"type": "string"},
            "metadata": {"type": "object", "description": "Arbitrary key-value metadata to merge into the task"},
        },
        "required": ["taskId"],
    },
}

TASK_LIST_TOOL = {
    "name": "TaskList",
    "description": "List all tasks with status and dependencies.",
    "input_schema": {"type": "object", "properties": {}},
}

# Build ALL_TOOLS based on feature gate
if TASKS_ENABLED:
    ALL_TOOLS = BASE_TOOLS + [SUBAGENT_TOOL, SKILL_TOOL, TASK_CREATE_TOOL, TASK_GET_TOOL, TASK_UPDATE_TOOL, TASK_LIST_TOOL]
else:
    ALL_TOOLS = BASE_TOOLS + [TODO_TOOL, SUBAGENT_TOOL, SKILL_TOOL]


def get_tools_for_agent(agent_type: str) -> list:
    allowed = AGENT_TYPES.get(agent_type, {}).get("tools", "*")
    if allowed == "*":
        return BASE_TOOLS
    return [t for t in BASE_TOOLS if t["name"] in allowed]


# =============================================================================
# Tool Implementations
# =============================================================================

def safe_path(p: str) -> Path:
    path = (WORKDIR / p).resolve()
    if not path.is_relative_to(WORKDIR):
        raise ValueError(f"Path escapes workspace: {p}")
    return path


def run_bash(cmd: str) -> str:
    if any(d in cmd for d in ["rm -rf /", "sudo", "shutdown"]):
        return "Error: Dangerous command"
    try:
        r = subprocess.run(cmd, shell=True, cwd=WORKDIR, capture_output=True, text=True, timeout=60)
        return ((r.stdout + r.stderr).strip() or "(no output)")[:50000]
    except Exception as e:
        return f"Error: {e}"


def run_read(path: str, limit: int = None) -> str:
    try:
        lines = safe_path(path).read_text().splitlines()
        if limit:
            lines = lines[:limit]
        return "\n".join(lines)[:50000]
    except Exception as e:
        return f"Error: {e}"


def run_write(path: str, content: str) -> str:
    try:
        fp = safe_path(path)
        fp.parent.mkdir(parents=True, exist_ok=True)
        fp.write_text(content)
        return f"Wrote {len(content)} bytes to {path}"
    except Exception as e:
        return f"Error: {e}"


def run_edit(path: str, old_text: str, new_text: str) -> str:
    try:
        fp = safe_path(path)
        text = fp.read_text()
        if old_text not in text:
            return f"Error: Text not found in {path}"
        fp.write_text(text.replace(old_text, new_text, 1))
        return f"Edited {path}"
    except Exception as e:
        return f"Error: {e}"


def run_todo(items: list) -> str:
    try:
        return TODO.update(items)
    except Exception as e:
        return f"Error: {e}"


def run_skill(skill_name: str) -> str:
    content = SKILLS.get_skill_content(skill_name)
    if content is None:
        available = ", ".join(SKILLS.list_skills()) or "none"
        return f"Error: Unknown skill '{skill_name}'. Available: {available}"
    return f'<skill-loaded name="{skill_name}">\n{content}\n</skill-loaded>\n\nFollow the instructions in the skill above to complete the user\'s task.'


def run_task_create(subject: str, description: str = "", active_form: str = "", metadata: dict = None) -> str:
    task = TASK_MGR.create(subject, description, active_form, metadata)
    return json.dumps({"id": task.id, "subject": task.subject, "status": task.status})


def run_task_get(task_id: str) -> str:
    task = TASK_MGR.get(task_id)
    if not task:
        return f"Error: Task {task_id} not found"
    return json.dumps(asdict(task), indent=2)


def run_task_update(task_id: str, **kwargs) -> str:
    if kwargs.get("status") == "deleted":
        if TASK_MGR.delete(task_id):
            return f"Task {task_id} deleted"
        return f"Error: Task {task_id} not found"
    task = TASK_MGR.update(task_id, **kwargs)
    if not task:
        return f"Error: Task {task_id} not found"
    return json.dumps({"id": task.id, "status": task.status, "blocked_by": task.blocked_by})


def run_task_list() -> str:
    tasks = TASK_MGR.list_all()
    if not tasks:
        return "No tasks."
    lines = []
    for t in tasks:
        icon = {"completed": "[x]", "in_progress": "[>]"}.get(t.status, "[ ]")
        blocked = f" (blocked by: {', '.join(t.blocked_by)})" if t.blocked_by else ""
        owner = f" @{t.owner}" if t.owner else ""
        lines.append(f"#{t.id}. {icon} {t.subject}{blocked}{owner}")
    return "\n".join(lines)


def run_subagent(description: str, prompt: str, agent_type: str) -> str:
    if agent_type not in AGENT_TYPES:
        return f"Error: Unknown agent type '{agent_type}'"

    config = AGENT_TYPES[agent_type]
    sub_system = f"You are a {agent_type} subagent at {WORKDIR}.\n\n{config['prompt']}\n\nComplete the task and return a clear, concise summary."
    sub_tools = get_tools_for_agent(agent_type)
    sub_messages = [{"role": "user", "content": prompt}]

    print(f"  [{agent_type}] {description}")
    start = time.time()
    tool_count = 0

    while True:
        sub_messages = CTX.microcompact(sub_messages)
        if CTX.should_compact(sub_messages):
            sub_messages = CTX.auto_compact(sub_messages)

        response = client.messages.create(model=MODEL, system=sub_system, messages=sub_messages, tools=sub_tools, max_tokens=8000)
        if response.stop_reason != "tool_use":
            break

        tool_calls = [b for b in response.content if b.type == "tool_use"]
        results = []
        for tc in tool_calls:
            tool_count += 1
            output = execute_tool(tc.name, tc.input)
            output = CTX.handle_large_output(output)
            results.append({"type": "tool_result", "tool_use_id": tc.id, "content": output})
            sys.stdout.write(f"\r  [{agent_type}] {description} ... {tool_count} tools, {time.time()-start:.1f}s")
            sys.stdout.flush()

        sub_messages.append({"role": "assistant", "content": response.content})
        sub_messages.append({"role": "user", "content": results})

    sys.stdout.write(f"\r  [{agent_type}] {description} - done ({tool_count} tools, {time.time()-start:.1f}s)\n")
    for block in response.content:
        if hasattr(block, "text"):
            return block.text
    return "(subagent returned no text)"


def execute_tool(name: str, args: dict) -> str:
    if name == "bash":
        return run_bash(args["command"])
    if name == "read_file":
        return run_read(args["path"], args.get("limit"))
    if name == "write_file":
        return run_write(args["path"], args["content"])
    if name == "edit_file":
        return run_edit(args["path"], args["old_text"], args["new_text"])
    if name == "TodoWrite":
        return run_todo(args["items"])
    if name == "Task":
        return run_subagent(args["description"], args["prompt"], args["agent_type"])
    if name == "Skill":
        return run_skill(args["skill"])
    if name == "TaskCreate":
        return run_task_create(args["subject"], args.get("description", ""), args.get("activeForm", ""), args.get("metadata"))
    if name == "TaskGet":
        return run_task_get(args["taskId"])
    if name == "TaskUpdate":
        kw = {k: v for k, v in args.items() if k != "taskId"}
        return run_task_update(args["taskId"], **kw)
    if name == "TaskList":
        return run_task_list()
    return f"Unknown tool: {name}"


# =============================================================================
# Main Agent Loop
# =============================================================================

INITIAL_REMINDER = """<reminder>
Use TaskCreate/TaskUpdate to plan and track multi-step tasks.
Create tasks first, then work through them systematically.
</reminder>"""

NAG_REMINDER = """<reminder>
You haven't updated tasks recently.
Use TaskCreate to plan work, TaskUpdate to track progress.
</reminder>"""


def agent_loop(messages: list) -> list:
    rounds_without_task_update = 0

    while True:
        messages = CTX.microcompact(messages)
        if CTX.should_compact(messages):
            print("\n[Compressing context...]")
            messages = CTX.auto_compact(messages)
            print("[Context compressed. Continuing...]\n")

        response = client.messages.create(model=MODEL, system=SYSTEM, messages=messages, tools=ALL_TOOLS, max_tokens=8000)

        tool_calls = []
        for block in response.content:
            if hasattr(block, "text"):
                print(block.text)
            if block.type == "tool_use":
                tool_calls.append(block)

        if response.stop_reason != "tool_use":
            messages.append({"role": "assistant", "content": response.content})
            return messages

        results = []
        has_task_op = False
        for tc in tool_calls:
            if tc.name == "Task":
                print(f"\n> Task: {tc.input.get('description', 'subtask')}")
            elif tc.name == "Skill":
                print(f"\n> Loading skill: {tc.input.get('skill', '?')}")
            elif tc.name.startswith("Task"):
                print(f"\n> {tc.name}: {tc.input.get('subject', tc.input.get('taskId', ''))}")
                has_task_op = True
            else:
                print(f"\n> {tc.name}")

            output = execute_tool(tc.name, tc.input)
            output = CTX.handle_large_output(output)

            if tc.name == "Skill":
                print(f"  Skill loaded ({len(output)} chars)")
            elif tc.name != "Task":
                preview = output[:200] + "..." if len(output) > 200 else output
                print(f"  {preview}")

            results.append({"type": "tool_result", "tool_use_id": tc.id, "content": output})

        if has_task_op:
            rounds_without_task_update = 0
        else:
            rounds_without_task_update += 1
            if rounds_without_task_update >= 3 and len(tool_calls) > 0:
                results.insert(0, {"type": "text", "text": NAG_REMINDER})

        messages.append({"role": "assistant", "content": response.content})
        messages.append({"role": "user", "content": results})


# =============================================================================
# Main REPL
# =============================================================================

def main():
    print(f"Mini Claude Code v6 (with Tasks) - {WORKDIR}")
    print(f"Skills: {', '.join(SKILLS.list_skills()) or 'none'}")
    print(f"Tasks: {'enabled' if TASKS_ENABLED else 'disabled (using TodoWrite)'}")
    print("Commands: /compact, /tasks, exit")
    print()

    history = []

    while True:
        try:
            user_input = input("You: ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if not user_input or user_input.lower() in ("exit", "quit", "q"):
            break

        if user_input.strip() == "/compact":
            if history:
                print("[Manual compression...]")
                history = CTX.auto_compact(history)
                print("[Done. Context compressed.]\n")
            else:
                print("[Nothing to compress.]\n")
            continue

        if user_input.strip() == "/tasks":
            print(run_task_list())
            print()
            continue

        history.append({"role": "user", "content": user_input})

        try:
            agent_loop(history)
        except Exception as e:
            print(f"Error: {e}")

        print()


if __name__ == "__main__":
    main()
