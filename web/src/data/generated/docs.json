[
  {
    "version": "s01",
    "locale": "en",
    "title": "s01: The Agent Loop",
    "content": "# s01: The Agent Loop\n\n> The core of a coding agent is a while loop that feeds tool results back to the model until the model decides to stop.\n\n## The Problem\n\nWhy can't a language model just answer a coding question? Because coding\nrequires _interaction with the real world_. The model needs to read files,\nrun tests, check errors, and iterate. A single prompt-response pair cannot\ndo this.\n\nWithout the agent loop, you would have to copy-paste outputs back into the\nmodel yourself. The user becomes the loop. The agent loop automates this:\ncall the model, execute whatever tools it asks for, feed the results back,\nrepeat until the model says \"I'm done.\"\n\nConsider a simple task: \"Create a Python file that prints hello.\" The model\nneeds to (1) decide to write a file, (2) write it, (3) verify it works.\nThat is three tool calls minimum. Without a loop, each one requires manual\nhuman intervention.\n\n## The Solution\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> |  Tool   |\n|  prompt  |      |       |      | execute |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                      (loop continues)\n\nThe loop terminates when stop_reason != \"tool_use\".\nThat single condition is the entire control flow.\n```\n\n## How It Works\n\n1. The user provides a prompt. It becomes the first message.\n\n```python\nhistory.append({\"role\": \"user\", \"content\": query})\n```\n\n2. The messages array is sent to the LLM along with the tool definitions.\n\n```python\nresponse = client.messages.create(\n    model=MODEL, system=SYSTEM, messages=messages,\n    tools=TOOLS, max_tokens=8000,\n)\n```\n\n3. The assistant response is appended to messages.\n\n```python\nmessages.append({\"role\": \"assistant\", \"content\": response.content})\n```\n\n4. We check the stop reason. If the model did not call a tool, the loop\n   ends. In this minimal lesson implementation, this is the only loop exit\n   condition.\n\n```python\nif response.stop_reason != \"tool_use\":\n    return\n```\n\n5. For each tool_use block in the response, execute the tool (bash in this\n   session) and collect results.\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        output = run_bash(block.input[\"command\"])\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n6. The results are appended as a user message, and the loop continues.\n\n```python\nmessages.append({\"role\": \"user\", \"content\": results})\n```\n\n## Key Code\n\nThe minimum viable agent -- the entire pattern in under 30 lines\n(from `agents/s01_agent_loop.py`, lines 66-86):\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                output = run_bash(block.input[\"command\"])\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## What Changed\n\nThis is session 1 -- the starting point. There is no prior session.\n\n| Component     | Before     | After                          |\n|---------------|------------|--------------------------------|\n| Agent loop    | (none)     | `while True` + stop_reason     |\n| Tools         | (none)     | `bash` (one tool)              |\n| Messages      | (none)     | Accumulating list              |\n| Control flow  | (none)     | `stop_reason != \"tool_use\"`    |\n\n## Design Rationale\n\nThis loop is the foundation of LLM-based agents. Production implementations add error handling, token counting, streaming, retry logic, permission policy, and lifecycle orchestration, but the core interaction pattern still starts here. The simplicity is the point for this session: in this minimal implementation, one exit condition (`stop_reason != \"tool_use\"`) controls the flow we need to learn first. Everything else in this course layers on top of this loop. Understanding this loop gives you the base model, not the full production architecture.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s01_agent_loop.py\n```\n\nExample prompts to try:\n\n1. `Create a file called hello.py that prints \"Hello, World!\"`\n2. `List all Python files in this directory`\n3. `What is the current git branch?`\n4. `Create a directory called test_output and write 3 files in it`\n"
  },
  {
    "version": "s02",
    "locale": "en",
    "title": "s02: Tools",
    "content": "# s02: Tools\n\n> A dispatch map routes tool calls to handler functions -- the loop itself does not change at all.\n\n## The Problem\n\nWith only `bash`, the agent shells out for everything: reading files,\nwriting files, editing files. This works but is fragile. `cat` output\ngets truncated unpredictably. `sed` replacements fail on special\ncharacters. The model wastes tokens constructing shell pipelines when\na direct function call would be simpler.\n\nMore importantly, bash is a security surface. Every bash call can do\nanything the shell can do. With dedicated tools like `read_file` and\n`write_file`, you can enforce path sandboxing and block dangerous\npatterns at the tool level rather than hoping the model avoids them.\n\nThe insight is that adding tools does not require changing the loop.\nThe loop from s01 stays identical. You add entries to the tools array,\nadd handler functions, and wire them together with a dispatch map.\n\n## The Solution\n\n```\n+----------+      +-------+      +------------------+\n|   User   | ---> |  LLM  | ---> | Tool Dispatch    |\n|  prompt  |      |       |      | {                |\n+----------+      +---+---+      |   bash: run_bash |\n                      ^          |   read: run_read |\n                      |          |   write: run_wr  |\n                      +----------+   edit: run_edit |\n                      tool_result| }                |\n                                 +------------------+\n\nThe dispatch map is a dict: {tool_name: handler_function}\nOne lookup replaces any if/elif chain.\n```\n\n## How It Works\n\n1. Define handler functions for each tool. Each takes keyword arguments\n   matching the tool's input_schema and returns a string result.\n\n```python\ndef run_read(path: str, limit: int = None) -> str:\n    text = safe_path(path).read_text()\n    lines = text.splitlines()\n    if limit and limit < len(lines):\n        lines = lines[:limit]\n    return \"\\n\".join(lines)[:50000]\n```\n\n2. Create the dispatch map linking tool names to handlers.\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n```\n\n3. In the agent loop, look up the handler by name instead of hardcoding.\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        handler = TOOL_HANDLERS.get(block.name)\n        output = handler(**block.input)\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n4. Path sandboxing prevents the model from escaping the workspace.\n\n```python\ndef safe_path(p: str) -> Path:\n    path = (WORKDIR / p).resolve()\n    if not path.is_relative_to(WORKDIR):\n        raise ValueError(f\"Path escapes workspace: {p}\")\n    return path\n```\n\n## Key Code\n\nThe dispatch pattern (from `agents/s02_tool_use.py`, lines 93-129):\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input) if handler \\\n                    else f\"Unknown tool: {block.name}\"\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## What Changed From s01\n\n| Component      | Before (s01)       | After (s02)                |\n|----------------|--------------------|----------------------------|\n| Tools          | 1 (bash only)      | 4 (bash, read, write, edit)|\n| Dispatch       | Hardcoded bash call | `TOOL_HANDLERS` dict       |\n| Path safety    | None               | `safe_path()` sandbox      |\n| Agent loop     | Unchanged          | Unchanged                  |\n\n## Design Rationale\n\nThe dispatch map pattern scales linearly -- adding a tool means adding one handler and one schema entry. The loop never changes. This separation of concerns (loop vs handlers) is why agent frameworks can support dozens of tools without increasing control flow complexity. The pattern also enables independent testing of each handler in isolation, since handlers are pure functions with no coupling to the loop. Any agent that outgrows a dispatch map has a design problem, not a scaling problem.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s02_tool_use.py\n```\n\nExample prompts to try:\n\n1. `Read the file requirements.txt`\n2. `Create a file called greet.py with a greet(name) function`\n3. `Edit greet.py to add a docstring to the function`\n4. `Read greet.py to verify the edit worked`\n5. `Run the greet function with bash: python -c \"from greet import greet; greet('World')\"`\n"
  },
  {
    "version": "s03",
    "locale": "en",
    "title": "s03: TodoWrite",
    "content": "# s03: TodoWrite\n\n> A TodoManager lets the agent track its own progress, and a nag reminder injection forces it to keep updating when it forgets.\n\n## The Problem\n\nWhen an agent works on a multi-step task, it often loses track of what it\nhas done and what remains. Without explicit planning, the model might repeat\nwork, skip steps, or wander off on tangents. The user has no visibility\ninto the agent's internal plan.\n\nThis is worse than it sounds. Long conversations cause the model to \"drift\"\n-- the system prompt fades in influence as the context window fills with\ntool results. A 10-step refactoring task might complete steps 1-3, then\nthe model starts improvising because it forgot steps 4-10 existed.\n\nThe solution is structured state: a TodoManager that the model writes to\nexplicitly. The model creates a plan, marks items in_progress as it works,\nand marks them completed when done. A nag reminder injects a nudge if the\nmodel goes 3+ rounds without updating its todos.\n\nNote: the nag threshold of 3 rounds is low for visibility. Production systems tune higher. From s07, this course switches to the Task board for durable multi-step work; TodoWrite remains available for quick checklists.\n\n## The Solution\n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> | Tools   |\n|  prompt  |      |       |      | + todo  |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                            |\n                +-----------+-----------+\n                | TodoManager state     |\n                | [ ] task A            |\n                | [>] task B  <- doing  |\n                | [x] task C            |\n                +-----------------------+\n                            |\n                if rounds_since_todo >= 3:\n                  inject <reminder> into tool_result\n```\n\n## How It Works\n\n1. The TodoManager validates and stores a list of items with statuses.\n   Only one item can be `in_progress` at a time.\n\n```python\nclass TodoManager:\n    def __init__(self):\n        self.items = []\n\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one task can be in_progress\")\n        self.items = validated\n        return self.render()\n```\n\n2. The `todo` tool is added to the dispatch map like any other tool.\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":  lambda **kw: run_bash(kw[\"command\"]),\n    # ...other tools...\n    \"todo\":  lambda **kw: TODO.update(kw[\"items\"]),\n}\n```\n\n3. The nag reminder injects a `<reminder>` tag into the tool_result\n   messages when the model goes 3+ rounds without calling `todo`.\n\n```python\ndef agent_loop(messages: list):\n    rounds_since_todo = 0\n    while True:\n        if rounds_since_todo >= 3 and messages:\n            last = messages[-1]\n            if (last[\"role\"] == \"user\"\n                    and isinstance(last.get(\"content\"), list)):\n                last[\"content\"].insert(0, {\n                    \"type\": \"text\",\n                    \"text\": \"<reminder>Update your todos.</reminder>\",\n                })\n        # ... rest of loop ...\n        rounds_since_todo = 0 if used_todo else rounds_since_todo + 1\n```\n\n4. The system prompt instructs the model to use todos for planning.\n\n```python\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nUse the todo tool to plan multi-step tasks.\nMark in_progress before starting, completed when done.\nPrefer tools over prose.\"\"\"\n```\n\n## Key Code\n\nThe TodoManager and nag injection (from `agents/s03_todo_write.py`,\nlines 51-85 and 158-187):\n\n```python\nclass TodoManager:\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one in_progress\")\n        self.items = validated\n        return self.render()\n\n# In agent_loop:\nif rounds_since_todo >= 3:\n    last[\"content\"].insert(0, {\n        \"type\": \"text\",\n        \"text\": \"<reminder>Update your todos.</reminder>\",\n    })\n```\n\n## What Changed From s02\n\n| Component      | Before (s02)     | After (s03)              |\n|----------------|------------------|--------------------------|\n| Tools          | 4                | 5 (+todo)                |\n| Planning       | None             | TodoManager with statuses|\n| Nag injection  | None             | `<reminder>` after 3 rounds|\n| Agent loop     | Simple dispatch  | + rounds_since_todo counter|\n\n## Design Rationale\n\nVisible plans improve task completion because the model can self-monitor progress. The nag mechanism creates accountability -- without it, the model may abandon plans mid-execution as conversation context grows and earlier instructions fade. The \"one in_progress at a time\" constraint enforces sequential focus, preventing context-switching overhead that degrades output quality. This pattern works because it externalizes the model's working memory into structured state that survives attention drift.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s03_todo_write.py\n```\n\nExample prompts to try:\n\n1. `Refactor the file hello.py: add type hints, docstrings, and a main guard`\n2. `Create a Python package with __init__.py, utils.py, and tests/test_utils.py`\n3. `Review all Python files and fix any style issues`\n"
  },
  {
    "version": "s04",
    "locale": "en",
    "title": "s04: Subagents",
    "content": "# s04: Subagents\n\n> A subagent runs with a fresh messages list, shares the filesystem with the parent, and returns only a summary -- keeping the parent context clean.\n\n## The Problem\n\nAs the agent works, its messages array grows. Every tool call, every file\nread, every bash output accumulates. After 20-30 tool calls, the context\nwindow is crowded with irrelevant history. Reading a 500-line file to\nanswer a quick question permanently adds 500 lines to the context.\n\nThis is particularly bad for exploratory tasks. \"What testing framework\ndoes this project use?\" might require reading 5 files, but the parent\nagent does not need all 5 file contents in its history -- it just needs\nthe answer: \"pytest with conftest.py configuration.\"\n\nIn this course, a practical solution is fresh-context isolation: spawn a child agent with `messages=[]`.\nThe child explores, reads files, runs commands. When it finishes, only its\nfinal text response returns to the parent. The child's entire message\nhistory is discarded.\n\n## The Solution\n\n```\nParent agent                     Subagent\n+------------------+             +------------------+\n| messages=[...]   |             | messages=[]      | <-- fresh\n|                  |  dispatch   |                  |\n| tool: task       | ---------->| while tool_use:  |\n|   prompt=\"...\"   |            |   call tools     |\n|                  |  summary   |   append results |\n|   result = \"...\" | <--------- | return last text |\n+------------------+             +------------------+\n          |\nParent context stays clean.\nSubagent context is discarded.\n```\n\n## How It Works\n\n1. The parent agent gets a `task` tool that triggers subagent spawning.\n   The child gets all base tools except `task` (no recursive spawning).\n\n```python\nPARENT_TOOLS = CHILD_TOOLS + [\n    {\"name\": \"task\",\n     \"description\": \"Spawn a subagent with fresh context.\",\n     \"input_schema\": {\n         \"type\": \"object\",\n         \"properties\": {\n             \"prompt\": {\"type\": \"string\"},\n             \"description\": {\"type\": \"string\"},\n         },\n         \"required\": [\"prompt\"],\n     }},\n]\n```\n\n2. The subagent starts with a fresh messages list containing only\n   the delegated prompt. It shares the same filesystem.\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):  # safety limit\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\n            \"role\": \"assistant\", \"content\": response.content\n        })\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n```\n\n3. Only the final text returns to the parent. The child's 30+ tool\n   call history is discarded.\n\n```python\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n4. The parent receives this summary as a normal tool_result.\n\n```python\nif block.name == \"task\":\n    output = run_subagent(block.input[\"prompt\"])\nresults.append({\n    \"type\": \"tool_result\",\n    \"tool_use_id\": block.id,\n    \"content\": str(output),\n})\n```\n\n## Key Code\n\nThe subagent function (from `agents/s04_subagent.py`,\nlines 110-128):\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\"role\": \"assistant\",\n                             \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input)\n                results.append({\"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": str(output)[:50000]})\n        sub_messages.append({\"role\": \"user\", \"content\": results})\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n## What Changed From s03\n\n| Component      | Before (s03)     | After (s04)               |\n|----------------|------------------|---------------------------|\n| Tools          | 5                | 5 (base) + task (parent)  |\n| Context        | Single shared    | Parent + child isolation  |\n| Subagent       | None             | `run_subagent()` function |\n| Return value   | N/A              | Summary text only         |\n\n## Design Rationale\n\nFresh-context isolation is a practical way to approximate context isolation in this session. A fresh `messages[]` means the subagent starts without the parent's conversation history. The tradeoff is communication overhead -- results must be compressed back to the parent, losing detail. This is a message-history isolation strategy, not OS process isolation. Limiting subagent depth (no recursive spawning) prevents unbounded resource consumption, and a max iteration count ensures runaway children terminate.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s04_subagent.py\n```\n\nExample prompts to try:\n\n1. `Use a subtask to find what testing framework this project uses`\n2. `Delegate: read all .py files and summarize what each one does`\n3. `Use a task to create a new module, then verify it from here`\n"
  },
  {
    "version": "s05",
    "locale": "en",
    "title": "s05: Skills",
    "content": "# s05: Skills\n\n> Two-layer skill injection avoids system prompt bloat by putting skill names in the system prompt (cheap) and full skill bodies in tool_result (on demand).\n\n## The Problem\n\nYou want the agent to follow specific workflows for different domains:\ngit conventions, testing patterns, code review checklists. The naive\napproach is to put everything in the system prompt. But the system prompt\nhas limited effective attention -- too much text and the model starts\nignoring parts of it.\n\nIf you have 10 skills at 2000 tokens each, that is 20,000 tokens of system\nprompt. The model pays attention to the beginning and end but skims the\nmiddle. Worse, most of those skills are irrelevant to any given task. A\nfile editing task does not need the git workflow instructions.\n\nThe two-layer approach solves this: Layer 1 puts short skill descriptions\nin the system prompt (~100 tokens per skill). Layer 2 loads the full skill\nbody into a tool_result only when the model calls `load_skill`. The model\nlearns what skills exist (cheap) and loads them on demand (only when\nrelevant).\n\n## The Solution\n\n```\nSystem prompt (Layer 1 -- always present):\n+--------------------------------------+\n| You are a coding agent.              |\n| Skills available:                    |\n|   - git: Git workflow helpers        |  ~100 tokens/skill\n|   - test: Testing best practices     |\n+--------------------------------------+\n\nWhen model calls load_skill(\"git\"):\n+--------------------------------------+\n| tool_result (Layer 2 -- on demand):  |\n| <skill name=\"git\">                   |\n|   Full git workflow instructions...  |  ~2000 tokens\n|   Step 1: ...                        |\n|   Step 2: ...                        |\n| </skill>                             |\n+--------------------------------------+\n```\n\n## How It Works\n\n1. Skill files live in `.skills/` as Markdown with YAML frontmatter.\n\n```\n.skills/\n  git.md       # ---\\n description: Git workflow\\n ---\\n ...\n  test.md      # ---\\n description: Testing patterns\\n ---\\n ...\n```\n\n2. The SkillLoader parses frontmatter and separates metadata from body.\n\n```python\nclass SkillLoader:\n    def _parse_frontmatter(self, text: str) -> tuple:\n        match = re.match(\n            r\"^---\\n(.*?)\\n---\\n(.*)\", text, re.DOTALL\n        )\n        if not match:\n            return {}, text\n        meta = {}\n        for line in match.group(1).strip().splitlines():\n            if \":\" in line:\n                key, val = line.split(\":\", 1)\n                meta[key.strip()] = val.strip()\n        return meta, match.group(2).strip()\n```\n\n3. Layer 1: `get_descriptions()` returns short lines for the system prompt.\n\n```python\ndef get_descriptions(self) -> str:\n    lines = []\n    for name, skill in self.skills.items():\n        desc = skill[\"meta\"].get(\"description\", \"No description\")\n        lines.append(f\"  - {name}: {desc}\")\n    return \"\\n\".join(lines)\n\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nSkills available:\n{SKILL_LOADER.get_descriptions()}\"\"\"\n```\n\n4. Layer 2: `get_content()` returns the full body wrapped in `<skill>` tags.\n\n```python\ndef get_content(self, name: str) -> str:\n    skill = self.skills.get(name)\n    if not skill:\n        return f\"Error: Unknown skill '{name}'.\"\n    return f\"<skill name=\\\"{name}\\\">\\n{skill['body']}\\n</skill>\"\n```\n\n5. The `load_skill` tool is just another entry in the dispatch map.\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"load_skill\": lambda **kw: SKILL_LOADER.get_content(kw[\"name\"]),\n}\n```\n\n## Key Code\n\nThe SkillLoader class (from `agents/s05_skill_loading.py`,\nlines 51-97):\n\n```python\nclass SkillLoader:\n    def __init__(self, skills_dir: Path):\n        self.skills = {}\n        for f in sorted(skills_dir.glob(\"*.md\")):\n            text = f.read_text()\n            meta, body = self._parse_frontmatter(text)\n            self.skills[f.stem] = {\n                \"meta\": meta, \"body\": body\n            }\n\n    def get_descriptions(self) -> str:\n        lines = []\n        for name, skill in self.skills.items():\n            desc = skill[\"meta\"].get(\"description\", \"\")\n            lines.append(f\"  - {name}: {desc}\")\n        return \"\\n\".join(lines)\n\n    def get_content(self, name: str) -> str:\n        skill = self.skills.get(name)\n        if not skill:\n            return f\"Error: Unknown skill '{name}'.\"\n        return (f\"<skill name=\\\"{name}\\\">\\n\"\n                f\"{skill['body']}\\n</skill>\")\n```\n\n## What Changed From s04\n\n| Component      | Before (s04)     | After (s05)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5 (base + task)  | 5 (base + load_skill)      |\n| System prompt  | Static string    | + skill descriptions       |\n| Knowledge      | None             | .skills/*.md files         |\n| Injection      | None             | Two-layer (system + result)|\n\n## Design Rationale\n\nTwo-layer injection solves the attention budget problem. Putting all skill content in the system prompt wastes tokens on unused skills. Layer 1 (compact summaries) costs roughly 120 tokens total. Layer 2 (full content) loads on demand via tool_result. This scales to dozens of skills without degrading model attention quality. The key insight is that the model only needs to know what skills exist (cheap) to decide when to load one (expensive). This is the same lazy-loading principle used in software module systems.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s05_skill_loading.py\n```\n\nExample prompts to try:\n\n1. `What skills are available?`\n2. `Load the agent-builder skill and follow its instructions`\n3. `I need to do a code review -- load the relevant skill first`\n4. `Build an MCP server using the mcp-builder skill`\n"
  },
  {
    "version": "s06",
    "locale": "en",
    "title": "s06: Compact",
    "content": "# s06: Compact\n\n> A three-layer compression pipeline lets the agent work indefinitely by strategically forgetting old tool results, auto-summarizing when tokens exceed a threshold, and allowing manual compression on demand.\n\n## The Problem\n\nThe context window is finite. After enough tool calls, the messages array\nexceeds the model's context limit and the API call fails. Even before\nhitting the hard limit, performance degrades: the model becomes slower,\nless accurate, and starts ignoring earlier messages.\n\nA 200,000 token context window sounds large, but a single `read_file` on\na 1000-line source file consumes ~4000 tokens. After reading 30 files and\nrunning 20 bash commands, you are at 100,000+ tokens. The agent cannot\nwork on large codebases without some form of compression.\n\nThe three-layer pipeline addresses this with increasing aggressiveness:\nLayer 1 (micro-compact) silently replaces old tool results every turn.\nLayer 2 (auto-compact) triggers a full summarization when tokens exceed\na threshold. Layer 3 (manual compact) lets the model trigger compression\nitself.\n\nTeaching simplification: the token estimation here uses a rough\ncharacters/4 heuristic. Production systems use proper tokenizer\nlibraries for accurate counts.\n\n## The Solution\n\n```\nEvery turn:\n+------------------+\n| Tool call result |\n+------------------+\n        |\n        v\n[Layer 1: micro_compact]        (silent, every turn)\n  Replace tool_result > 3 turns old\n  with \"[Previous: used {tool_name}]\"\n        |\n        v\n[Check: tokens > 50000?]\n   |               |\n   no              yes\n   |               |\n   v               v\ncontinue    [Layer 2: auto_compact]\n              Save transcript to .transcripts/\n              LLM summarizes conversation.\n              Replace all messages with [summary].\n                    |\n                    v\n            [Layer 3: compact tool]\n              Model calls compact explicitly.\n              Same summarization as auto_compact.\n```\n\n## How It Works\n\n1. **Layer 1 -- micro_compact**: Before each LLM call, find all\n   tool_result entries older than the last 3 and replace their content.\n\n```python\ndef micro_compact(messages: list) -> list:\n    tool_results = []\n    for i, msg in enumerate(messages):\n        if msg[\"role\"] == \"user\" and isinstance(msg.get(\"content\"), list):\n            for j, part in enumerate(msg[\"content\"]):\n                if isinstance(part, dict) and part.get(\"type\") == \"tool_result\":\n                    tool_results.append((i, j, part))\n    if len(tool_results) <= KEEP_RECENT:\n        return messages\n    to_clear = tool_results[:-KEEP_RECENT]\n    for _, _, part in to_clear:\n        if len(part.get(\"content\", \"\")) > 100:\n            tool_id = part.get(\"tool_use_id\", \"\")\n            tool_name = tool_name_map.get(tool_id, \"unknown\")\n            part[\"content\"] = f\"[Previous: used {tool_name}]\"\n    return messages\n```\n\n2. **Layer 2 -- auto_compact**: When estimated tokens exceed 50,000,\n   save the full transcript and ask the LLM to summarize.\n\n```python\ndef auto_compact(messages: list) -> list:\n    TRANSCRIPT_DIR.mkdir(exist_ok=True)\n    transcript_path = TRANSCRIPT_DIR / f\"transcript_{int(time.time())}.jsonl\"\n    with open(transcript_path, \"w\") as f:\n        for msg in messages:\n            f.write(json.dumps(msg, default=str) + \"\\n\")\n    response = client.messages.create(\n        model=MODEL,\n        messages=[{\"role\": \"user\", \"content\":\n            \"Summarize this conversation for continuity...\"\n            + json.dumps(messages, default=str)[:80000]}],\n        max_tokens=2000,\n    )\n    summary = response.content[0].text\n    return [\n        {\"role\": \"user\", \"content\": f\"[Compressed]\\n\\n{summary}\"},\n        {\"role\": \"assistant\", \"content\": \"Understood. Continuing.\"},\n    ]\n```\n\n3. **Layer 3 -- manual compact**: The `compact` tool triggers the same\n   summarization on demand.\n\n```python\nif manual_compact:\n    messages[:] = auto_compact(messages)\n```\n\n4. The agent loop integrates all three layers.\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        micro_compact(messages)\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)\n        response = client.messages.create(...)\n        # ... tool execution ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)\n```\n\n## Key Code\n\nThe three-layer pipeline (from `agents/s06_context_compact.py`,\nlines 67-93 and 189-223):\n\n```python\nTHRESHOLD = 50000\nKEEP_RECENT = 3\n\ndef micro_compact(messages):\n    # Replace old tool results with placeholders\n    ...\n\ndef auto_compact(messages):\n    # Save transcript, LLM summarize, replace messages\n    ...\n\ndef agent_loop(messages):\n    while True:\n        micro_compact(messages)          # Layer 1\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)  # Layer 2\n        response = client.messages.create(...)\n        # ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)  # Layer 3\n```\n\n## What Changed From s05\n\n| Component      | Before (s05)     | After (s06)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 5 (base + compact)         |\n| Context mgmt   | None             | Three-layer compression    |\n| Micro-compact  | None             | Old results -> placeholders|\n| Auto-compact   | None             | Token threshold trigger    |\n| Manual compact | None             | `compact` tool             |\n| Transcripts    | None             | Saved to .transcripts/     |\n\n## Design Rationale\n\nContext windows are finite, but agent sessions can be infinite. Three compression layers solve this at different granularities: micro-compact (replace old tool outputs), auto-compact (LLM summarizes when approaching limit), and manual compact (user-triggered). The key insight is that forgetting is a feature, not a bug -- it enables unbounded sessions. Transcripts preserve the full history on disk so nothing is truly lost, just moved out of the active context. The layered approach lets each layer operate independently at its own granularity, from silent per-turn cleanup to full conversation reset.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s06_context_compact.py\n```\n\nExample prompts to try:\n\n1. `Read every Python file in the agents/ directory one by one`\n   (watch micro-compact replace old results)\n2. `Keep reading files until compression triggers automatically`\n3. `Use the compact tool to manually compress the conversation`\n"
  },
  {
    "version": "s07",
    "locale": "en",
    "title": "s07: Tasks",
    "content": "# s07: Tasks\n\n> Tasks are persisted as JSON files with a dependency graph, so state survives context compression and can be shared across agents.\n\n## Problem\n\nIn-memory state (for example the TodoManager from s03) is fragile under compression (s06). Once earlier turns are compacted into summaries, in-memory todo state is gone.\n\ns06 -> s07 is the key transition:\n\n1. Todo list state in memory is conversational and lossy.\n2. Task board state on disk is durable and recoverable.\n\nA second issue is visibility: in-memory structures are process-local, so teammates cannot reliably share that state.\n\n## When to Use Task vs Todo\n\nFrom s07 onward, Task is the default. Todo remains for short linear checklists.\n\n## Quick Decision Matrix\n\n| Situation | Prefer | Why |\n|---|---|---|\n| Short, single-session checklist | Todo | Lowest ceremony, fastest capture |\n| Cross-session work, dependencies, or teammates | Task | Durable state, dependency graph, shared visibility |\n| Unsure which one to use | Task | Easier to simplify later than migrate mid-run |\n\n## Solution\n\n```\n.tasks/\n  task_1.json  {\"id\":1, \"status\":\"completed\", ...}\n  task_2.json  {\"id\":2, \"blockedBy\":[1], \"status\":\"pending\"}\n  task_3.json  {\"id\":3, \"blockedBy\":[2], \"status\":\"pending\"}\n\nDependency resolution:\n+----------+     +----------+     +----------+\n| task 1   | --> | task 2   | --> | task 3   |\n| complete |     | blocked  |     | blocked  |\n+----------+     +----------+     +----------+\n     |                ^\n     +--- completing task 1 removes it from\n          task 2's blockedBy list\n```\n\n## How It Works\n\n1. TaskManager provides CRUD with one JSON file per task.\n\n```python\nclass TaskManager:\n    def create(self, subject: str, description: str = \"\") -> str:\n        task = {\n            \"id\": self._next_id,\n            \"subject\": subject,\n            \"description\": description,\n            \"status\": \"pending\",\n            \"blockedBy\": [],\n            \"blocks\": [],\n            \"owner\": \"\",\n        }\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n```\n\n2. Completing a task clears that dependency from other tasks.\n\n```python\ndef _clear_dependency(self, completed_id: int):\n    for f in self.dir.glob(\"task_*.json\"):\n        task = json.loads(f.read_text())\n        if completed_id in task.get(\"blockedBy\", []):\n            task[\"blockedBy\"].remove(completed_id)\n            self._save(task)\n```\n\n3. `update` handles status transitions and dependency wiring.\n\n```python\ndef update(self, task_id, status=None,\n           add_blocked_by=None, add_blocks=None):\n    task = self._load(task_id)\n    if status:\n        task[\"status\"] = status\n        if status == \"completed\":\n            self._clear_dependency(task_id)\n    if add_blocks:\n        task[\"blocks\"] = list(set(task[\"blocks\"] + add_blocks))\n        for blocked_id in add_blocks:\n            blocked = self._load(blocked_id)\n            if task_id not in blocked[\"blockedBy\"]:\n                blocked[\"blockedBy\"].append(task_id)\n                self._save(blocked)\n    self._save(task)\n```\n\n4. Task tools are added to the dispatch map.\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"task_create\": lambda **kw: TASKS.create(kw[\"subject\"]),\n    \"task_update\": lambda **kw: TASKS.update(kw[\"task_id\"],\n                       kw.get(\"status\")),\n    \"task_list\":   lambda **kw: TASKS.list_all(),\n    \"task_get\":    lambda **kw: TASKS.get(kw[\"task_id\"]),\n}\n```\n\n## Key Code\n\nTaskManager with dependency graph (from `agents/s07_task_system.py`, lines 46-123):\n\n```python\nclass TaskManager:\n    def __init__(self, tasks_dir: Path):\n        self.dir = tasks_dir\n        self.dir.mkdir(exist_ok=True)\n        self._next_id = self._max_id() + 1\n\n    def _load(self, task_id: int) -> dict:\n        path = self.dir / f\"task_{task_id}.json\"\n        return json.loads(path.read_text())\n\n    def _save(self, task: dict):\n        path = self.dir / f\"task_{task['id']}.json\"\n        path.write_text(json.dumps(task, indent=2))\n\n    def create(self, subject, description=\"\"):\n        task = {\"id\": self._next_id, \"subject\": subject,\n                \"status\": \"pending\", \"blockedBy\": [],\n                \"blocks\": [], \"owner\": \"\"}\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n\n    def _clear_dependency(self, completed_id):\n        for f in self.dir.glob(\"task_*.json\"):\n            task = json.loads(f.read_text())\n            if completed_id in task.get(\"blockedBy\", []):\n                task[\"blockedBy\"].remove(completed_id)\n                self._save(task)\n```\n\n## What Changed From s06\n\n| Component | Before (s06) | After (s07) |\n|---|---|---|\n| Tools | 5 | 8 (`task_create/update/list/get`) |\n| State storage | In-memory only | JSON files in `.tasks/` |\n| Dependencies | None | `blockedBy + blocks` graph |\n| Persistence | Lost on compact | Survives compression |\n\n## Design Rationale\n\nFile-based state survives compaction and process restarts. The dependency graph preserves execution order even when conversation details are forgotten. This turns transient chat context into durable work state.\n\nDurability still needs a write discipline: reload task JSON before each write, validate expected `status/blockedBy`, then persist atomically. Otherwise concurrent writers can overwrite each other.\n\nCourse-level implication: s07+ defaults to Task because it better matches long-running and collaborative engineering workflows.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s07_task_system.py\n```\n\nSuggested prompts:\n\n1. `Create 3 tasks: \"Setup project\", \"Write code\", \"Write tests\". Make them depend on each other in order.`\n2. `List all tasks and show the dependency graph`\n3. `Complete task 1 and then list tasks to see task 2 unblocked`\n4. `Create a task board for refactoring: parse -> transform -> emit -> test`\n"
  },
  {
    "version": "s08",
    "locale": "en",
    "title": "s08: Background Tasks",
    "content": "# s08: Background Tasks\n\n> A BackgroundManager runs commands in separate threads and drains a notification queue before each LLM call, so the agent never blocks on long-running operations.\n\n## The Problem\n\nSome commands take minutes: `npm install`, `pytest`, `docker build`. With\na blocking agent loop, the model sits idle waiting for the subprocess to\nfinish. It cannot do anything else. If the user asked \"install dependencies\nand while that runs, create the config file,\" the agent would install\nfirst, _then_ create the config -- sequentially, not in parallel.\n\nThe agent needs concurrency. Not full multi-threading of the agent loop\nitself, but the ability to fire off a long command and continue working\nwhile it runs. When the command finishes, its result should appear\nnaturally in the conversation.\n\nThe solution is a BackgroundManager that runs commands in daemon threads\nand collects results in a notification queue. Before each LLM call, the\nqueue is drained and results are injected into the messages.\n\n## The Solution\n\n```\nMain thread                Background thread\n+-----------------+        +-----------------+\n| agent loop      |        | task executes   |\n| ...             |        | ...             |\n| [LLM call] <---+------- | enqueue(result) |\n|  ^drain queue   |        +-----------------+\n+-----------------+\n\nTimeline:\nAgent --[spawn A]--[spawn B]--[other work]----\n             |          |\n             v          v\n          [A runs]   [B runs]      (parallel)\n             |          |\n             +-- notification queue --+\n                                      |\n                           [results injected before\n                            next LLM call]\n```\n\n## How It Works\n\n1. The BackgroundManager tracks tasks and maintains a thread-safe\n   notification queue.\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n```\n\n2. `run()` starts a daemon thread and returns a task_id immediately.\n\n```python\ndef run(self, command: str) -> str:\n    task_id = str(uuid.uuid4())[:8]\n    self.tasks[task_id] = {\n        \"status\": \"running\",\n        \"result\": None,\n        \"command\": command,\n    }\n    thread = threading.Thread(\n        target=self._execute,\n        args=(task_id, command),\n        daemon=True,\n    )\n    thread.start()\n    return f\"Background task {task_id} started\"\n```\n\n3. The thread target `_execute` runs the subprocess and pushes\n   results to the notification queue.\n\n```python\ndef _execute(self, task_id: str, command: str):\n    try:\n        r = subprocess.run(command, shell=True, cwd=WORKDIR,\n            capture_output=True, text=True, timeout=300)\n        output = (r.stdout + r.stderr).strip()[:50000]\n        status = \"completed\"\n    except subprocess.TimeoutExpired:\n        output = \"Error: Timeout (300s)\"\n        status = \"timeout\"\n    self.tasks[task_id][\"status\"] = status\n    self.tasks[task_id][\"result\"] = output\n    with self._lock:\n        self._notification_queue.append({\n            \"task_id\": task_id,\n            \"status\": status,\n            \"result\": output[:500],\n        })\n```\n\n4. `drain_notifications()` returns and clears pending results.\n\n```python\ndef drain_notifications(self) -> list:\n    with self._lock:\n        notifs = list(self._notification_queue)\n        self._notification_queue.clear()\n    return notifs\n```\n\n5. The agent loop drains notifications before each LLM call.\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        notifs = BG.drain_notifications()\n        if notifs and messages:\n            notif_text = \"\\n\".join(\n                f\"[bg:{n['task_id']}] {n['status']}: \"\n                f\"{n['result']}\" for n in notifs\n            )\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<background-results>\"\n                           f\"\\n{notif_text}\\n\"\n                           f\"</background-results>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted background results.\"})\n        response = client.messages.create(...)\n```\n\n## Key Code\n\nThe BackgroundManager (from `agents/s08_background_tasks.py`, lines 49-107):\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n\n    def run(self, command: str) -> str:\n        task_id = str(uuid.uuid4())[:8]\n        self.tasks[task_id] = {\"status\": \"running\",\n                               \"result\": None,\n                               \"command\": command}\n        thread = threading.Thread(\n            target=self._execute,\n            args=(task_id, command), daemon=True)\n        thread.start()\n        return f\"Background task {task_id} started\"\n\n    def _execute(self, task_id, command):\n        # run subprocess, push to queue\n        ...\n\n    def drain_notifications(self) -> list:\n        with self._lock:\n            notifs = list(self._notification_queue)\n            self._notification_queue.clear()\n        return notifs\n```\n\n## What Changed From s07\n\n| Component      | Before (s07)     | After (s08)                |\n|----------------|------------------|----------------------------|\n| Tools          | 8                | 6 (base + background_run + check)|\n| Execution      | Blocking only    | Blocking + background threads|\n| Notification   | None             | Queue drained per loop     |\n| Concurrency    | None             | Daemon threads             |\n\n## Design Rationale\n\nThe agent loop is inherently single-threaded (one LLM call at a time). Background threads break this constraint for I/O-bound work (tests, builds, installs). The notification queue pattern (\"drain before next LLM call\") ensures results arrive at natural conversation breakpoints rather than interrupting the model's reasoning mid-thought. This is a minimal concurrency model: the agent loop stays single-threaded and deterministic, while only the I/O-bound subprocess execution is parallelized.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s08_background_tasks.py\n```\n\nExample prompts to try:\n\n1. `Run \"sleep 5 && echo done\" in the background, then create a file while it runs`\n2. `Start 3 background tasks: \"sleep 2\", \"sleep 4\", \"sleep 6\". Check their status.`\n3. `Run pytest in the background and keep working on other things`\n"
  },
  {
    "version": "s09",
    "locale": "en",
    "title": "s09: Agent Teams",
    "content": "# s09: Agent Teams\n\n> Persistent teammates with JSONL inboxes are one teaching protocol for turning isolated agents into a communicating team -- spawn, message, broadcast, and drain.\n\n## The Problem\n\nSubagents (s04) are disposable: spawn, work, return summary, die. They\nhave no identity, no memory between invocations, and no way to receive\nfollow-up instructions. Background tasks (s08) run shell commands but\ncannot make LLM-guided decisions or communicate findings.\n\nFor real teamwork you need three things: (1) persistent agents that\nsurvive beyond a single prompt, (2) identity and lifecycle management,\nand (3) a communication channel between agents. Without messaging, even\npersistent teammates are deaf and mute -- they can work in parallel but\nnever coordinate.\n\nThe solution combines a TeammateManager for spawning persistent named\nagents with a MessageBus using JSONL inbox files. Each teammate runs\nits own agent loop in a thread, checks its inbox before every LLM call,\nand can send messages to any other teammate or the lead.\n\nNote on the s06-to-s07 bridge: TodoManager items from s03 die with\ncompression (s06). File-based tasks (s07) survive compression because\nthey live on disk. Teams build on this same principle -- config.json and\ninbox files persist outside the context window.\n\n## The Solution\n\n```\nTeammate lifecycle:\n  spawn -> WORKING -> IDLE -> WORKING -> ... -> SHUTDOWN\n\nCommunication:\n  .team/\n    config.json           <- team roster + statuses\n    inbox/\n      alice.jsonl         <- append-only, drain-on-read\n      bob.jsonl\n      lead.jsonl\n\n                +--------+    send(\"alice\",\"bob\",\"...\")    +--------+\n                | alice  | -----------------------------> |  bob   |\n                | loop   |    bob.jsonl << {json_line}    |  loop  |\n                +--------+                                +--------+\n                     ^                                         |\n                     |        BUS.read_inbox(\"alice\")          |\n                     +---- alice.jsonl -> read + drain ---------+\n\n5 message types:\n+-------------------------+------------------------------+\n| message                 | Normal text between agents   |\n| broadcast               | Sent to all teammates        |\n| shutdown_request        | Request graceful shutdown     |\n| shutdown_response       | Approve/reject shutdown      |\n| plan_approval_response  | Approve/reject plan          |\n+-------------------------+------------------------------+\n```\n\n## How It Works\n\n1. The TeammateManager maintains config.json with the team roster.\n   Each member has a name, role, and status.\n\n```python\nclass TeammateManager:\n    def __init__(self, team_dir: Path):\n        self.dir = team_dir\n        self.dir.mkdir(exist_ok=True)\n        self.config_path = self.dir / \"config.json\"\n        self.config = self._load_config()\n        self.threads = {}\n```\n\n2. `spawn()` creates a teammate and starts its agent loop in a thread.\n   Re-spawning an idle teammate reactivates it.\n\n```python\ndef spawn(self, name: str, role: str, prompt: str) -> str:\n    member = self._find_member(name)\n    if member:\n        if member[\"status\"] not in (\"idle\", \"shutdown\"):\n            return f\"Error: '{name}' is currently {member['status']}\"\n        member[\"status\"] = \"working\"\n    else:\n        member = {\"name\": name, \"role\": role, \"status\": \"working\"}\n        self.config[\"members\"].append(member)\n    self._save_config()\n    thread = threading.Thread(\n        target=self._teammate_loop,\n        args=(name, role, prompt), daemon=True)\n    self.threads[name] = thread\n    thread.start()\n    return f\"Spawned teammate '{name}' (role: {role})\"\n```\n\n3. The MessageBus handles JSONL inbox files. `send()` appends a JSON\n   line; `read_inbox()` reads all lines and drains the file.\n\n```python\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content,\n               \"timestamp\": time.time()}\n        if extra:\n            msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n        return f\"Sent {msg_type} to {to}\"\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists():\n            return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")  # drain\n        return json.dumps(msgs, indent=2)\n```\n\n4. Each teammate checks its inbox before every LLM call and injects\n   received messages into the conversation context.\n\n```python\ndef _teammate_loop(self, name, role, prompt):\n    sys_prompt = f\"You are '{name}', role: {role}, at {WORKDIR}.\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(50):\n        inbox = BUS.read_inbox(name)\n        if inbox != \"[]\":\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted inbox messages.\"})\n        response = client.messages.create(\n            model=MODEL, system=sys_prompt,\n            messages=messages, tools=TOOLS)\n        messages.append({\"role\": \"assistant\",\n                         \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n    self._find_member(name)[\"status\"] = \"idle\"\n    self._save_config()\n```\n\n5. `broadcast()` sends the same message to all teammates except the\n   sender.\n\n```python\ndef broadcast(self, sender, content, teammates):\n    count = 0\n    for name in teammates:\n        if name != sender:\n            self.send(sender, name, content, \"broadcast\")\n            count += 1\n    return f\"Broadcast to {count} teammates\"\n```\n\n## Key Code\n\nThe TeammateManager + MessageBus core (from `agents/s09_agent_teams.py`):\n\n```python\nclass TeammateManager:\n    def spawn(self, name, role, prompt):\n        member = self._find_member(name) or {\n            \"name\": name, \"role\": role, \"status\": \"working\"\n        }\n        member[\"status\"] = \"working\"\n        self._save_config()\n        thread = threading.Thread(\n            target=self._teammate_loop,\n            args=(name, role, prompt), daemon=True)\n        thread.start()\n        return f\"Spawned '{name}'\"\n\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content, \"timestamp\": time.time()}\n        if extra: msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists(): return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")\n        return json.dumps(msgs, indent=2)\n```\n\n## What Changed From s08\n\n| Component      | Before (s08)     | After (s09)                |\n|----------------|------------------|----------------------------|\n| Tools          | 6                | 9 (+spawn/send/read_inbox) |\n| Agents         | Single           | Lead + N teammates         |\n| Persistence    | None             | config.json + JSONL inboxes|\n| Threads        | Background cmds  | Full agent loops per thread|\n| Lifecycle      | Fire-and-forget  | idle -> working -> idle    |\n| Communication  | None             | 5 message types + broadcast|\n\nTeaching simplification: this implementation does not use lock files\nfor inbox access. In production, concurrent append from multiple writers\nwould need file locking or atomic rename. The single-writer-per-inbox\npattern used here is safe for the teaching scenario.\n\n## Design Rationale\n\nFile-based mailboxes (append-only JSONL) are easy to inspect and reason about in a teaching codebase. The \"drain on read\" pattern (read all, truncate) gives batch delivery with very little machinery. The tradeoff is latency -- messages are only seen at the next poll -- but for LLM-driven agents where each turn takes seconds, polling latency is acceptable for this course.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s09_agent_teams.py\n```\n\nExample prompts to try:\n\n1. `Spawn alice (coder) and bob (tester). Have alice send bob a message.`\n2. `Broadcast \"status update: phase 1 complete\" to all teammates`\n3. `Check the lead inbox for any messages`\n4. Type `/team` to see the team roster with statuses\n5. Type `/inbox` to manually check the lead's inbox\n"
  },
  {
    "version": "s10",
    "locale": "en",
    "title": "s10: Team Protocols",
    "content": "# s10: Team Protocols\n\n> The same request_id handshake pattern powers both shutdown and plan approval -- one FSM, two applications.\n\n## The Problem\n\nIn s09, teammates work and communicate but there is no structured\ncoordination. Two problems arise:\n\n**Shutdown**: How do you stop a teammate cleanly? Killing the thread\nleaves files partially written and config.json in a wrong state.\nGraceful shutdown requires a handshake: the lead requests, the teammate\ndecides whether to approve (finish and exit) or reject (keep working).\n\n**Plan approval**: How do you gate execution? When the lead says\n\"refactor the auth module,\" the teammate starts immediately. For\nhigh-risk changes, the lead should review the plan before execution\nbegins. A junior proposes, a senior approves.\n\nBoth problems share the same structure: one side sends a request with a\nunique ID, the other side responds referencing that ID. A finite state\nmachine tracks each request through pending -> approved | rejected.\n\n## The Solution\n\n```\nShutdown Protocol            Plan Approval Protocol\n==================           ======================\n\nLead             Teammate    Teammate           Lead\n  |                 |           |                 |\n  |--shutdown_req-->|           |--plan_req------>|\n  | {req_id:\"abc\"}  |           | {req_id:\"xyz\"}  |\n  |                 |           |                 |\n  |<--shutdown_resp-|           |<--plan_resp-----|\n  | {req_id:\"abc\",  |           | {req_id:\"xyz\",  |\n  |  approve:true}  |           |  approve:true}  |\n  |                 |           |                 |\n  v                 v           v                 v\ntracker[\"abc\"]     exits     proceeds          tracker[\"xyz\"]\n = approved                                     = approved\n\nShared FSM (identical for both protocols):\n  [pending] --approve--> [approved]\n  [pending] --reject---> [rejected]\n\nTrackers:\n  shutdown_requests = {req_id: {target, status}}\n  plan_requests     = {req_id: {from, plan, status}}\n```\n\n## How It Works\n\n1. The lead initiates shutdown by generating a request_id and sending\n   a shutdown_request through the inbox.\n\n```python\nshutdown_requests = {}\n\ndef handle_shutdown_request(teammate: str) -> str:\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\",\n    }\n    BUS.send(\"lead\", teammate, \"Please shut down gracefully.\",\n             \"shutdown_request\", {\"request_id\": req_id})\n    return f\"Shutdown request {req_id} sent (status: pending)\"\n```\n\n2. The teammate receives the request in its inbox and calls the\n   `shutdown_response` tool to approve or reject.\n\n```python\nif tool_name == \"shutdown_response\":\n    req_id = args[\"request_id\"]\n    approve = args[\"approve\"]\n    if req_id in shutdown_requests:\n        shutdown_requests[req_id][\"status\"] = \\\n            \"approved\" if approve else \"rejected\"\n    BUS.send(sender, \"lead\", args.get(\"reason\", \"\"),\n             \"shutdown_response\",\n             {\"request_id\": req_id, \"approve\": approve})\n    return f\"Shutdown {'approved' if approve else 'rejected'}\"\n```\n\n3. The teammate loop checks for approved shutdown and exits.\n\n```python\nif (block.name == \"shutdown_response\"\n        and block.input.get(\"approve\")):\n    should_exit = True\n# ...\nmember[\"status\"] = \"shutdown\" if should_exit else \"idle\"\n```\n\n4. Plan approval follows the identical pattern. The teammate submits\n   a plan, generating a request_id.\n\n```python\nplan_requests = {}\n\nif tool_name == \"plan_approval\":\n    plan_text = args.get(\"plan\", \"\")\n    req_id = str(uuid.uuid4())[:8]\n    plan_requests[req_id] = {\n        \"from\": sender, \"plan\": plan_text,\n        \"status\": \"pending\",\n    }\n    BUS.send(sender, \"lead\", plan_text,\n             \"plan_approval_request\",\n             {\"request_id\": req_id, \"plan\": plan_text})\n    return f\"Plan submitted (request_id={req_id})\"\n```\n\n5. The lead reviews and responds with the same request_id.\n\n```python\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests.get(request_id)\n    if not req:\n        return f\"Error: Unknown request_id '{request_id}'\"\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve,\n              \"feedback\": feedback})\n    return f\"Plan {req['status']} for '{req['from']}'\"\n```\n\n6. Both protocols use the same `plan_approval` tool name with two\n   modes: teammates submit (no request_id), the lead reviews (with\n   request_id).\n\n```python\n# Lead tool dispatch:\n\"plan_approval\": lambda **kw: handle_plan_review(\n    kw[\"request_id\"], kw[\"approve\"],\n    kw.get(\"feedback\", \"\")),\n# Teammate: submit mode (generate request_id)\n```\n\n## Key Code\n\nThe dual protocol handlers (from `agents/s10_team_protocols.py`):\n\n```python\nshutdown_requests = {}\nplan_requests = {}\n\n# -- Shutdown --\ndef handle_shutdown_request(teammate):\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\"\n    }\n    BUS.send(\"lead\", teammate,\n             \"Please shut down gracefully.\",\n             \"shutdown_request\",\n             {\"request_id\": req_id})\n\n# -- Plan Approval --\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests[request_id]\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve})\n\n# Both use the same FSM:\n# pending -> approved | rejected\n# Both correlate by request_id across async inboxes\n```\n\n## What Changed From s09\n\n| Component      | Before (s09)     | After (s10)                  |\n|----------------|------------------|------------------------------|\n| Tools          | 9                | 12 (+shutdown_req/resp +plan)|\n| Shutdown       | Natural exit only| Request-response handshake   |\n| Plan gating    | None             | Submit/review with approval  |\n| Request tracking| None            | Two tracker dicts            |\n| Correlation    | None             | request_id per request       |\n| FSM            | None             | pending -> approved/rejected |\n\n## Design Rationale\n\nThe request_id correlation pattern turns any async interaction into a trackable finite state machine. The same 3-state machine (pending -> approved/rejected) applies to shutdown, plan approval, or any future protocol. This is why one pattern handles multiple protocols -- the FSM does not care what it is approving. The request_id provides correlation across async inboxes where messages may arrive out of order, making the pattern robust to timing variations between agents.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s10_team_protocols.py\n```\n\nExample prompts to try:\n\n1. `Spawn alice as a coder. Then request her shutdown.`\n2. `List teammates to see alice's status after shutdown approval`\n3. `Spawn bob with a risky refactoring task. Review and reject his plan.`\n4. `Spawn charlie, have him submit a plan, then approve it.`\n5. Type `/team` to monitor statuses\n"
  },
  {
    "version": "s11",
    "locale": "en",
    "title": "s11: Autonomous Agents",
    "content": "# s11: Autonomous Agents\n\n> An idle cycle with task board polling lets teammates find and claim work themselves, with identity re-injection after context compression.\n\n## The Problem\n\nIn s09-s10, teammates only work when explicitly told to. The lead must\nspawn each teammate with a specific prompt. If the task board has 10\nunclaimed tasks, the lead must manually assign each one. This does not\nscale.\n\nTrue autonomy means teammates find work themselves. When a teammate\nfinishes its current task, it should scan the task board for unclaimed\nwork, claim a task, and start working -- without any instruction from\nthe lead.\n\nBut autonomous agents face a subtlety: after context compression, the\nagent might forget who it is. If the messages are summarized, the\noriginal system prompt identity (\"you are alice, role: coder\") fades.\nIdentity re-injection solves this by inserting an identity block at the\nstart of compressed contexts.\n\nNote: token estimation here uses characters/4 (rough). The nag threshold of 3 rounds is low for teaching visibility.\n\n## The Solution\n\n```\nTeammate lifecycle with idle cycle:\n\n+-------+\n| spawn |\n+---+---+\n    |\n    v\n+-------+   tool_use     +-------+\n| WORK  | <------------- |  LLM  |\n+---+---+                +-------+\n    |\n    | stop_reason != tool_use\n    | (or idle tool called)\n    v\n+--------+\n|  IDLE  |  poll every 5s for up to 60s\n+---+----+\n    |\n    +---> check inbox --> message? ----------> WORK\n    |\n    +---> scan .tasks/ --> unclaimed? -------> claim -> WORK\n    |\n    +---> 60s timeout ----------------------> SHUTDOWN\n\nIdentity re-injection after compression:\n  if len(messages) <= 3:\n    messages.insert(0, identity_block)\n    \"You are 'alice', role: coder, team: my-team\"\n```\n\n## How It Works\n\n1. The teammate loop has two phases: WORK and IDLE. WORK runs the\n   standard agent loop. When the LLM stops calling tools (or calls\n   the `idle` tool), the teammate enters the IDLE phase.\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # -- WORK PHASE --\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        for _ in range(50):\n            inbox = BUS.read_inbox(name)\n            for msg in inbox:\n                if msg.get(\"type\") == \"shutdown_request\":\n                    self._set_status(name, \"shutdown\")\n                    return\n                messages.append(...)\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            # execute tools...\n            if idle_requested:\n                break\n\n        # -- IDLE PHASE --\n        self._set_status(name, \"idle\")\n        resume = self._idle_poll(name, messages)\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n2. The idle phase polls the inbox and task board in a loop.\n\n```python\ndef _idle_poll(self, name, messages):\n    polls = IDLE_TIMEOUT // POLL_INTERVAL  # 60s / 5s = 12\n    for _ in range(polls):\n        time.sleep(POLL_INTERVAL)\n        # Check inbox for new messages\n        inbox = BUS.read_inbox(name)\n        if inbox:\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            return True\n        # Scan task board for unclaimed tasks\n        unclaimed = scan_unclaimed_tasks()\n        if unclaimed:\n            task = unclaimed[0]\n            claim_task(task[\"id\"], name)\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<auto-claimed>Task #{task['id']}: \"\n                           f\"{task['subject']}</auto-claimed>\"})\n            return True\n    return False  # timeout -> shutdown\n```\n\n3. Task board scanning looks for pending, unowned, unblocked tasks.\n\n```python\ndef scan_unclaimed_tasks() -> list:\n    TASKS_DIR.mkdir(exist_ok=True)\n    unclaimed = []\n    for f in sorted(TASKS_DIR.glob(\"task_*.json\")):\n        task = json.loads(f.read_text())\n        if (task.get(\"status\") == \"pending\"\n                and not task.get(\"owner\")\n                and not task.get(\"blockedBy\")):\n            unclaimed.append(task)\n    return unclaimed\n\ndef claim_task(task_id: int, owner: str):\n    path = TASKS_DIR / f\"task_{task_id}.json\"\n    task = json.loads(path.read_text())\n    task[\"status\"] = \"in_progress\"\n    task[\"owner\"] = owner\n    path.write_text(json.dumps(task, indent=2))\n```\n\n4. Identity re-injection inserts an identity block when the context\n   is too short, indicating compression has occurred.\n\n```python\ndef make_identity_block(name, role, team_name):\n    return {\"role\": \"user\",\n            \"content\": f\"<identity>You are '{name}', \"\n                       f\"role: {role}, team: {team_name}. \"\n                       f\"Continue your work.</identity>\"}\n\n# Before resuming work after idle:\nif len(messages) <= 3:\n    messages.insert(0, make_identity_block(\n        name, role, team_name))\n    messages.insert(1, {\"role\": \"assistant\",\n        \"content\": f\"I am {name}. Continuing.\"})\n```\n\n5. The `idle` tool lets the teammate explicitly signal it has no more\n   work, entering the idle polling phase early.\n\n```python\n{\"name\": \"idle\",\n \"description\": \"Signal that you have no more work. \"\n                \"Enters idle polling phase.\",\n \"input_schema\": {\"type\": \"object\", \"properties\": {}}},\n```\n\n## Key Code\n\nThe autonomous loop (from `agents/s11_autonomous_agents.py`):\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # WORK PHASE\n        for _ in range(50):\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            for block in response.content:\n                if block.name == \"idle\":\n                    idle_requested = True\n            if idle_requested:\n                break\n\n        # IDLE PHASE\n        self._set_status(name, \"idle\")\n        for _ in range(IDLE_TIMEOUT // POLL_INTERVAL):\n            time.sleep(POLL_INTERVAL)\n            inbox = BUS.read_inbox(name)\n            if inbox: resume = True; break\n            unclaimed = scan_unclaimed_tasks()\n            if unclaimed:\n                claim_task(unclaimed[0][\"id\"], name)\n                resume = True; break\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n## What Changed From s10\n\n| Component      | Before (s10)     | After (s11)                |\n|----------------|------------------|----------------------------|\n| Tools          | 12               | 14 (+idle, +claim_task)    |\n| Autonomy       | Lead-directed    | Self-organizing            |\n| Idle phase     | None             | Poll inbox + task board    |\n| Task claiming  | Manual only      | Auto-claim unclaimed tasks |\n| Identity       | System prompt    | + re-injection after compress|\n| Timeout        | None             | 60s idle -> auto shutdown  |\n\n## Design Rationale\n\nPolling + timeout makes agents self-organizing without a central coordinator. Each agent independently polls the task board, claims unclaimed work, and returns to idle when done. The timeout triggers the poll cycle, and if no work appears within the window, the agent shuts itself down. This is the same pattern as work-stealing thread pools -- distributed, no single point of failure. Identity re-injection after compression ensures agents maintain their role even when conversation history is summarized away.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s11_autonomous_agents.py\n```\n\nExample prompts to try:\n\n1. `Create 3 tasks on the board, then spawn alice and bob. Watch them auto-claim.`\n2. `Spawn a coder teammate and let it find work from the task board itself`\n3. `Create tasks with dependencies. Watch teammates respect the blocked order.`\n4. Type `/tasks` to see the task board with owners\n5. Type `/team` to monitor who is working vs idle\n"
  },
  {
    "version": "s12",
    "locale": "en",
    "title": "s12: Worktree + Task Isolation",
    "content": "# s12: Worktree + Task Isolation\n\n> Isolate by directory, coordinate by task ID -- tasks are the control plane, worktrees are the execution plane, and an event stream makes every lifecycle step observable.\n\n## The Problem\n\nBy s11, agents can claim and complete tasks autonomously. But every task runs in one shared directory. Ask two agents to refactor different modules at the same time and you hit three failure modes:\n\nAgent A edits `auth.py`. Agent B edits `auth.py`. Neither knows the other touched it. Unstaged changes collide, task status says \"in_progress\" but the directory is a mess, and when something breaks there is no way to roll back one agent's work without destroying the other's. The task board tracks _what to do_ but has no opinion about _where to do it_.\n\nThe fix is to separate the two concerns. Tasks manage goals. Worktrees manage execution context. Bind them by task ID, and each agent gets its own directory, its own branch, and a clean teardown path.\n\n## The Solution\n\n```\nControl Plane (.tasks/)              Execution Plane (.worktrees/)\n+---------------------------+        +---------------------------+\n| task_1.json               |        | index.json                |\n|   id: 1                   |        |   name: \"auth-refactor\"   |\n|   subject: \"Auth refactor\"|  bind  |   path: \".worktrees/...\"  |\n|   status: \"in_progress\"   | <----> |   branch: \"wt/auth-...\"   |\n|   worktree: \"auth-refactor\"|       |   task_id: 1              |\n+---------------------------+        |   status: \"active\"        |\n                                     +---------------------------+\n| task_2.json               |        |                           |\n|   id: 2                   |  bind  |   name: \"ui-login\"        |\n|   subject: \"Login page\"   | <----> |   task_id: 2              |\n|   worktree: \"ui-login\"    |        |   status: \"active\"        |\n+---------------------------+        +---------------------------+\n                                               |\n                                     +---------------------------+\n                                     | events.jsonl (append-only)|\n                                     | worktree.create.before    |\n                                     | worktree.create.after     |\n                                     | worktree.remove.after     |\n                                     | task.completed            |\n                                     +---------------------------+\n```\n\nThree state layers make this work:\n\n1. **Control plane** (`.tasks/task_*.json`) -- what is assigned, in progress, or done. Key fields: `id`, `subject`, `status`, `owner`, `worktree`.\n2. **Execution plane** (`.worktrees/index.json`) -- where commands run and whether the workspace is still valid. Key fields: `name`, `path`, `branch`, `task_id`, `status`.\n3. **Runtime state** (in-memory) -- per-turn execution continuity: `current_task`, `current_worktree`, `tool_result`, `error`.\n\n## How It Works\n\nThe lifecycle has five steps. Each step is a tool call.\n\n1. **Create a task.** Persist the goal first. The task starts as `pending` with an empty `worktree` field.\n\n```python\ntask = {\n    \"id\": self._next_id,\n    \"subject\": subject,\n    \"status\": \"pending\",\n    \"owner\": \"\",\n    \"worktree\": \"\",\n}\nself._save(task)\n```\n\n2. **Create a worktree.** Allocate an isolated directory and branch. If you pass `task_id`, the task auto-advances to `in_progress` and the binding is written to both sides.\n\n```python\nself._run_git([\"worktree\", \"add\", \"-b\", branch, str(path), base_ref])\n\nentry = {\n    \"name\": name,\n    \"path\": str(path),\n    \"branch\": branch,\n    \"task_id\": task_id,\n    \"status\": \"active\",\n}\nidx[\"worktrees\"].append(entry)\nself._save_index(idx)\n\nif task_id is not None:\n    self.tasks.bind_worktree(task_id, name)\n```\n\n3. **Run commands in the worktree.** `worktree_run` sets `cwd` to the worktree path. Edits happen in the isolated directory, not the shared workspace.\n\n```python\nr = subprocess.run(\n    command,\n    shell=True,\n    cwd=path,\n    capture_output=True,\n    text=True,\n    timeout=300,\n)\n```\n\n4. **Observe.** `worktree_status` shows git state inside the isolated context. `worktree_events` queries the append-only event stream.\n\n5. **Close out.** Two choices:\n   - `worktree_keep(name)` -- preserve the directory, mark lifecycle as `kept`.\n   - `worktree_remove(name, complete_task=True)` -- remove the directory, complete the bound task, unbind, and emit `task.completed`. This is the closeout pattern: one call handles teardown and task completion together.\n\n## State Machines\n\n```\nTask:     pending -------> in_progress -------> completed\n               (worktree_create          (worktree_remove\n                with task_id)        with complete_task=true)\n\nWorktree: absent --------> active -----------> removed | kept\n               (worktree_create)         (worktree_remove | worktree_keep)\n```\n\n## Key Code\n\nThe closeout pattern -- teardown + task completion in one operation (from `agents/s12_worktree_task_isolation.py`):\n\n```python\ndef remove(self, name: str, force: bool = False, complete_task: bool = False) -> str:\n    wt = self._find(name)\n    if not wt:\n        return f\"Error: Unknown worktree '{name}'\"\n\n    self.events.emit(\n        \"worktree.remove.before\",\n        task={\"id\": wt.get(\"task_id\")} if wt.get(\"task_id\") is not None else {},\n        worktree={\"name\": name, \"path\": wt.get(\"path\")},\n    )\n    try:\n        args = [\"worktree\", \"remove\"]\n        if force:\n            args.append(\"--force\")\n        args.append(wt[\"path\"])\n        self._run_git(args)\n\n        if complete_task and wt.get(\"task_id\") is not None:\n            task_id = wt[\"task_id\"]\n            self.tasks.update(task_id, status=\"completed\")\n            self.tasks.unbind_worktree(task_id)\n            self.events.emit(\"task.completed\", task={\n                \"id\": task_id, \"status\": \"completed\",\n            }, worktree={\"name\": name})\n\n        idx = self._load_index()\n        for item in idx.get(\"worktrees\", []):\n            if item.get(\"name\") == name:\n                item[\"status\"] = \"removed\"\n                item[\"removed_at\"] = time.time()\n        self._save_index(idx)\n\n        self.events.emit(\n            \"worktree.remove.after\",\n            task={\"id\": wt.get(\"task_id\")} if wt.get(\"task_id\") is not None else {},\n            worktree={\"name\": name, \"path\": wt.get(\"path\"), \"status\": \"removed\"},\n        )\n        return f\"Removed worktree '{name}'\"\n    except Exception as e:\n        self.events.emit(\n            \"worktree.remove.failed\",\n            worktree={\"name\": name},\n            error=str(e),\n        )\n        raise\n```\n\nThe task-side binding (from `agents/s12_worktree_task_isolation.py`):\n\n```python\ndef bind_worktree(self, task_id: int, worktree: str, owner: str = \"\") -> str:\n    task = self._load(task_id)\n    task[\"worktree\"] = worktree\n    if task[\"status\"] == \"pending\":\n        task[\"status\"] = \"in_progress\"\n    task[\"updated_at\"] = time.time()\n    self._save(task)\n```\n\nThe dispatch map wiring all tools together:\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":               lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":          lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\":         lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":          lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"], kw[\"new_text\"]),\n    \"task_create\":        lambda **kw: TASKS.create(kw[\"subject\"], kw.get(\"description\", \"\")),\n    \"task_list\":          lambda **kw: TASKS.list_all(),\n    \"task_get\":           lambda **kw: TASKS.get(kw[\"task_id\"]),\n    \"task_update\":        lambda **kw: TASKS.update(kw[\"task_id\"], kw.get(\"status\"), kw.get(\"owner\")),\n    \"task_bind_worktree\": lambda **kw: TASKS.bind_worktree(kw[\"task_id\"], kw[\"worktree\"]),\n    \"worktree_create\":    lambda **kw: WORKTREES.create(kw[\"name\"], kw.get(\"task_id\")),\n    \"worktree_list\":      lambda **kw: WORKTREES.list_all(),\n    \"worktree_status\":    lambda **kw: WORKTREES.status(kw[\"name\"]),\n    \"worktree_run\":       lambda **kw: WORKTREES.run(kw[\"name\"], kw[\"command\"]),\n    \"worktree_keep\":      lambda **kw: WORKTREES.keep(kw[\"name\"]),\n    \"worktree_remove\":    lambda **kw: WORKTREES.remove(kw[\"name\"], kw.get(\"force\", False), kw.get(\"complete_task\", False)),\n    \"worktree_events\":    lambda **kw: EVENTS.list_recent(kw.get(\"limit\", 20)),\n}\n```\n\n## Event Stream\n\nEvery lifecycle transition emits a before/after/failed triplet to `.worktrees/events.jsonl`. This is an append-only log, not a replacement for task/worktree state files.\n\nEvents emitted:\n\n- `worktree.create.before` / `worktree.create.after` / `worktree.create.failed`\n- `worktree.remove.before` / `worktree.remove.after` / `worktree.remove.failed`\n- `worktree.keep`\n- `task.completed` (when `complete_task=true` succeeds)\n\nPayload shape:\n\n```json\n{\n  \"event\": \"worktree.remove.after\",\n  \"task\": {\"id\": 7, \"status\": \"completed\"},\n  \"worktree\": {\"name\": \"auth-refactor\", \"path\": \"...\", \"status\": \"removed\"},\n  \"ts\": 1730000000\n}\n```\n\nThis gives you three things: policy decoupling (audit and notifications stay outside the core flow), failure compensation (`*.failed` records mark partial transitions), and queryability (`worktree_events` tool reads the log directly).\n\n## What Changed From s11\n\n| Component          | Before (s11)               | After (s12)                                  |\n|--------------------|----------------------------|----------------------------------------------|\n| Coordination state | Task board (`owner/status`) | Task board + explicit `worktree` binding     |\n| Execution scope    | Shared directory            | Task-scoped isolated directory               |\n| Recoverability     | Task status only            | Task status + worktree index                 |\n| Teardown semantics | Task completion             | Task completion + explicit keep/remove       |\n| Lifecycle visibility | Implicit in logs          | Explicit events in `.worktrees/events.jsonl` |\n\n## Design Rationale\n\nSeparating control plane from execution plane means you can reason about _what to do_ and _where to do it_ independently. A task can exist without a worktree (planning phase). A worktree can exist without a task (ad-hoc exploration). Binding them is an explicit action that writes state to both sides. This composability is the point -- it keeps the system recoverable after crashes. After an interruption, state reconstructs from `.tasks/` + `.worktrees/index.json` on disk. Volatile in-memory session state downgrades into explicit, durable file state. The event stream adds observability without coupling side effects into the critical path: auditing, notifications, and quota checks consume events rather than intercepting state writes.\n\n## Try It\n\n```sh\ncd learn-claude-code\npython agents/s12_worktree_task_isolation.py\n```\n\nExample prompts to try:\n\n1. `Create tasks for backend auth and frontend login page, then list tasks.`\n2. `Create worktree \"auth-refactor\" for task 1, create worktree \"ui-login\", then bind task 2 to \"ui-login\".`\n3. `Run \"git status --short\" in worktree \"auth-refactor\".`\n4. `Keep worktree \"ui-login\", then list worktrees and inspect worktree events.`\n5. `Remove worktree \"auth-refactor\" with complete_task=true, then list tasks/worktrees/events.`\n"
  },
  {
    "version": "s01",
    "locale": "zh",
    "title": "s01: Agent Loop ()",
    "content": "# s01: Agent Loop ()\n\n> AI  while  -- , \n\n## \n\n? ****-\n\n agent loop, Agent loop : , , ,  --  \"\"\n\n: \" hello  Python \"  (1) , (2) , (3) , \n\n## \n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> |  Tool   |\n|  prompt  |      |       |      | execute |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                      (loop continues)\n\nThe loop terminates when stop_reason != \"tool_use\".\nThat single condition is the entire control flow.\n```\n\n## \n\n1.  prompt, \n\n```python\nhistory.append({\"role\": \"user\", \"content\": query})\n```\n\n2.  LLM\n\n```python\nresponse = client.messages.create(\n    model=MODEL, system=SYSTEM, messages=messages,\n    tools=TOOLS, max_tokens=8000,\n)\n```\n\n3. \n\n```python\nmessages.append({\"role\": \"assistant\", \"content\": response.content})\n```\n\n4.  stop_reason, , \n\n```python\nif response.stop_reason != \"tool_use\":\n    return\n```\n\n5.  tool_use ,  ( bash) \n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        output = run_bash(block.input[\"command\"])\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n6.  user , \n\n```python\nmessages.append({\"role\": \"user\", \"content\": results})\n```\n\n## \n\n --  30 \n( `agents/s01_agent_loop.py`,  66-86 ):\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                output = run_bash(block.input[\"command\"])\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## \n\n 1  -- \n\n|           |        |                            |\n|---------------|------------|--------------------------------|\n| Agent loop    | ()       | `while True` + stop_reason     |\n| Tools         | ()       | `bash` ()              |\n| Messages      | ()       |                  |\n| Control flow  | ()       | `stop_reason != \"tool_use\"`    |\n\n## \n\n LLM token , : ,  (`stop_reason != \"tool_use\"`) , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s01_agent_loop.py\n```\n\n:\n\n1. `Create a file called hello.py that prints \"Hello, World!\"`\n2. `List all Python files in this directory`\n3. `What is the current git branch?`\n4. `Create a directory called test_output and write 3 files in it`\n"
  },
  {
    "version": "s02",
    "locale": "zh",
    "title": "s02: Tools ()",
    "content": "# s02: Tools ()\n\n>  (dispatch map)  -- \n\n## \n\n `bash` ,  shell: `cat` `sed`  token  shell , \n\n, bash  bash  shell  `read_file`  `write_file`, , , \n\n: s01 , ,  dispatch map \n\n## \n\n```\n+----------+      +-------+      +------------------+\n|   User   | ---> |  LLM  | ---> | Tool Dispatch    |\n|  prompt  |      |       |      | {                |\n+----------+      +---+---+      |   bash: run_bash |\n                      ^          |   read: run_read |\n                      |          |   write: run_wr  |\n                      +----------+   edit: run_edit |\n                      tool_result| }                |\n                                 +------------------+\n\nThe dispatch map is a dict: {tool_name: handler_function}\nOne lookup replaces any if/elif chain.\n```\n\n## \n\n1.  input_schema , \n\n```python\ndef run_read(path: str, limit: int = None) -> str:\n    text = safe_path(path).read_text()\n    lines = text.splitlines()\n    if limit and limit < len(lines):\n        lines = lines[:limit]\n    return \"\\n\".join(lines)[:50000]\n```\n\n2.  dispatch map, \n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n```\n\n3.  agent loop , , \n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        handler = TOOL_HANDLERS.get(block.name)\n        output = handler(**block.input)\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n4. \n\n```python\ndef safe_path(p: str) -> Path:\n    path = (WORKDIR / p).resolve()\n    if not path.is_relative_to(WORKDIR):\n        raise ValueError(f\"Path escapes workspace: {p}\")\n    return path\n```\n\n## \n\ndispatch  ( `agents/s02_tool_use.py`,  93-129 ):\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input) if handler \\\n                    else f\"Unknown tool: {block.name}\"\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n##  s01 \n\n|            |  (s01)         |  (s02)                     |\n|----------------|--------------------|----------------------------|\n| Tools          | 1 ( bash)        | 4 (bash, read, write, edit)|\n| Dispatch       |  bash    | `TOOL_HANDLERS`        |\n|        |                  | `safe_path()`          |\n| Agent loop     |                |                        |\n\n## \n\ndispatch map  --  schema  ( vs ) ,  dispatch map , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s02_tool_use.py\n```\n\n:\n\n1. `Read the file requirements.txt`\n2. `Create a file called greet.py with a greet(name) function`\n3. `Edit greet.py to add a docstring to the function`\n4. `Read greet.py to verify the edit worked`\n5. `Run the greet function with bash: python -c \"from greet import greet; greet('World')\"`\n"
  },
  {
    "version": "s03",
    "locale": "zh",
    "title": "s03: TodoWrite ()",
    "content": "# s03: TodoWrite ()\n\n> TodoManager ,  nag reminder \n\n## \n\n, , \n\n \"\" -- ,  10  1-3 , ,  4-10 \n\n:  TodoManager,  in_progress,  completednag reminder  3 \n\n: nag  3 ,  s07 ,  Task ; TodoWrite \n\n## \n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> | Tools   |\n|  prompt  |      |       |      | + todo  |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                            |\n                +-----------+-----------+\n                | TodoManager state     |\n                | [ ] task A            |\n                | [>] task B  <- doing  |\n                | [x] task C            |\n                +-----------------------+\n                            |\n                if rounds_since_todo >= 3:\n                  inject <reminder> into tool_result\n```\n\n## \n\n1. TodoManager  `in_progress` \n\n```python\nclass TodoManager:\n    def __init__(self):\n        self.items = []\n\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one task can be in_progress\")\n        self.items = validated\n        return self.render()\n```\n\n2. `todo`  dispatch map \n\n```python\nTOOL_HANDLERS = {\n    \"bash\":  lambda **kw: run_bash(kw[\"command\"]),\n    # ...other tools...\n    \"todo\":  lambda **kw: TODO.update(kw[\"items\"]),\n}\n```\n\n3. nag reminder  3  `todo` ,  tool_result  `<reminder>` \n\n```python\ndef agent_loop(messages: list):\n    rounds_since_todo = 0\n    while True:\n        if rounds_since_todo >= 3 and messages:\n            last = messages[-1]\n            if (last[\"role\"] == \"user\"\n                    and isinstance(last.get(\"content\"), list)):\n                last[\"content\"].insert(0, {\n                    \"type\": \"text\",\n                    \"text\": \"<reminder>Update your todos.</reminder>\",\n                })\n        # ... rest of loop ...\n        rounds_since_todo = 0 if used_todo else rounds_since_todo + 1\n```\n\n4.  todo \n\n```python\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nUse the todo tool to plan multi-step tasks.\nMark in_progress before starting, completed when done.\nPrefer tools over prose.\"\"\"\n```\n\n## \n\nTodoManager  nag  ( `agents/s03_todo_write.py`,\n 51-85  158-187 ):\n\n```python\nclass TodoManager:\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one in_progress\")\n        self.items = validated\n        return self.render()\n\n# In agent_loop:\nif rounds_since_todo >= 3:\n    last[\"content\"].insert(0, {\n        \"type\": \"text\",\n        \"text\": \"<reminder>Update your todos.</reminder>\",\n    })\n```\n\n##  s02 \n\n|            |  (s02)       |  (s03)                   |\n|----------------|------------------|--------------------------|\n| Tools          | 4                | 5 (+todo)                |\n|            |                |  TodoManager     |\n| Nag        |                | 3  `<reminder>`  |\n| Agent loop     |          | + rounds_since_todo |\n\n## \n\n, nag  -- , , \" in_progress\" , , , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s03_todo_write.py\n```\n\n:\n\n1. `Refactor the file hello.py: add type hints, docstrings, and a main guard`\n2. `Create a Python package with __init__.py, utils.py, and tests/test_utils.py`\n3. `Review all Python files and fix any style issues`\n"
  },
  {
    "version": "s04",
    "locale": "zh",
    "title": "s04: Subagent ()",
    "content": "# s04: Subagent ()\n\n> , ,  -- \n\n## \n\n,  bash 20-30 ,  500 ,  500 \n\n\"?\"  5 ,  5  -- : \"pytest,  conftest.py \"\n\n,  fresh `messages[]` :  `messages=[]` , \n\n## \n\n```\nParent agent                     Subagent\n+------------------+             +------------------+\n| messages=[...]   |             | messages=[]      | <-- fresh\n|                  |  dispatch   |                  |\n| tool: task       | ---------->| while tool_use:  |\n|   prompt=\"...\"   |            |   call tools     |\n|                  |  summary   |   append results |\n|   result = \"...\" | <--------- | return last text |\n+------------------+             +------------------+\n          |\nParent context stays clean.\nSubagent context is discarded.\n```\n\n## \n\n1.  `task`  `task`  ()\n\n```python\nPARENT_TOOLS = CHILD_TOOLS + [\n    {\"name\": \"task\",\n     \"description\": \"Spawn a subagent with fresh context.\",\n     \"input_schema\": {\n         \"type\": \"object\",\n         \"properties\": {\n             \"prompt\": {\"type\": \"string\"},\n             \"description\": {\"type\": \"string\"},\n         },\n         \"required\": [\"prompt\"],\n     }},\n]\n```\n\n2. ,  prompt\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):  # safety limit\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\n            \"role\": \"assistant\", \"content\": response.content\n        })\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n```\n\n3.  30+ \n\n```python\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n4.  tool_result \n\n```python\nif block.name == \"task\":\n    output = run_subagent(block.input[\"prompt\"])\nresults.append({\n    \"type\": \"tool_result\",\n    \"tool_use_id\": block.id,\n    \"content\": str(output),\n})\n```\n\n## \n\n ( `agents/s04_subagent.py`,  110-128 ):\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\"role\": \"assistant\",\n                             \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input)\n                results.append({\"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": str(output)[:50000]})\n        sub_messages.append({\"role\": \"user\", \"content\": results})\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n##  s03 \n\n|            |  (s03)       |  (s04)                    |\n|----------------|------------------|---------------------------|\n| Tools          | 5                | 5 () + task ()  |\n|          |          |  +                |\n| Subagent       |                | `run_subagent()`      |\n|          |            |                 |\n\n## \n\n, fresh `messages[]`  `messages[]`  -- , ,  () , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s04_subagent.py\n```\n\n:\n\n1. `Use a subtask to find what testing framework this project uses`\n2. `Delegate: read all .py files and summarize what each one does`\n3. `Use a task to create a new module, then verify it from here`\n"
  },
  {
    "version": "s05",
    "locale": "zh",
    "title": "s05: Skills ()",
    "content": "# s05: Skills ()\n\n> :  (),  tool_result \n\n## \n\n: git  -- , \n\n 10 ,  2000 token,  20,000 token , ,  git \n\n:  ( 100 token) `load_skill` ,  tool_result  (),  ()\n\n## \n\n```\nSystem prompt (Layer 1 -- always present):\n+--------------------------------------+\n| You are a coding agent.              |\n| Skills available:                    |\n|   - git: Git workflow helpers        |  ~100 tokens/skill\n|   - test: Testing best practices     |\n+--------------------------------------+\n\nWhen model calls load_skill(\"git\"):\n+--------------------------------------+\n| tool_result (Layer 2 -- on demand):  |\n| <skill name=\"git\">                   |\n|   Full git workflow instructions...  |  ~2000 tokens\n|   Step 1: ...                        |\n|   Step 2: ...                        |\n| </skill>                             |\n+--------------------------------------+\n```\n\n## \n\n1.  Markdown  `.skills/` ,  YAML frontmatter\n\n```\n.skills/\n  git.md       # ---\\n description: Git workflow\\n ---\\n ...\n  test.md      # ---\\n description: Testing patterns\\n ---\\n ...\n```\n\n2. SkillLoader  frontmatter, \n\n```python\nclass SkillLoader:\n    def _parse_frontmatter(self, text: str) -> tuple:\n        match = re.match(\n            r\"^---\\n(.*?)\\n---\\n(.*)\", text, re.DOTALL\n        )\n        if not match:\n            return {}, text\n        meta = {}\n        for line in match.group(1).strip().splitlines():\n            if \":\" in line:\n                key, val = line.split(\":\", 1)\n                meta[key.strip()] = val.strip()\n        return meta, match.group(2).strip()\n```\n\n3. : `get_descriptions()` , \n\n```python\ndef get_descriptions(self) -> str:\n    lines = []\n    for name, skill in self.skills.items():\n        desc = skill[\"meta\"].get(\"description\", \"No description\")\n        lines.append(f\"  - {name}: {desc}\")\n    return \"\\n\".join(lines)\n\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nSkills available:\n{SKILL_LOADER.get_descriptions()}\"\"\"\n```\n\n4. : `get_content()`  `<skill>` \n\n```python\ndef get_content(self, name: str) -> str:\n    skill = self.skills.get(name)\n    if not skill:\n        return f\"Error: Unknown skill '{name}'.\"\n    return f\"<skill name=\\\"{name}\\\">\\n{skill['body']}\\n</skill>\"\n```\n\n5. `load_skill`  dispatch map \n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"load_skill\": lambda **kw: SKILL_LOADER.get_content(kw[\"name\"]),\n}\n```\n\n## \n\nSkillLoader  ( `agents/s05_skill_loading.py`,  51-97 ):\n\n```python\nclass SkillLoader:\n    def __init__(self, skills_dir: Path):\n        self.skills = {}\n        for f in sorted(skills_dir.glob(\"*.md\")):\n            text = f.read_text()\n            meta, body = self._parse_frontmatter(text)\n            self.skills[f.stem] = {\n                \"meta\": meta, \"body\": body\n            }\n\n    def get_descriptions(self) -> str:\n        lines = []\n        for name, skill in self.skills.items():\n            desc = skill[\"meta\"].get(\"description\", \"\")\n            lines.append(f\"  - {name}: {desc}\")\n        return \"\\n\".join(lines)\n\n    def get_content(self, name: str) -> str:\n        skill = self.skills.get(name)\n        if not skill:\n            return f\"Error: Unknown skill '{name}'.\"\n        return (f\"<skill name=\\\"{name}\\\">\\n\"\n                f\"{skill['body']}\\n</skill>\")\n```\n\n##  s04 \n\n|            |  (s04)       |  (s05)                     |\n|----------------|------------------|----------------------------|\n| Tools          | 5 ( + task)  | 5 ( + load_skill)      |\n|        |        | +              |\n|          |                | .skills/*.md           |\n|        |                |  ( + result)   |\n\n## \n\n token ()  120 token ()  tool_result :  ()  ()\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s05_skill_loading.py\n```\n\n:\n\n1. `What skills are available?`\n2. `Load the agent-builder skill and follow its instructions`\n3. `I need to do a code review -- load the relevant skill first`\n4. `Build an MCP server using the mcp-builder skill`\n"
  },
  {
    "version": "s06",
    "locale": "zh",
    "title": "s06: Compact ()",
    "content": "# s06: Compact ()\n\n> : , token , \n\n## \n\n, , API , : , \n\n200,000 token ,  `read_file`  1000  4000 token 30  20  bash ,  100,000+ token , \n\n:\n (micro-compact) \n (auto-compact)  token \n (manual compact) \n\n:  token  /4  tokenizer \n\n## \n\n```\nEvery turn:\n+------------------+\n| Tool call result |\n+------------------+\n        |\n        v\n[Layer 1: micro_compact]        (silent, every turn)\n  Replace tool_result > 3 turns old\n  with \"[Previous: used {tool_name}]\"\n        |\n        v\n[Check: tokens > 50000?]\n   |               |\n   no              yes\n   |               |\n   v               v\ncontinue    [Layer 2: auto_compact]\n              Save transcript to .transcripts/\n              LLM summarizes conversation.\n              Replace all messages with [summary].\n                    |\n                    v\n            [Layer 3: compact tool]\n              Model calls compact explicitly.\n              Same summarization as auto_compact.\n```\n\n## \n\n1. ** -- micro_compact**:  LLM ,  3  tool_result , \n\n```python\ndef micro_compact(messages: list) -> list:\n    tool_results = []\n    for i, msg in enumerate(messages):\n        if msg[\"role\"] == \"user\" and isinstance(msg.get(\"content\"), list):\n            for j, part in enumerate(msg[\"content\"]):\n                if isinstance(part, dict) and part.get(\"type\") == \"tool_result\":\n                    tool_results.append((i, j, part))\n    if len(tool_results) <= KEEP_RECENT:\n        return messages\n    to_clear = tool_results[:-KEEP_RECENT]\n    for _, _, part in to_clear:\n        if len(part.get(\"content\", \"\")) > 100:\n            tool_id = part.get(\"tool_use_id\", \"\")\n            tool_name = tool_name_map.get(tool_id, \"unknown\")\n            part[\"content\"] = f\"[Previous: used {tool_name}]\"\n    return messages\n```\n\n2. ** -- auto_compact**:  token  50,000 ,  LLM \n\n```python\ndef auto_compact(messages: list) -> list:\n    TRANSCRIPT_DIR.mkdir(exist_ok=True)\n    transcript_path = TRANSCRIPT_DIR / f\"transcript_{int(time.time())}.jsonl\"\n    with open(transcript_path, \"w\") as f:\n        for msg in messages:\n            f.write(json.dumps(msg, default=str) + \"\\n\")\n    response = client.messages.create(\n        model=MODEL,\n        messages=[{\"role\": \"user\", \"content\":\n            \"Summarize this conversation for continuity...\"\n            + json.dumps(messages, default=str)[:80000]}],\n        max_tokens=2000,\n    )\n    summary = response.content[0].text\n    return [\n        {\"role\": \"user\", \"content\": f\"[Compressed]\\n\\n{summary}\"},\n        {\"role\": \"assistant\", \"content\": \"Understood. Continuing.\"},\n    ]\n```\n\n3. ** -- manual compact**: `compact` \n\n```python\nif manual_compact:\n    messages[:] = auto_compact(messages)\n```\n\n4. Agent loop \n\n```python\ndef agent_loop(messages: list):\n    while True:\n        micro_compact(messages)\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)\n        response = client.messages.create(...)\n        # ... tool execution ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)\n```\n\n## \n\n ( `agents/s06_context_compact.py`,  67-93  189-223 ):\n\n```python\nTHRESHOLD = 50000\nKEEP_RECENT = 3\n\ndef micro_compact(messages):\n    # Replace old tool results with placeholders\n    ...\n\ndef auto_compact(messages):\n    # Save transcript, LLM summarize, replace messages\n    ...\n\ndef agent_loop(messages):\n    while True:\n        micro_compact(messages)          # Layer 1\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)  # Layer 2\n        response = client.messages.create(...)\n        # ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)  # Layer 3\n```\n\n##  s05 \n\n|            |  (s05)       |  (s06)                     |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 5 ( + compact)         |\n|      |                |                    |\n| Micro-compact  |                |  ->            |\n| Auto-compact   |                | token              |\n| Manual compact |                | `compact`              |\n| Transcripts    |                |  .transcripts/       |\n\n## \n\n, : micro-compact (), auto-compact ( LLM ), manual compact () -- , , , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s06_context_compact.py\n```\n\n:\n\n1. `Read every Python file in the agents/ directory one by one`\n   ( micro-compact )\n2. `Keep reading files until compression triggers automatically`\n3. `Use the compact tool to manually compress the conversation`\n"
  },
  {
    "version": "s07",
    "locale": "zh",
    "title": "s07: Tasks ()",
    "content": "# s07: Tasks ()\n\n>  JSON , , , \n\n## \n\n ( s03  TodoManager)  (s06) auto_compact , , \n\n s06  s07 : TodoManager ; \n\n,  (s09+) , \n\n JSON  `.tasks/` ,  ID 1  2  ( 2  `blockedBy: [1]`), \n\n## Task vs Todo: \n\n s07 , Task Todo \n\n## \n\n|  |  |  |\n|---|---|---|\n|  | Todo |  |\n|  | Task |  |\n|  | Task |  |\n\n## \n\n```\n.tasks/\n  task_1.json  {\"id\":1, \"status\":\"completed\", ...}\n  task_2.json  {\"id\":2, \"blockedBy\":[1], \"status\":\"pending\"}\n  task_3.json  {\"id\":3, \"blockedBy\":[2], \"status\":\"pending\"}\n\nDependency resolution:\n+----------+     +----------+     +----------+\n| task 1   | --> | task 2   | --> | task 3   |\n| complete |     | blocked  |     | blocked  |\n+----------+     +----------+     +----------+\n     |                ^\n     +--- completing task 1 removes it from\n          task 2's blockedBy list\n```\n\n## \n\n1. TaskManager  CRUD  JSON \n\n```python\nclass TaskManager:\n    def create(self, subject: str, description: str = \"\") -> str:\n        task = {\n            \"id\": self._next_id,\n            \"subject\": subject,\n            \"description\": description,\n            \"status\": \"pending\",\n            \"blockedBy\": [],\n            \"blocks\": [],\n            \"owner\": \"\",\n        }\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n```\n\n2.  completed , `_clear_dependency`  ID  `blockedBy` \n\n```python\ndef _clear_dependency(self, completed_id: int):\n    for f in self.dir.glob(\"task_*.json\"):\n        task = json.loads(f.read_text())\n        if completed_id in task.get(\"blockedBy\", []):\n            task[\"blockedBy\"].remove(completed_id)\n            self._save(task)\n```\n\n3. `update` \n\n```python\ndef update(self, task_id, status=None,\n           add_blocked_by=None, add_blocks=None):\n    task = self._load(task_id)\n    if status:\n        task[\"status\"] = status\n        if status == \"completed\":\n            self._clear_dependency(task_id)\n    if add_blocks:\n        task[\"blocks\"] = list(set(task[\"blocks\"] + add_blocks))\n        for blocked_id in add_blocks:\n            blocked = self._load(blocked_id)\n            if task_id not in blocked[\"blockedBy\"]:\n                blocked[\"blockedBy\"].append(task_id)\n                self._save(blocked)\n    self._save(task)\n```\n\n4.  dispatch map\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"task_create\": lambda **kw: TASKS.create(kw[\"subject\"]),\n    \"task_update\": lambda **kw: TASKS.update(kw[\"task_id\"],\n                       kw.get(\"status\")),\n    \"task_list\":   lambda **kw: TASKS.list_all(),\n    \"task_get\":    lambda **kw: TASKS.get(kw[\"task_id\"]),\n}\n```\n\n## \n\n TaskManager ( `agents/s07_task_system.py`,  46-123 ):\n\n```python\nclass TaskManager:\n    def __init__(self, tasks_dir: Path):\n        self.dir = tasks_dir\n        self.dir.mkdir(exist_ok=True)\n        self._next_id = self._max_id() + 1\n\n    def _load(self, task_id: int) -> dict:\n        path = self.dir / f\"task_{task_id}.json\"\n        return json.loads(path.read_text())\n\n    def _save(self, task: dict):\n        path = self.dir / f\"task_{task['id']}.json\"\n        path.write_text(json.dumps(task, indent=2))\n\n    def create(self, subject, description=\"\"):\n        task = {\"id\": self._next_id, \"subject\": subject,\n                \"status\": \"pending\", \"blockedBy\": [],\n                \"blocks\": [], \"owner\": \"\"}\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n\n    def _clear_dependency(self, completed_id):\n        for f in self.dir.glob(\"task_*.json\"):\n            task = json.loads(f.read_text())\n            if completed_id in task.get(\"blockedBy\", []):\n                task[\"blockedBy\"].remove(completed_id)\n                self._save(task)\n```\n\n##  s06 \n\n|  |  (s06) |  (s07) |\n|---|---|---|\n| Tools | 5 | 8 (`task_create/update/list/get`) |\n|  |  | `.tasks/`  JSON  |\n|  |  | `blockedBy + blocks`  |\n|  |  |  |\n\n## \n\n, ,  -- , , ,  JSON \n\n `status/blockedBy` \n\n,  s07  Task  Todo: \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s07_task_system.py\n```\n\n:\n\n1. `Create 3 tasks: \"Setup project\", \"Write code\", \"Write tests\". Make them depend on each other in order.`\n2. `List all tasks and show the dependency graph`\n3. `Complete task 1 and then list tasks to see task 2 unblocked`\n4. `Create a task board for refactoring: parse -> transform -> emit -> test`\n"
  },
  {
    "version": "s08",
    "locale": "zh",
    "title": "s08: Background Tasks ()",
    "content": "# s08: Background Tasks ()\n\n> BackgroundManager ,  LLM , \n\n## \n\n: `npm install``pytest``docker build` agent loop , ,  \", \", ,  -- , \n\n agent loop , , \n\n BackgroundManager, ,  LLM , , \n\n## \n\n```\nMain thread                Background thread\n+-----------------+        +-----------------+\n| agent loop      |        | task executes   |\n| ...             |        | ...             |\n| [LLM call] <---+------- | enqueue(result) |\n|  ^drain queue   |        +-----------------+\n+-----------------+\n\nTimeline:\nAgent --[spawn A]--[spawn B]--[other work]----\n             |          |\n             v          v\n          [A runs]   [B runs]      (parallel)\n             |          |\n             +-- notification queue --+\n                                      |\n                           [results injected before\n                            next LLM call]\n```\n\n## \n\n1. BackgroundManager \n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n```\n\n2. `run()`  task_id\n\n```python\ndef run(self, command: str) -> str:\n    task_id = str(uuid.uuid4())[:8]\n    self.tasks[task_id] = {\n        \"status\": \"running\",\n        \"result\": None,\n        \"command\": command,\n    }\n    thread = threading.Thread(\n        target=self._execute,\n        args=(task_id, command),\n        daemon=True,\n    )\n    thread.start()\n    return f\"Background task {task_id} started\"\n```\n\n3.  `_execute` \n\n```python\ndef _execute(self, task_id: str, command: str):\n    try:\n        r = subprocess.run(command, shell=True, cwd=WORKDIR,\n            capture_output=True, text=True, timeout=300)\n        output = (r.stdout + r.stderr).strip()[:50000]\n        status = \"completed\"\n    except subprocess.TimeoutExpired:\n        output = \"Error: Timeout (300s)\"\n        status = \"timeout\"\n    self.tasks[task_id][\"status\"] = status\n    self.tasks[task_id][\"result\"] = output\n    with self._lock:\n        self._notification_queue.append({\n            \"task_id\": task_id,\n            \"status\": status,\n            \"result\": output[:500],\n        })\n```\n\n4. `drain_notifications()` \n\n```python\ndef drain_notifications(self) -> list:\n    with self._lock:\n        notifs = list(self._notification_queue)\n        self._notification_queue.clear()\n    return notifs\n```\n\n5. Agent loop  LLM \n\n```python\ndef agent_loop(messages: list):\n    while True:\n        notifs = BG.drain_notifications()\n        if notifs and messages:\n            notif_text = \"\\n\".join(\n                f\"[bg:{n['task_id']}] {n['status']}: \"\n                f\"{n['result']}\" for n in notifs\n            )\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<background-results>\"\n                           f\"\\n{notif_text}\\n\"\n                           f\"</background-results>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted background results.\"})\n        response = client.messages.create(...)\n```\n\n## \n\nBackgroundManager ( `agents/s08_background_tasks.py`,  49-107 ):\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n\n    def run(self, command: str) -> str:\n        task_id = str(uuid.uuid4())[:8]\n        self.tasks[task_id] = {\"status\": \"running\",\n                               \"result\": None,\n                               \"command\": command}\n        thread = threading.Thread(\n            target=self._execute,\n            args=(task_id, command), daemon=True)\n        thread.start()\n        return f\"Background task {task_id} started\"\n\n    def _execute(self, task_id, command):\n        # run subprocess, push to queue\n        ...\n\n    def drain_notifications(self) -> list:\n        with self._lock:\n            notifs = list(self._notification_queue)\n            self._notification_queue.clear()\n        return notifs\n```\n\n##  s07 \n\n|            |  (s07)       |  (s08)                         |\n|----------------|------------------|------------------------------------|\n| Tools          | 8                | 6 ( + background_run + check)  |\n|        |            |  +                     |\n|        |                |                      |\n|            |                |                            |\n\n## \n\n ( LLM ) I/O  ()  (\" LLM \") , : ,  I/O \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s08_background_tasks.py\n```\n\n:\n\n1. `Run \"sleep 5 && echo done\" in the background, then create a file while it runs`\n2. `Start 3 background tasks: \"sleep 2\", \"sleep 4\", \"sleep 6\". Check their status.`\n3. `Run pytest in the background and keep working on other things`\n"
  },
  {
    "version": "s09",
    "locale": "zh",
    "title": "s09: Agent Teams ()",
    "content": "# s09: Agent Teams ()\n\n>  JSONL ,  -- spawnmessagebroadcast  drain\n\n## \n\n (s04) : , ,  (s08)  shell ,  LLM \n\n: (1)  prompt , (2) , (3) ,  -- \n\n TeammateManager ()  JSONL  MessageBus  agent loop,  LLM , \n\n s06  s07 : s03  TodoManager  (s06)  (s07)  -- config.json \n\n## \n\n```\nTeammate lifecycle:\n  spawn -> WORKING -> IDLE -> WORKING -> ... -> SHUTDOWN\n\nCommunication:\n  .team/\n    config.json           <- team roster + statuses\n    inbox/\n      alice.jsonl         <- append-only, drain-on-read\n      bob.jsonl\n      lead.jsonl\n\n                +--------+    send(\"alice\",\"bob\",\"...\")    +--------+\n                | alice  | -----------------------------> |  bob   |\n                | loop   |    bob.jsonl << {json_line}    |  loop  |\n                +--------+                                +--------+\n                     ^                                         |\n                     |        BUS.read_inbox(\"alice\")          |\n                     +---- alice.jsonl -> read + drain ---------+\n\n5 message types:\n+-------------------------+------------------------------+\n| message                 | Normal text between agents   |\n| broadcast               | Sent to all teammates        |\n| shutdown_request        | Request graceful shutdown     |\n| shutdown_response       | Approve/reject shutdown      |\n| plan_approval_response  | Approve/reject plan          |\n+-------------------------+------------------------------+\n```\n\n## \n\n1. TeammateManager  config.json \n\n```python\nclass TeammateManager:\n    def __init__(self, team_dir: Path):\n        self.dir = team_dir\n        self.dir.mkdir(exist_ok=True)\n        self.config_path = self.dir / \"config.json\"\n        self.config = self._load_config()\n        self.threads = {}\n```\n\n2. `spawn()`  agent loop spawn  idle \n\n```python\ndef spawn(self, name: str, role: str, prompt: str) -> str:\n    member = self._find_member(name)\n    if member:\n        if member[\"status\"] not in (\"idle\", \"shutdown\"):\n            return f\"Error: '{name}' is currently {member['status']}\"\n        member[\"status\"] = \"working\"\n    else:\n        member = {\"name\": name, \"role\": role, \"status\": \"working\"}\n        self.config[\"members\"].append(member)\n    self._save_config()\n    thread = threading.Thread(\n        target=self._teammate_loop,\n        args=(name, role, prompt), daemon=True)\n    self.threads[name] = thread\n    thread.start()\n    return f\"Spawned teammate '{name}' (role: {role})\"\n```\n\n3. MessageBus  JSONL `send()`  JSON; `read_inbox()` \n\n```python\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content,\n               \"timestamp\": time.time()}\n        if extra:\n            msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n        return f\"Sent {msg_type} to {to}\"\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists():\n            return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")  # drain\n        return json.dumps(msgs, indent=2)\n```\n\n4.  LLM , \n\n```python\ndef _teammate_loop(self, name, role, prompt):\n    sys_prompt = f\"You are '{name}', role: {role}, at {WORKDIR}.\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(50):\n        inbox = BUS.read_inbox(name)\n        if inbox != \"[]\":\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted inbox messages.\"})\n        response = client.messages.create(\n            model=MODEL, system=sys_prompt,\n            messages=messages, tools=TOOLS)\n        messages.append({\"role\": \"assistant\",\n                         \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n    self._find_member(name)[\"status\"] = \"idle\"\n    self._save_config()\n```\n\n5. `broadcast()` \n\n```python\ndef broadcast(self, sender, content, teammates):\n    count = 0\n    for name in teammates:\n        if name != sender:\n            self.send(sender, name, content, \"broadcast\")\n            count += 1\n    return f\"Broadcast to {count} teammates\"\n```\n\n## \n\nTeammateManager + MessageBus  ( `agents/s09_agent_teams.py`):\n\n```python\nclass TeammateManager:\n    def spawn(self, name, role, prompt):\n        member = self._find_member(name) or {\n            \"name\": name, \"role\": role, \"status\": \"working\"\n        }\n        member[\"status\"] = \"working\"\n        self._save_config()\n        thread = threading.Thread(\n            target=self._teammate_loop,\n            args=(name, role, prompt), daemon=True)\n        thread.start()\n        return f\"Spawned '{name}'\"\n\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content, \"timestamp\": time.time()}\n        if extra: msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists(): return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")\n        return json.dumps(msgs, indent=2)\n```\n\n##  s08 \n\n|            |  (s08)       |  (s09)                         |\n|----------------|------------------|------------------------------------|\n| Tools          | 6                | 9 (+spawn/send/read_inbox)         |\n|      |              |  + N                     |\n|          |                | config.json + JSONL          |\n|            |          |  agent loop              |\n|        |            | idle -> working -> idle            |\n|            |                | 5  + broadcast           |\n\n: , -per-\n\n## \n\n ( JSONL) \"\"  (, )  --  --  LLM , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s09_agent_teams.py\n```\n\n:\n\n1. `Spawn alice (coder) and bob (tester). Have alice send bob a message.`\n2. `Broadcast \"status update: phase 1 complete\" to all teammates`\n3. `Check the lead inbox for any messages`\n4.  `/team` \n5.  `/inbox` \n"
  },
  {
    "version": "s10",
    "locale": "zh",
    "title": "s10: Team Protocols ()",
    "content": "# s10: Team Protocols ()\n\n>  request_id  --  FSM, \n\n## \n\n s09 , , :\n\n****: ?  config.json: ,  ()  ()\n\n****: ?  \"\", , , \n\n:  ID ,  ID  (FSM)  pending -> approved | rejected \n\n## \n\n```\nShutdown Protocol            Plan Approval Protocol\n==================           ======================\n\nLead             Teammate    Teammate           Lead\n  |                 |           |                 |\n  |--shutdown_req-->|           |--plan_req------>|\n  | {req_id:\"abc\"}  |           | {req_id:\"xyz\"}  |\n  |                 |           |                 |\n  |<--shutdown_resp-|           |<--plan_resp-----|\n  | {req_id:\"abc\",  |           | {req_id:\"xyz\",  |\n  |  approve:true}  |           |  approve:true}  |\n  |                 |           |                 |\n  v                 v           v                 v\ntracker[\"abc\"]     exits     proceeds          tracker[\"xyz\"]\n = approved                                     = approved\n\nShared FSM (identical for both protocols):\n  [pending] --approve--> [approved]\n  [pending] --reject---> [rejected]\n\nTrackers:\n  shutdown_requests = {req_id: {target, status}}\n  plan_requests     = {req_id: {from, plan, status}}\n```\n\n## \n\n1.  request_id  shutdown_request \n\n```python\nshutdown_requests = {}\n\ndef handle_shutdown_request(teammate: str) -> str:\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\",\n    }\n    BUS.send(\"lead\", teammate, \"Please shut down gracefully.\",\n             \"shutdown_request\", {\"request_id\": req_id})\n    return f\"Shutdown request {req_id} sent (status: pending)\"\n```\n\n2. ,  `shutdown_response` \n\n```python\nif tool_name == \"shutdown_response\":\n    req_id = args[\"request_id\"]\n    approve = args[\"approve\"]\n    if req_id in shutdown_requests:\n        shutdown_requests[req_id][\"status\"] = \\\n            \"approved\" if approve else \"rejected\"\n    BUS.send(sender, \"lead\", args.get(\"reason\", \"\"),\n             \"shutdown_response\",\n             {\"request_id\": req_id, \"approve\": approve})\n    return f\"Shutdown {'approved' if approve else 'rejected'}\"\n```\n\n3. \n\n```python\nif (block.name == \"shutdown_response\"\n        and block.input.get(\"approve\")):\n    should_exit = True\n# ...\nmember[\"status\"] = \"shutdown\" if should_exit else \"idle\"\n```\n\n4.  request_id\n\n```python\nplan_requests = {}\n\nif tool_name == \"plan_approval\":\n    plan_text = args.get(\"plan\", \"\")\n    req_id = str(uuid.uuid4())[:8]\n    plan_requests[req_id] = {\n        \"from\": sender, \"plan\": plan_text,\n        \"status\": \"pending\",\n    }\n    BUS.send(sender, \"lead\", plan_text,\n             \"plan_approval_request\",\n             {\"request_id\": req_id, \"plan\": plan_text})\n    return f\"Plan submitted (request_id={req_id})\"\n```\n\n5.  request_id \n\n```python\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests.get(request_id)\n    if not req:\n        return f\"Error: Unknown request_id '{request_id}'\"\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve,\n              \"feedback\": feedback})\n    return f\"Plan {req['status']} for '{req['from']}'\"\n```\n\n6.  `plan_approval` , :  ( request_id),  ( request_id)\n\n```python\n# Lead tool dispatch:\n\"plan_approval\": lambda **kw: handle_plan_review(\n    kw[\"request_id\"], kw[\"approve\"],\n    kw.get(\"feedback\", \"\")),\n# Teammate: submit mode (generate request_id)\n```\n\n## \n\n ( `agents/s10_team_protocols.py`):\n\n```python\nshutdown_requests = {}\nplan_requests = {}\n\n# -- Shutdown --\ndef handle_shutdown_request(teammate):\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\"\n    }\n    BUS.send(\"lead\", teammate,\n             \"Please shut down gracefully.\",\n             \"shutdown_request\",\n             {\"request_id\": req_id})\n\n# -- Plan Approval --\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests[request_id]\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve})\n\n# Both use the same FSM:\n# pending -> approved | rejected\n# Both correlate by request_id across async inboxes\n```\n\n##  s09 \n\n|            |  (s09)       |  (s10)                           |\n|----------------|------------------|--------------------------------------|\n| Tools          | 9                | 12 (+shutdown_req/resp +plan)        |\n|            |        | -                        |\n|        |                | /                      |\n|        |                |  tracker                     |\n|            |                |  request_id              |\n| FSM            |                | pending -> approved/rejected         |\n\n## \n\nrequest_id  (pending -> approved/rejected)  -- FSM request_id , , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s10_team_protocols.py\n```\n\n:\n\n1. `Spawn alice as a coder. Then request her shutdown.`\n2. `List teammates to see alice's status after shutdown approval`\n3. `Spawn bob with a risky refactoring task. Review and reject his plan.`\n4. `Spawn charlie, have him submit a plan, then approve it.`\n5.  `/team` \n"
  },
  {
    "version": "s11",
    "locale": "zh",
    "title": "s11: Autonomous Agents ()",
    "content": "# s11: Autonomous Agents ()\n\n> , \n\n## \n\n s09-s10 ,  prompt  10 , \n\n, , ,  -- \n\n: , ,  (\" alice, : coder\") \n\n: token /4 ()nag  3 \n\n## \n\n```\nTeammate lifecycle with idle cycle:\n\n+-------+\n| spawn |\n+---+---+\n    |\n    v\n+-------+   tool_use     +-------+\n| WORK  | <------------- |  LLM  |\n+---+---+                +-------+\n    |\n    | stop_reason != tool_use\n    | (or idle tool called)\n    v\n+--------+\n|  IDLE  |  poll every 5s for up to 60s\n+---+----+\n    |\n    +---> check inbox --> message? ----------> WORK\n    |\n    +---> scan .tasks/ --> unclaimed? -------> claim -> WORK\n    |\n    +---> 60s timeout ----------------------> SHUTDOWN\n\nIdentity re-injection after compression:\n  if len(messages) <= 3:\n    messages.insert(0, identity_block)\n    \"You are 'alice', role: coder, team: my-team\"\n```\n\n## \n\n1. : WORK  IDLEWORK  agent loop LLM  ( `idle` ) ,  IDLE \n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # -- WORK PHASE --\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        for _ in range(50):\n            inbox = BUS.read_inbox(name)\n            for msg in inbox:\n                if msg.get(\"type\") == \"shutdown_request\":\n                    self._set_status(name, \"shutdown\")\n                    return\n                messages.append(...)\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            # execute tools...\n            if idle_requested:\n                break\n\n        # -- IDLE PHASE --\n        self._set_status(name, \"idle\")\n        resume = self._idle_poll(name, messages)\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n2. \n\n```python\ndef _idle_poll(self, name, messages):\n    polls = IDLE_TIMEOUT // POLL_INTERVAL  # 60s / 5s = 12\n    for _ in range(polls):\n        time.sleep(POLL_INTERVAL)\n        # Check inbox for new messages\n        inbox = BUS.read_inbox(name)\n        if inbox:\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            return True\n        # Scan task board for unclaimed tasks\n        unclaimed = scan_unclaimed_tasks()\n        if unclaimed:\n            task = unclaimed[0]\n            claim_task(task[\"id\"], name)\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<auto-claimed>Task #{task['id']}: \"\n                           f\"{task['subject']}</auto-claimed>\"})\n            return True\n    return False  # timeout -> shutdown\n```\n\n3.  pending  owner\n\n```python\ndef scan_unclaimed_tasks() -> list:\n    TASKS_DIR.mkdir(exist_ok=True)\n    unclaimed = []\n    for f in sorted(TASKS_DIR.glob(\"task_*.json\")):\n        task = json.loads(f.read_text())\n        if (task.get(\"status\") == \"pending\"\n                and not task.get(\"owner\")\n                and not task.get(\"blockedBy\")):\n            unclaimed.append(task)\n    return unclaimed\n\ndef claim_task(task_id: int, owner: str):\n    path = TASKS_DIR / f\"task_{task_id}.json\"\n    task = json.loads(path.read_text())\n    task[\"status\"] = \"in_progress\"\n    task[\"owner\"] = owner\n    path.write_text(json.dumps(task, indent=2))\n```\n\n4. : , \n\n```python\ndef make_identity_block(name, role, team_name):\n    return {\"role\": \"user\",\n            \"content\": f\"<identity>You are '{name}', \"\n                       f\"role: {role}, team: {team_name}. \"\n                       f\"Continue your work.</identity>\"}\n\n# Before resuming work after idle:\nif len(messages) <= 3:\n    messages.insert(0, make_identity_block(\n        name, role, team_name))\n    messages.insert(1, {\"role\": \"assistant\",\n        \"content\": f\"I am {name}. Continuing.\"})\n```\n\n5. `idle` , \n\n```python\n{\"name\": \"idle\",\n \"description\": \"Signal that you have no more work. \"\n                \"Enters idle polling phase.\",\n \"input_schema\": {\"type\": \"object\", \"properties\": {}}},\n```\n\n## \n\n ( `agents/s11_autonomous_agents.py`):\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # WORK PHASE\n        for _ in range(50):\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            for block in response.content:\n                if block.name == \"idle\":\n                    idle_requested = True\n            if idle_requested:\n                break\n\n        # IDLE PHASE\n        self._set_status(name, \"idle\")\n        for _ in range(IDLE_TIMEOUT // POLL_INTERVAL):\n            time.sleep(POLL_INTERVAL)\n            inbox = BUS.read_inbox(name)\n            if inbox: resume = True; break\n            unclaimed = scan_unclaimed_tasks()\n            if unclaimed:\n                claim_task(unclaimed[0][\"id\"], name)\n                resume = True; break\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n##  s10 \n\n|            |  (s10)       |  (s11)                       |\n|----------------|------------------|----------------------------------|\n| Tools          | 12               | 14 (+idle, +claim_task)          |\n|          |          |                            |\n|        |                |  +            |\n|        |            |                |\n|            |          | +                    |\n|            |                | 60  ->             |\n\n## \n\n + , , , ,  -- , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s11_autonomous_agents.py\n```\n\n:\n\n1. `Create 3 tasks on the board, then spawn alice and bob. Watch them auto-claim.`\n2. `Spawn a coder teammate and let it find work from the task board itself`\n3. `Create tasks with dependencies. Watch teammates respect the blocked order.`\n4.  `/tasks`  owner \n5.  `/team` \n"
  },
  {
    "version": "s12",
    "locale": "zh",
    "title": "s12: Worktree + ",
    "content": "# s12: Worktree + \n\n> ,  ID  -- \" () + worktree ()\"\n\n## \n\ns11 , agent  agent , , , \n\n: agent A  auth , agent B  `config.py`A  B  `git status` , B ,  -- \n\n\"\"\"\", :  git worktree ,  ID \n\n## \n\n```\n (.tasks/)              (.worktrees/)\n+------------------+         +------------------------+\n| task_1.json      |         | auth-refactor/         |\n|   status: in_progress  <---->   branch: wt/auth-refactor\n|   worktree: \"auth-refactor\" |   task_id: 1           |\n+------------------+         +------------------------+\n| task_2.json      |         | ui-login/              |\n|   status: pending    <---->   branch: wt/ui-login\n|   worktree: \"ui-login\"  |   task_id: 2           |\n+------------------+         +------------------------+\n                              |\n                    index.json (worktree registry)\n                    events.jsonl (lifecycle log)\n```\n\n:\n1.  (What): `.tasks/task_*.json` -- \n2.  (Where): `.worktrees/index.json` -- \n3.  (Now):  --  worktree\n\n:\n```text\nTask:     pending -> in_progress -> completed\nWorktree: absent  -> active      -> removed | kept\n```\n\n## \n\n1. , \n\n```python\nTASKS.create(\"Implement auth refactor\")\n# -> .tasks/task_1.json  status=pending  worktree=\"\"\n```\n\n2.  worktree  `task_id`  `in_progress`\n\n```python\nWORKTREES.create(\"auth-refactor\", task_id=1)\n# -> git worktree add -b wt/auth-refactor .worktrees/auth-refactor HEAD\n# -> index.json  entry, task_1.json  worktree=\"auth-refactor\"\n```\n\n3. `cwd`  worktree , \n\n```python\nWORKTREES.run(\"auth-refactor\", \"git status --short\")\n# -> subprocess.run(command, cwd=\".worktrees/auth-refactor\", ...)\n```\n\n4. `worktree_status`  git , `task_update` \n\n```python\nWORKTREES.status(\"auth-refactor\")  # git status inside worktree\nTASKS.update(1, owner=\"agent-A\")   # update task metadata\n```\n\n5. :  keep  remove`remove`  `complete_task=true`  worktree\n\n```python\nWORKTREES.remove(\"auth-refactor\", complete_task=True)\n# -> git worktree remove\n# -> task_1.json status=completed, worktree=\"\"\n# -> index.json  status=removed\n# -> events.jsonl  task.completed + worktree.remove.after\n```\n\n6. ,  `.tasks/` + `.worktrees/index.json` , \n\n## \n\n -- append-only  ( `agents/s12_worktree_task_isolation.py`):\n\n```python\nclass EventBus:\n    def emit(self, event, task=None, worktree=None, error=None):\n        payload = {\n            \"event\": event,\n            \"ts\": time.time(),\n            \"task\": task or {},\n            \"worktree\": worktree or {},\n        }\n        if error:\n            payload[\"error\"] = error\n        with self.path.open(\"a\", encoding=\"utf-8\") as f:\n            f.write(json.dumps(payload) + \"\\n\")\n```\n\n `.worktrees/events.jsonl`, :\n- `worktree.create.before / after / failed`\n- `worktree.remove.before / after / failed`\n- `task.completed` ( `complete_task=true` )\n\n:\n\n```json\n{\n  \"event\": \"worktree.remove.after\",\n  \"task\": {\"id\": 7, \"status\": \"completed\"},\n  \"worktree\": {\"name\": \"auth-refactor\", \"path\": \"...\", \"status\": \"removed\"},\n  \"ts\": 1730000000\n}\n```\n\n -- Task  worktree :\n\n```python\ndef bind_worktree(self, task_id: int, worktree: str, owner: str = \"\") -> str:\n    task = self._load(task_id)\n    task[\"worktree\"] = worktree\n    if task[\"status\"] == \"pending\":\n        task[\"status\"] = \"in_progress\"\n    self._save(task)\n```\n\n -- cwd  worktree :\n\n```python\nr = subprocess.run(\n    command,\n    shell=True,\n    cwd=path,\n    capture_output=True,\n    text=True,\n    timeout=300,\n)\n```\n\n -- remove :\n\n```python\ndef remove(self, name, force=False, complete_task=False):\n    self._run_git([\"worktree\", \"remove\", wt[\"path\"]])\n    if complete_task and wt.get(\"task_id\") is not None:\n        self.tasks.update(wt[\"task_id\"], status=\"completed\")\n        self.tasks.unbind_worktree(wt[\"task_id\"])\n        self.events.emit(\"task.completed\", ...)\n```\n\n:\n\n```python\n\"worktree_keep\":   lambda **kw: WORKTREES.keep(kw[\"name\"]),\n\"worktree_events\": lambda **kw: EVENTS.list_recent(kw.get(\"limit\", 20)),\n```\n\n##  s11 \n\n|            |  (s11)                 |  (s12)                              |\n|----------------|----------------------------|-----------------------------------------|\n|        |  (owner/status)      |  + `worktree`             |\n|      |                    |  worktree         |\n|        |                |  + worktree         |\n|        |                    |  + worktree  keep/remove    |\n|  |                    | `.worktrees/events.jsonl`     |\n\n## \n\n/Task \"\", worktree \"\",  task ID  worktree (),  worktree \n\n,  `.tasks/`  `.worktrees/index.json` , \n\n, , `keep/remove` ,  -- agent , \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s12_worktree_task_isolation.py\n```\n\n:\n\n1. `Create tasks for backend auth and frontend login page, then list tasks.`\n2. `Create worktree \"auth-refactor\" for task 1, create worktree \"ui-login\", then bind task 2 to \"ui-login\".`\n3. `Run \"git status --short\" in worktree \"auth-refactor\".`\n4. `Keep worktree \"ui-login\", then list worktrees and inspect worktree events.`\n5. `Remove worktree \"auth-refactor\" with complete_task=true, then list tasks/worktrees/events.`\n"
  },
  {
    "version": "s01",
    "locale": "ja",
    "title": "s01: The Agent Loop",
    "content": "# s01: The Agent Loop\n\n> AI while \n\n## \n\n-\n\nagent loopagent loop: \n\n: helloPython(1)(2)(3)3\n\n## \n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> |  Tool   |\n|  prompt  |      |       |      | execute |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                      (loop continues)\n\nThe loop terminates when stop_reason != \"tool_use\".\nThat single condition is the entire control flow.\n```\n\n## \n\n1. \n\n```python\nhistory.append({\"role\": \"user\", \"content\": query})\n```\n\n2. LLM\n\n```python\nresponse = client.messages.create(\n    model=MODEL, system=SYSTEM, messages=messages,\n    tools=TOOLS, max_tokens=8000,\n)\n```\n\n3. \n\n```python\nmessages.append({\"role\": \"assistant\", \"content\": response.content})\n```\n\n4. stop reason\n\n```python\nif response.stop_reason != \"tool_use\":\n    return\n```\n\n5. tool_use(bash)\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        output = run_bash(block.input[\"command\"])\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n6. user\n\n```python\nmessages.append({\"role\": \"user\", \"content\": results})\n```\n\n## \n\n -- 30\n(`agents/s01_agent_loop.py` 66-86):\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                output = run_bash(block.input[\"command\"])\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## \n\n1 -- \n\n| Component     | Before     | After                          |\n|---------------|------------|--------------------------------|\n| Agent loop    | (none)     | `while True` + stop_reason     |\n| Tools         | (none)     | `bash` (one tool)              |\n| Messages      | (none)     | Accumulating list              |\n| Control flow  | (none)     | `stop_reason != \"tool_use\"`    |\n\n## \n\n LLM  1 (`stop_reason != \"tool_use\"`)\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s01_agent_loop.py\n```\n\n:\n\n1. `Create a file called hello.py that prints \"Hello, World!\"`\n2. `List all Python files in this directory`\n3. `What is the current git branch?`\n4. `Create a directory called test_output and write 3 files in it`\n"
  },
  {
    "version": "s02",
    "locale": "ja",
    "title": "s02: Tools",
    "content": "# s02: Tools\n\n>  -- \n\n## \n\n`bash`: `cat``sed`\n\nbashbash`read_file``write_file`\n\ns01\n\n## \n\n```\n+----------+      +-------+      +------------------+\n|   User   | ---> |  LLM  | ---> | Tool Dispatch    |\n|  prompt  |      |       |      | {                |\n+----------+      +---+---+      |   bash: run_bash |\n                      ^          |   read: run_read |\n                      |          |   write: run_wr  |\n                      +----------+   edit: run_edit |\n                      tool_result| }                |\n                                 +------------------+\n\nThe dispatch map is a dict: {tool_name: handler_function}\nOne lookup replaces any if/elif chain.\n```\n\n## \n\n1. input_schema\n\n```python\ndef run_read(path: str, limit: int = None) -> str:\n    text = safe_path(path).read_text()\n    lines = text.splitlines()\n    if limit and limit < len(lines):\n        lines = lines[:limit]\n    return \"\\n\".join(lines)[:50000]\n```\n\n2. \n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n```\n\n3. agent loop\n\n```python\nfor block in response.content:\n    if block.type == \"tool_use\":\n        handler = TOOL_HANDLERS.get(block.name)\n        output = handler(**block.input)\n        results.append({\n            \"type\": \"tool_result\",\n            \"tool_use_id\": block.id,\n            \"content\": output,\n        })\n```\n\n4. \n\n```python\ndef safe_path(p: str) -> Path:\n    path = (WORKDIR / p).resolve()\n    if not path.is_relative_to(WORKDIR):\n        raise ValueError(f\"Path escapes workspace: {p}\")\n    return path\n```\n\n## \n\n(`agents/s02_tool_use.py` 93-129):\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":       lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\":  lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\":  lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"],\n                                        kw[\"new_text\"]),\n}\n\ndef agent_loop(messages: list):\n    while True:\n        response = client.messages.create(\n            model=MODEL, system=SYSTEM, messages=messages,\n            tools=TOOLS, max_tokens=8000,\n        )\n        messages.append({\"role\": \"assistant\", \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            return\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input) if handler \\\n                    else f\"Unknown tool: {block.name}\"\n                results.append({\n                    \"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": output,\n                })\n        messages.append({\"role\": \"user\", \"content\": results})\n```\n\n## s01\n\n| Component      | Before (s01)       | After (s02)                |\n|----------------|--------------------|----------------------------|\n| Tools          | 1 (bash only)      | 4 (bash, read, write, edit)|\n| Dispatch       | Hardcoded bash call | `TOOL_HANDLERS` dict       |\n| Path safety    | None               | `safe_path()` sandbox      |\n| Agent loop     | Unchanged          | Unchanged                  |\n\n## \n\n -- 1( vs )\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s02_tool_use.py\n```\n\n:\n\n1. `Read the file requirements.txt`\n2. `Create a file called greet.py with a greet(name) function`\n3. `Edit greet.py to add a docstring to the function`\n4. `Read greet.py to verify the edit worked`\n5. `Run the greet function with bash: python -c \"from greet import greet; greet('World')\"`\n"
  },
  {
    "version": "s03",
    "locale": "ja",
    "title": "s03: TodoWrite",
    "content": "# s03: TodoWrite\n\n> TodoManagernag\n\n## \n\n\n\n -- 101-34-10\n\n: TodoManagerin_progresscompletednag3todo\n\n: nag  3 s07  Task TodoWrite \n\n## \n\n```\n+----------+      +-------+      +---------+\n|   User   | ---> |  LLM  | ---> | Tools   |\n|  prompt  |      |       |      | + todo  |\n+----------+      +---+---+      +----+----+\n                      ^               |\n                      |   tool_result |\n                      +---------------+\n                            |\n                +-----------+-----------+\n                | TodoManager state     |\n                | [ ] task A            |\n                | [>] task B  <- doing  |\n                | [x] task C            |\n                +-----------------------+\n                            |\n                if rounds_since_todo >= 3:\n                  inject <reminder> into tool_result\n```\n\n## \n\n1. TodoManager`in_progress`1\n\n```python\nclass TodoManager:\n    def __init__(self):\n        self.items = []\n\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one task can be in_progress\")\n        self.items = validated\n        return self.render()\n```\n\n2. `todo`\n\n```python\nTOOL_HANDLERS = {\n    \"bash\":  lambda **kw: run_bash(kw[\"command\"]),\n    # ...other tools...\n    \"todo\":  lambda **kw: TODO.update(kw[\"items\"]),\n}\n```\n\n3. nag3`todo`tool_result`<reminder>`\n\n```python\ndef agent_loop(messages: list):\n    rounds_since_todo = 0\n    while True:\n        if rounds_since_todo >= 3 and messages:\n            last = messages[-1]\n            if (last[\"role\"] == \"user\"\n                    and isinstance(last.get(\"content\"), list)):\n                last[\"content\"].insert(0, {\n                    \"type\": \"text\",\n                    \"text\": \"<reminder>Update your todos.</reminder>\",\n                })\n        # ... rest of loop ...\n        rounds_since_todo = 0 if used_todo else rounds_since_todo + 1\n```\n\n4. todo\n\n```python\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nUse the todo tool to plan multi-step tasks.\nMark in_progress before starting, completed when done.\nPrefer tools over prose.\"\"\"\n```\n\n## \n\nTodoManagernag(`agents/s03_todo_write.py` 51-85158-187):\n\n```python\nclass TodoManager:\n    def update(self, items: list) -> str:\n        validated = []\n        in_progress_count = 0\n        for item in items:\n            status = item.get(\"status\", \"pending\")\n            if status == \"in_progress\":\n                in_progress_count += 1\n            validated.append({\n                \"id\": item[\"id\"],\n                \"text\": item[\"text\"],\n                \"status\": status,\n            })\n        if in_progress_count > 1:\n            raise ValueError(\"Only one in_progress\")\n        self.items = validated\n        return self.render()\n\n# In agent_loop:\nif rounds_since_todo >= 3:\n    last[\"content\"].insert(0, {\n        \"type\": \"text\",\n        \"text\": \"<reminder>Update your todos.</reminder>\",\n    })\n```\n\n## s02\n\n| Component      | Before (s02)     | After (s03)              |\n|----------------|------------------|--------------------------|\n| Tools          | 4                | 5 (+todo)                |\n| Planning       | None             | TodoManager with statuses|\n| Nag injection  | None             | `<reminder>` after 3 rounds|\n| Agent loop     | Simple dispatch  | + rounds_since_todo counter|\n\n## \n\nnag -- in_progress1\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s03_todo_write.py\n```\n\n:\n\n1. `Refactor the file hello.py: add type hints, docstrings, and a main guard`\n2. `Create a Python package with __init__.py, utils.py, and tests/test_utils.py`\n3. `Review all Python files and fix any style issues`\n"
  },
  {
    "version": "s04",
    "locale": "ja",
    "title": "s04: Subagents",
    "content": "# s04: Subagents\n\n>  -- \n\n## \n\nbash20-30500500\n\n55 -- pytest with conftest.py configuration\n\n fresh `messages[]` : `messages=[]`\n\n## \n\n```\nParent agent                     Subagent\n+------------------+             +------------------+\n| messages=[...]   |             | messages=[]      | <-- fresh\n|                  |  dispatch   |                  |\n| tool: task       | ---------->| while tool_use:  |\n|   prompt=\"...\"   |            |   call tools     |\n|                  |  summary   |   append results |\n|   result = \"...\" | <--------- | return last text |\n+------------------+             +------------------+\n          |\nParent context stays clean.\nSubagent context is discarded.\n```\n\n## \n\n1. `task``task`()\n\n```python\nPARENT_TOOLS = CHILD_TOOLS + [\n    {\"name\": \"task\",\n     \"description\": \"Spawn a subagent with fresh context.\",\n     \"input_schema\": {\n         \"type\": \"object\",\n         \"properties\": {\n             \"prompt\": {\"type\": \"string\"},\n             \"description\": {\"type\": \"string\"},\n         },\n         \"required\": [\"prompt\"],\n     }},\n]\n```\n\n2. \n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):  # safety limit\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\n            \"role\": \"assistant\", \"content\": response.content\n        })\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n```\n\n3. 30\n\n```python\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n4. tool_result\n\n```python\nif block.name == \"task\":\n    output = run_subagent(block.input[\"prompt\"])\nresults.append({\n    \"type\": \"tool_result\",\n    \"tool_use_id\": block.id,\n    \"content\": str(output),\n})\n```\n\n## \n\n(`agents/s04_subagent.py` 110-128):\n\n```python\ndef run_subagent(prompt: str) -> str:\n    sub_messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(30):\n        response = client.messages.create(\n            model=MODEL, system=SUBAGENT_SYSTEM,\n            messages=sub_messages,\n            tools=CHILD_TOOLS, max_tokens=8000,\n        )\n        sub_messages.append({\"role\": \"assistant\",\n                             \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        results = []\n        for block in response.content:\n            if block.type == \"tool_use\":\n                handler = TOOL_HANDLERS.get(block.name)\n                output = handler(**block.input)\n                results.append({\"type\": \"tool_result\",\n                    \"tool_use_id\": block.id,\n                    \"content\": str(output)[:50000]})\n        sub_messages.append({\"role\": \"user\", \"content\": results})\n    return \"\".join(\n        b.text for b in response.content if hasattr(b, \"text\")\n    ) or \"(no summary)\"\n```\n\n## s03\n\n| Component      | Before (s03)     | After (s04)               |\n|----------------|------------------|---------------------------|\n| Tools          | 5                | 5 (base) + task (parent)  |\n| Context        | Single shared    | Parent + child isolation  |\n| Subagent       | None             | `run_subagent()` function |\n| Return value   | N/A              | Summary text only         |\n\n## \n\nfresh `messages[]` `messages[]`OS()\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s04_subagent.py\n```\n\n:\n\n1. `Use a subtask to find what testing framework this project uses`\n2. `Delegate: read all .py files and summarize what each one does`\n3. `Use a task to create a new module, then verify it from here`\n"
  },
  {
    "version": "s05",
    "locale": "ja",
    "title": "s05: Skills",
    "content": "# s05: Skills\n\n> 2()tool_result()\n\n## \n\n: git\n\n10200020,000git\n\n2: 1(100)2`load_skill`tool_result()()\n\n## \n\n```\nSystem prompt (Layer 1 -- always present):\n+--------------------------------------+\n| You are a coding agent.              |\n| Skills available:                    |\n|   - git: Git workflow helpers        |  ~100 tokens/skill\n|   - test: Testing best practices     |\n+--------------------------------------+\n\nWhen model calls load_skill(\"git\"):\n+--------------------------------------+\n| tool_result (Layer 2 -- on demand):  |\n| <skill name=\"git\">                   |\n|   Full git workflow instructions...  |  ~2000 tokens\n|   Step 1: ...                        |\n|   Step 2: ...                        |\n| </skill>                             |\n+--------------------------------------+\n```\n\n## \n\n1. `.skills/`YAMLMarkdown\n\n```\n.skills/\n  git.md       # ---\\n description: Git workflow\\n ---\\n ...\n  test.md      # ---\\n description: Testing patterns\\n ---\\n ...\n```\n\n2. SkillLoader\n\n```python\nclass SkillLoader:\n    def _parse_frontmatter(self, text: str) -> tuple:\n        match = re.match(\n            r\"^---\\n(.*?)\\n---\\n(.*)\", text, re.DOTALL\n        )\n        if not match:\n            return {}, text\n        meta = {}\n        for line in match.group(1).strip().splitlines():\n            if \":\" in line:\n                key, val = line.split(\":\", 1)\n                meta[key.strip()] = val.strip()\n        return meta, match.group(2).strip()\n```\n\n3. 1: `get_descriptions()`\n\n```python\ndef get_descriptions(self) -> str:\n    lines = []\n    for name, skill in self.skills.items():\n        desc = skill[\"meta\"].get(\"description\", \"No description\")\n        lines.append(f\"  - {name}: {desc}\")\n    return \"\\n\".join(lines)\n\nSYSTEM = f\"\"\"You are a coding agent at {WORKDIR}.\nSkills available:\n{SKILL_LOADER.get_descriptions()}\"\"\"\n```\n\n4. 2: `get_content()``<skill>`\n\n```python\ndef get_content(self, name: str) -> str:\n    skill = self.skills.get(name)\n    if not skill:\n        return f\"Error: Unknown skill '{name}'.\"\n    return f\"<skill name=\\\"{name}\\\">\\n{skill['body']}\\n</skill>\"\n```\n\n5. `load_skill`\n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"load_skill\": lambda **kw: SKILL_LOADER.get_content(kw[\"name\"]),\n}\n```\n\n## \n\nSkillLoader(`agents/s05_skill_loading.py` 51-97):\n\n```python\nclass SkillLoader:\n    def __init__(self, skills_dir: Path):\n        self.skills = {}\n        for f in sorted(skills_dir.glob(\"*.md\")):\n            text = f.read_text()\n            meta, body = self._parse_frontmatter(text)\n            self.skills[f.stem] = {\n                \"meta\": meta, \"body\": body\n            }\n\n    def get_descriptions(self) -> str:\n        lines = []\n        for name, skill in self.skills.items():\n            desc = skill[\"meta\"].get(\"description\", \"\")\n            lines.append(f\"  - {name}: {desc}\")\n        return \"\\n\".join(lines)\n\n    def get_content(self, name: str) -> str:\n        skill = self.skills.get(name)\n        if not skill:\n            return f\"Error: Unknown skill '{name}'.\"\n        return (f\"<skill name=\\\"{name}\\\">\\n\"\n                f\"{skill['body']}\\n</skill>\")\n```\n\n## s04\n\n| Component      | Before (s04)     | After (s05)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5 (base + task)  | 5 (base + load_skill)      |\n| System prompt  | Static string    | + skill descriptions       |\n| Knowledge      | None             | .skills/*.md files         |\n| Injection      | None             | Two-layer (system + result)|\n\n## \n\n21()1202()tool_result()()\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s05_skill_loading.py\n```\n\n:\n\n1. `What skills are available?`\n2. `Load the agent-builder skill and follow its instructions`\n3. `I need to do a code review -- load the relevant skill first`\n4. `Build an MCP server using the mcp-builder skill`\n"
  },
  {
    "version": "s06",
    "locale": "ja",
    "title": "s06: Compact",
    "content": "# s06: Compact\n\n> 3\n\n## \n\nAPI: \n\n200,0001000`read_file`40003020bash100,000\n\n3:\n1(micro-compact)\n2(auto-compact)\n3(manual compact)\n\n: /4\n\n## \n\n```\nEvery turn:\n+------------------+\n| Tool call result |\n+------------------+\n        |\n        v\n[Layer 1: micro_compact]        (silent, every turn)\n  Replace tool_result > 3 turns old\n  with \"[Previous: used {tool_name}]\"\n        |\n        v\n[Check: tokens > 50000?]\n   |               |\n   no              yes\n   |               |\n   v               v\ncontinue    [Layer 2: auto_compact]\n              Save transcript to .transcripts/\n              LLM summarizes conversation.\n              Replace all messages with [summary].\n                    |\n                    v\n            [Layer 3: compact tool]\n              Model calls compact explicitly.\n              Same summarization as auto_compact.\n```\n\n## \n\n1. **1 -- micro_compact**: LLM3tool_result\n\n```python\ndef micro_compact(messages: list) -> list:\n    tool_results = []\n    for i, msg in enumerate(messages):\n        if msg[\"role\"] == \"user\" and isinstance(msg.get(\"content\"), list):\n            for j, part in enumerate(msg[\"content\"]):\n                if isinstance(part, dict) and part.get(\"type\") == \"tool_result\":\n                    tool_results.append((i, j, part))\n    if len(tool_results) <= KEEP_RECENT:\n        return messages\n    to_clear = tool_results[:-KEEP_RECENT]\n    for _, _, part in to_clear:\n        if len(part.get(\"content\", \"\")) > 100:\n            tool_id = part.get(\"tool_use_id\", \"\")\n            tool_name = tool_name_map.get(tool_id, \"unknown\")\n            part[\"content\"] = f\"[Previous: used {tool_name}]\"\n    return messages\n```\n\n2. **2 -- auto_compact**: 50,000LLM\n\n```python\ndef auto_compact(messages: list) -> list:\n    TRANSCRIPT_DIR.mkdir(exist_ok=True)\n    transcript_path = TRANSCRIPT_DIR / f\"transcript_{int(time.time())}.jsonl\"\n    with open(transcript_path, \"w\") as f:\n        for msg in messages:\n            f.write(json.dumps(msg, default=str) + \"\\n\")\n    response = client.messages.create(\n        model=MODEL,\n        messages=[{\"role\": \"user\", \"content\":\n            \"Summarize this conversation for continuity...\"\n            + json.dumps(messages, default=str)[:80000]}],\n        max_tokens=2000,\n    )\n    summary = response.content[0].text\n    return [\n        {\"role\": \"user\", \"content\": f\"[Compressed]\\n\\n{summary}\"},\n        {\"role\": \"assistant\", \"content\": \"Understood. Continuing.\"},\n    ]\n```\n\n3. **3 -- manual compact**: `compact`\n\n```python\nif manual_compact:\n    messages[:] = auto_compact(messages)\n```\n\n4. agent loop3\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        micro_compact(messages)\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)\n        response = client.messages.create(...)\n        # ... tool execution ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)\n```\n\n## \n\n3(`agents/s06_context_compact.py` 67-93189-223):\n\n```python\nTHRESHOLD = 50000\nKEEP_RECENT = 3\n\ndef micro_compact(messages):\n    # Replace old tool results with placeholders\n    ...\n\ndef auto_compact(messages):\n    # Save transcript, LLM summarize, replace messages\n    ...\n\ndef agent_loop(messages):\n    while True:\n        micro_compact(messages)          # Layer 1\n        if estimate_tokens(messages) > THRESHOLD:\n            messages[:] = auto_compact(messages)  # Layer 2\n        response = client.messages.create(...)\n        # ...\n        if manual_compact:\n            messages[:] = auto_compact(messages)  # Layer 3\n```\n\n## s05\n\n| Component      | Before (s05)     | After (s06)                |\n|----------------|------------------|----------------------------|\n| Tools          | 5                | 5 (base + compact)         |\n| Context mgmt   | None             | Three-layer compression    |\n| Micro-compact  | None             | Old results -> placeholders|\n| Auto-compact   | None             | Token threshold trigger    |\n| Manual compact | None             | `compact` tool             |\n| Transcripts    | None             | Saved to .transcripts/     |\n\n## \n\n3: micro-compact()auto-compact(LLM)manual compact() -- \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s06_context_compact.py\n```\n\n:\n\n1. `Read every Python file in the agents/ directory one by one`\n   (micro-compact)\n2. `Keep reading files until compression triggers automatically`\n3. `Use the compact tool to manually compress the conversation`\n"
  },
  {
    "version": "s07",
    "locale": "ja",
    "title": "s07: Tasks",
    "content": "# s07: Tasks\n\n>  JSON \n\n## \n\ns03  TodoManager s06 Todo \n\ns06 -> s07 :\n\n1.  Todo \n2.  Task \n\n\n\n## Task vs Todo: \n\ns07  Task Todo \n\n## \n\n|  |  |  |\n|---|---|---|\n|  | Todo |  |\n|  | Task |  |\n|  | Task |  |\n\n## \n\n```\n.tasks/\n  task_1.json  {\"id\":1, \"status\":\"completed\", ...}\n  task_2.json  {\"id\":2, \"blockedBy\":[1], \"status\":\"pending\"}\n  task_3.json  {\"id\":3, \"blockedBy\":[2], \"status\":\"pending\"}\n\nDependency resolution:\n+----------+     +----------+     +----------+\n| task 1   | --> | task 2   | --> | task 3   |\n| complete |     | blocked  |     | blocked  |\n+----------+     +----------+     +----------+\n     |                ^\n     +--- completing task 1 removes it from\n          task 2's blockedBy list\n```\n\n## \n\n1. TaskManager 1 JSON  CRUD \n\n```python\nclass TaskManager:\n    def create(self, subject: str, description: str = \"\") -> str:\n        task = {\n            \"id\": self._next_id,\n            \"subject\": subject,\n            \"description\": description,\n            \"status\": \"pending\",\n            \"blockedBy\": [],\n            \"blocks\": [],\n            \"owner\": \"\",\n        }\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n```\n\n2. \n\n```python\ndef _clear_dependency(self, completed_id: int):\n    for f in self.dir.glob(\"task_*.json\"):\n        task = json.loads(f.read_text())\n        if completed_id in task.get(\"blockedBy\", []):\n            task[\"blockedBy\"].remove(completed_id)\n            self._save(task)\n```\n\n3. `update` \n\n```python\ndef update(self, task_id, status=None,\n           add_blocked_by=None, add_blocks=None):\n    task = self._load(task_id)\n    if status:\n        task[\"status\"] = status\n        if status == \"completed\":\n            self._clear_dependency(task_id)\n    if add_blocks:\n        task[\"blocks\"] = list(set(task[\"blocks\"] + add_blocks))\n        for blocked_id in add_blocks:\n            blocked = self._load(blocked_id)\n            if task_id not in blocked[\"blockedBy\"]:\n                blocked[\"blockedBy\"].append(task_id)\n                self._save(blocked)\n    self._save(task)\n```\n\n4. \n\n```python\nTOOL_HANDLERS = {\n    # ...base tools...\n    \"task_create\": lambda **kw: TASKS.create(kw[\"subject\"]),\n    \"task_update\": lambda **kw: TASKS.update(kw[\"task_id\"],\n                       kw.get(\"status\")),\n    \"task_list\":   lambda **kw: TASKS.list_all(),\n    \"task_get\":    lambda **kw: TASKS.get(kw[\"task_id\"]),\n}\n```\n\n## \n\n TaskManager`agents/s07_task_system.py` 46-123:\n\n```python\nclass TaskManager:\n    def __init__(self, tasks_dir: Path):\n        self.dir = tasks_dir\n        self.dir.mkdir(exist_ok=True)\n        self._next_id = self._max_id() + 1\n\n    def _load(self, task_id: int) -> dict:\n        path = self.dir / f\"task_{task_id}.json\"\n        return json.loads(path.read_text())\n\n    def _save(self, task: dict):\n        path = self.dir / f\"task_{task['id']}.json\"\n        path.write_text(json.dumps(task, indent=2))\n\n    def create(self, subject, description=\"\"):\n        task = {\"id\": self._next_id, \"subject\": subject,\n                \"status\": \"pending\", \"blockedBy\": [],\n                \"blocks\": [], \"owner\": \"\"}\n        self._save(task)\n        self._next_id += 1\n        return json.dumps(task, indent=2)\n\n    def _clear_dependency(self, completed_id):\n        for f in self.dir.glob(\"task_*.json\"):\n            task = json.loads(f.read_text())\n            if completed_id in task.get(\"blockedBy\", []):\n                task[\"blockedBy\"].remove(completed_id)\n                self._save(task)\n```\n\n## s06 \n\n|  | Before (s06) | After (s07) |\n|---|---|---|\n| Tools | 5 | 8 (`task_create/update/list/get`) |\n|  |  | `.tasks/`  JSON |\n|  |  | `blockedBy + blocks`  |\n|  | compact  | compact  |\n\n## \n\n compaction \n\n task JSON `status/blockedBy` \n\ns07  Task \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s07_task_system.py\n```\n\n:\n\n1. `Create 3 tasks: \"Setup project\", \"Write code\", \"Write tests\". Make them depend on each other in order.`\n2. `List all tasks and show the dependency graph`\n3. `Complete task 1 and then list tasks to see task 2 unblocked`\n4. `Create a task board for refactoring: parse -> transform -> emit -> test`\n"
  },
  {
    "version": "s08",
    "locale": "ja",
    "title": "s08: Background Tasks",
    "content": "# s08: Background Tasks\n\n> BackgroundManagerLLM\n\n## \n\n: `npm install``pytest``docker build`agent loopconfigconfig -- \n\nagent loop\n\nBackgroundManagerLLM\n\n## \n\n```\nMain thread                Background thread\n+-----------------+        +-----------------+\n| agent loop      |        | task executes   |\n| ...             |        | ...             |\n| [LLM call] <---+------- | enqueue(result) |\n|  ^drain queue   |        +-----------------+\n+-----------------+\n\nTimeline:\nAgent --[spawn A]--[spawn B]--[other work]----\n             |          |\n             v          v\n          [A runs]   [B runs]      (parallel)\n             |          |\n             +-- notification queue --+\n                                      |\n                           [results injected before\n                            next LLM call]\n```\n\n## \n\n1. BackgroundManager\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n```\n\n2. `run()`task_id\n\n```python\ndef run(self, command: str) -> str:\n    task_id = str(uuid.uuid4())[:8]\n    self.tasks[task_id] = {\n        \"status\": \"running\",\n        \"result\": None,\n        \"command\": command,\n    }\n    thread = threading.Thread(\n        target=self._execute,\n        args=(task_id, command),\n        daemon=True,\n    )\n    thread.start()\n    return f\"Background task {task_id} started\"\n```\n\n3. `_execute`\n\n```python\ndef _execute(self, task_id: str, command: str):\n    try:\n        r = subprocess.run(command, shell=True, cwd=WORKDIR,\n            capture_output=True, text=True, timeout=300)\n        output = (r.stdout + r.stderr).strip()[:50000]\n        status = \"completed\"\n    except subprocess.TimeoutExpired:\n        output = \"Error: Timeout (300s)\"\n        status = \"timeout\"\n    self.tasks[task_id][\"status\"] = status\n    self.tasks[task_id][\"result\"] = output\n    with self._lock:\n        self._notification_queue.append({\n            \"task_id\": task_id,\n            \"status\": status,\n            \"result\": output[:500],\n        })\n```\n\n4. `drain_notifications()`\n\n```python\ndef drain_notifications(self) -> list:\n    with self._lock:\n        notifs = list(self._notification_queue)\n        self._notification_queue.clear()\n    return notifs\n```\n\n5. agent loopLLM\n\n```python\ndef agent_loop(messages: list):\n    while True:\n        notifs = BG.drain_notifications()\n        if notifs and messages:\n            notif_text = \"\\n\".join(\n                f\"[bg:{n['task_id']}] {n['status']}: \"\n                f\"{n['result']}\" for n in notifs\n            )\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<background-results>\"\n                           f\"\\n{notif_text}\\n\"\n                           f\"</background-results>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted background results.\"})\n        response = client.messages.create(...)\n```\n\n## \n\nBackgroundManager(`agents/s08_background_tasks.py` 49-107):\n\n```python\nclass BackgroundManager:\n    def __init__(self):\n        self.tasks = {}\n        self._notification_queue = []\n        self._lock = threading.Lock()\n\n    def run(self, command: str) -> str:\n        task_id = str(uuid.uuid4())[:8]\n        self.tasks[task_id] = {\"status\": \"running\",\n                               \"result\": None,\n                               \"command\": command}\n        thread = threading.Thread(\n            target=self._execute,\n            args=(task_id, command), daemon=True)\n        thread.start()\n        return f\"Background task {task_id} started\"\n\n    def _execute(self, task_id, command):\n        # run subprocess, push to queue\n        ...\n\n    def drain_notifications(self) -> list:\n        with self._lock:\n            notifs = list(self._notification_queue)\n            self._notification_queue.clear()\n        return notifs\n```\n\n## s07\n\n| Component      | Before (s07)     | After (s08)                |\n|----------------|------------------|----------------------------|\n| Tools          | 8                | 6 (base + background_run + check)|\n| Execution      | Blocking only    | Blocking + background threads|\n| Notification   | None             | Queue drained per loop     |\n| Concurrency    | None             | Daemon threads             |\n\n## \n\n(1LLM)I/O()(LLM): I/O\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s08_background_tasks.py\n```\n\n:\n\n1. `Run \"sleep 5 && echo done\" in the background, then create a file while it runs`\n2. `Start 3 background tasks: \"sleep 2\", \"sleep 4\", \"sleep 6\". Check their status.`\n3. `Run pytest in the background and keep working on other things`\n"
  },
  {
    "version": "s09",
    "locale": "ja",
    "title": "s09: Agent Teams",
    "content": "# s09: Agent Teams\n\n> JSONL  -- spawnmessagebroadcastdrain\n\n## \n\n(s04): (s08)LLM\n\n3: (1)(2)(3) -- \n\nTeammateManagerJSONL MessageBusagent loopLLM\n\ns06s07: s03TodoManager(s06)(s07) -- config.json\n\n## \n\n```\nTeammate lifecycle:\n  spawn -> WORKING -> IDLE -> WORKING -> ... -> SHUTDOWN\n\nCommunication:\n  .team/\n    config.json           <- team roster + statuses\n    inbox/\n      alice.jsonl         <- append-only, drain-on-read\n      bob.jsonl\n      lead.jsonl\n\n                +--------+    send(\"alice\",\"bob\",\"...\")    +--------+\n                | alice  | -----------------------------> |  bob   |\n                | loop   |    bob.jsonl << {json_line}    |  loop  |\n                +--------+                                +--------+\n                     ^                                         |\n                     |        BUS.read_inbox(\"alice\")          |\n                     +---- alice.jsonl -> read + drain ---------+\n\n5 message types:\n+-------------------------+------------------------------+\n| message                 | Normal text between agents   |\n| broadcast               | Sent to all teammates        |\n| shutdown_request        | Request graceful shutdown     |\n| shutdown_response       | Approve/reject shutdown      |\n| plan_approval_response  | Approve/reject plan          |\n+-------------------------+------------------------------+\n```\n\n## \n\n1. TeammateManagerconfig.json\n\n```python\nclass TeammateManager:\n    def __init__(self, team_dir: Path):\n        self.dir = team_dir\n        self.dir.mkdir(exist_ok=True)\n        self.config_path = self.dir / \"config.json\"\n        self.config = self._load_config()\n        self.threads = {}\n```\n\n2. `spawn()`agent loopspawn\n\n```python\ndef spawn(self, name: str, role: str, prompt: str) -> str:\n    member = self._find_member(name)\n    if member:\n        if member[\"status\"] not in (\"idle\", \"shutdown\"):\n            return f\"Error: '{name}' is currently {member['status']}\"\n        member[\"status\"] = \"working\"\n    else:\n        member = {\"name\": name, \"role\": role, \"status\": \"working\"}\n        self.config[\"members\"].append(member)\n    self._save_config()\n    thread = threading.Thread(\n        target=self._teammate_loop,\n        args=(name, role, prompt), daemon=True)\n    self.threads[name] = thread\n    thread.start()\n    return f\"Spawned teammate '{name}' (role: {role})\"\n```\n\n3. MessageBusJSONL`send()`JSON`read_inbox()`\n\n```python\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content,\n               \"timestamp\": time.time()}\n        if extra:\n            msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n        return f\"Sent {msg_type} to {to}\"\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists():\n            return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")  # drain\n        return json.dumps(msgs, indent=2)\n```\n\n4. LLM\n\n```python\ndef _teammate_loop(self, name, role, prompt):\n    sys_prompt = f\"You are '{name}', role: {role}, at {WORKDIR}.\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    for _ in range(50):\n        inbox = BUS.read_inbox(name)\n        if inbox != \"[]\":\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            messages.append({\"role\": \"assistant\",\n                \"content\": \"Noted inbox messages.\"})\n        response = client.messages.create(\n            model=MODEL, system=sys_prompt,\n            messages=messages, tools=TOOLS)\n        messages.append({\"role\": \"assistant\",\n                         \"content\": response.content})\n        if response.stop_reason != \"tool_use\":\n            break\n        # execute tools, append results...\n    self._find_member(name)[\"status\"] = \"idle\"\n    self._save_config()\n```\n\n5. `broadcast()`\n\n```python\ndef broadcast(self, sender, content, teammates):\n    count = 0\n    for name in teammates:\n        if name != sender:\n            self.send(sender, name, content, \"broadcast\")\n            count += 1\n    return f\"Broadcast to {count} teammates\"\n```\n\n## \n\nTeammateManager + MessageBus(`agents/s09_agent_teams.py`):\n\n```python\nclass TeammateManager:\n    def spawn(self, name, role, prompt):\n        member = self._find_member(name) or {\n            \"name\": name, \"role\": role, \"status\": \"working\"\n        }\n        member[\"status\"] = \"working\"\n        self._save_config()\n        thread = threading.Thread(\n            target=self._teammate_loop,\n            args=(name, role, prompt), daemon=True)\n        thread.start()\n        return f\"Spawned '{name}'\"\n\nclass MessageBus:\n    def send(self, sender, to, content,\n             msg_type=\"message\", extra=None):\n        msg = {\"type\": msg_type, \"from\": sender,\n               \"content\": content, \"timestamp\": time.time()}\n        if extra: msg.update(extra)\n        with open(self.dir / f\"{to}.jsonl\", \"a\") as f:\n            f.write(json.dumps(msg) + \"\\n\")\n\n    def read_inbox(self, name):\n        path = self.dir / f\"{name}.jsonl\"\n        if not path.exists(): return \"[]\"\n        msgs = [json.loads(l)\n                for l in path.read_text().strip().splitlines()\n                if l]\n        path.write_text(\"\")\n        return json.dumps(msgs, indent=2)\n```\n\n## s08\n\n| Component      | Before (s08)     | After (s09)                |\n|----------------|------------------|----------------------------|\n| Tools          | 6                | 9 (+spawn/send/read_inbox) |\n| Agents         | Single           | Lead + N teammates         |\n| Persistence    | None             | config.json + JSONL inboxes|\n| Threads        | Background cmds  | Full agent loops per thread|\n| Lifecycle      | Fire-and-forget  | idle -> working -> idle    |\n| Communication  | None             | 5 message types + broadcast|\n\n: /\n\n## \n\n( JSONL)() LLM \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s09_agent_teams.py\n```\n\n:\n\n1. `Spawn alice (coder) and bob (tester). Have alice send bob a message.`\n2. `Broadcast \"status update: phase 1 complete\" to all teammates`\n3. `Check the lead inbox for any messages`\n4. `/team`\n5. `/inbox`\n"
  },
  {
    "version": "s10",
    "locale": "ja",
    "title": "s10: Team Protocols",
    "content": "# s10: Team Protocols\n\n> request_id -- 1FSM2\n\n## \n\ns092:\n\n****: config.json: ()()\n\n****: \n\n: IDIDpending -> approved | rejected\n\n## \n\n```\nShutdown Protocol            Plan Approval Protocol\n==================           ======================\n\nLead             Teammate    Teammate           Lead\n  |                 |           |                 |\n  |--shutdown_req-->|           |--plan_req------>|\n  | {req_id:\"abc\"}  |           | {req_id:\"xyz\"}  |\n  |                 |           |                 |\n  |<--shutdown_resp-|           |<--plan_resp-----|\n  | {req_id:\"abc\",  |           | {req_id:\"xyz\",  |\n  |  approve:true}  |           |  approve:true}  |\n  |                 |           |                 |\n  v                 v           v                 v\ntracker[\"abc\"]     exits     proceeds          tracker[\"xyz\"]\n = approved                                     = approved\n\nShared FSM (identical for both protocols):\n  [pending] --approve--> [approved]\n  [pending] --reject---> [rejected]\n\nTrackers:\n  shutdown_requests = {req_id: {target, status}}\n  plan_requests     = {req_id: {from, plan, status}}\n```\n\n## \n\n1. request_idshutdown_request\n\n```python\nshutdown_requests = {}\n\ndef handle_shutdown_request(teammate: str) -> str:\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\",\n    }\n    BUS.send(\"lead\", teammate, \"Please shut down gracefully.\",\n             \"shutdown_request\", {\"request_id\": req_id})\n    return f\"Shutdown request {req_id} sent (status: pending)\"\n```\n\n2. `shutdown_response`\n\n```python\nif tool_name == \"shutdown_response\":\n    req_id = args[\"request_id\"]\n    approve = args[\"approve\"]\n    if req_id in shutdown_requests:\n        shutdown_requests[req_id][\"status\"] = \\\n            \"approved\" if approve else \"rejected\"\n    BUS.send(sender, \"lead\", args.get(\"reason\", \"\"),\n             \"shutdown_response\",\n             {\"request_id\": req_id, \"approve\": approve})\n    return f\"Shutdown {'approved' if approve else 'rejected'}\"\n```\n\n3. \n\n```python\nif (block.name == \"shutdown_response\"\n        and block.input.get(\"approve\")):\n    should_exit = True\n# ...\nmember[\"status\"] = \"shutdown\" if should_exit else \"idle\"\n```\n\n4. request_id\n\n```python\nplan_requests = {}\n\nif tool_name == \"plan_approval\":\n    plan_text = args.get(\"plan\", \"\")\n    req_id = str(uuid.uuid4())[:8]\n    plan_requests[req_id] = {\n        \"from\": sender, \"plan\": plan_text,\n        \"status\": \"pending\",\n    }\n    BUS.send(sender, \"lead\", plan_text,\n             \"plan_approval_request\",\n             {\"request_id\": req_id, \"plan\": plan_text})\n    return f\"Plan submitted (request_id={req_id})\"\n```\n\n5. request_id\n\n```python\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests.get(request_id)\n    if not req:\n        return f\"Error: Unknown request_id '{request_id}'\"\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve,\n              \"feedback\": feedback})\n    return f\"Plan {req['status']} for '{req['from']}'\"\n```\n\n6. `plan_approval`2: (request_id)(request_id)\n\n```python\n# Lead tool dispatch:\n\"plan_approval\": lambda **kw: handle_plan_review(\n    kw[\"request_id\"], kw[\"approve\"],\n    kw.get(\"feedback\", \"\")),\n# Teammate: submit mode (generate request_id)\n```\n\n## \n\n2(`agents/s10_team_protocols.py`):\n\n```python\nshutdown_requests = {}\nplan_requests = {}\n\n# -- Shutdown --\ndef handle_shutdown_request(teammate):\n    req_id = str(uuid.uuid4())[:8]\n    shutdown_requests[req_id] = {\n        \"target\": teammate, \"status\": \"pending\"\n    }\n    BUS.send(\"lead\", teammate,\n             \"Please shut down gracefully.\",\n             \"shutdown_request\",\n             {\"request_id\": req_id})\n\n# -- Plan Approval --\ndef handle_plan_review(request_id, approve, feedback=\"\"):\n    req = plan_requests[request_id]\n    req[\"status\"] = \"approved\" if approve else \"rejected\"\n    BUS.send(\"lead\", req[\"from\"], feedback,\n             \"plan_approval_response\",\n             {\"request_id\": request_id,\n              \"approve\": approve})\n\n# Both use the same FSM:\n# pending -> approved | rejected\n# Both correlate by request_id across async inboxes\n```\n\n## s09\n\n| Component      | Before (s09)     | After (s10)                  |\n|----------------|------------------|------------------------------|\n| Tools          | 9                | 12 (+shutdown_req/resp +plan)|\n| Shutdown       | Natural exit only| Request-response handshake   |\n| Plan gating    | None             | Submit/review with approval  |\n| Request tracking| None            | Two tracker dicts            |\n| Correlation    | None             | request_id per request       |\n| FSM            | None             | pending -> approved/rejected |\n\n## \n\nrequest_id3(pending -> approved/rejected)1 -- FSMrequest_id\n\n## \n\n```sh\ncd learn-claude-code\npython agents/s10_team_protocols.py\n```\n\n:\n\n1. `Spawn alice as a coder. Then request her shutdown.`\n2. `List teammates to see alice's status after shutdown approval`\n3. `Spawn bob with a risky refactoring task. Review and reject his plan.`\n4. `Spawn charlie, have him submit a plan, then approve it.`\n5. `/team`\n"
  },
  {
    "version": "s11",
    "locale": "ja",
    "title": "s11: Autonomous Agents",
    "content": "# s11: Autonomous Agents\n\n> \n\n## \n\ns09-s10spawn10\n\n -- \n\n: (alicecoder)\n\n: /4nag  3 \n\n## \n\n```\nTeammate lifecycle with idle cycle:\n\n+-------+\n| spawn |\n+---+---+\n    |\n    v\n+-------+   tool_use     +-------+\n| WORK  | <------------- |  LLM  |\n+---+---+                +-------+\n    |\n    | stop_reason != tool_use\n    | (or idle tool called)\n    v\n+--------+\n|  IDLE  |  poll every 5s for up to 60s\n+---+----+\n    |\n    +---> check inbox --> message? ----------> WORK\n    |\n    +---> scan .tasks/ --> unclaimed? -------> claim -> WORK\n    |\n    +---> 60s timeout ----------------------> SHUTDOWN\n\nIdentity re-injection after compression:\n  if len(messages) <= 3:\n    messages.insert(0, identity_block)\n    \"You are 'alice', role: coder, team: my-team\"\n```\n\n## \n\n1. WORKIDLE2WORKagent loopLLM(`idle`)IDLE\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # -- WORK PHASE --\n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        for _ in range(50):\n            inbox = BUS.read_inbox(name)\n            for msg in inbox:\n                if msg.get(\"type\") == \"shutdown_request\":\n                    self._set_status(name, \"shutdown\")\n                    return\n                messages.append(...)\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            # execute tools...\n            if idle_requested:\n                break\n\n        # -- IDLE PHASE --\n        self._set_status(name, \"idle\")\n        resume = self._idle_poll(name, messages)\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n2. IDLE\n\n```python\ndef _idle_poll(self, name, messages):\n    polls = IDLE_TIMEOUT // POLL_INTERVAL  # 60s / 5s = 12\n    for _ in range(polls):\n        time.sleep(POLL_INTERVAL)\n        # Check inbox for new messages\n        inbox = BUS.read_inbox(name)\n        if inbox:\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<inbox>{inbox}</inbox>\"})\n            return True\n        # Scan task board for unclaimed tasks\n        unclaimed = scan_unclaimed_tasks()\n        if unclaimed:\n            task = unclaimed[0]\n            claim_task(task[\"id\"], name)\n            messages.append({\"role\": \"user\",\n                \"content\": f\"<auto-claimed>Task #{task['id']}: \"\n                           f\"{task['subject']}</auto-claimed>\"})\n            return True\n    return False  # timeout -> shutdown\n```\n\n3. pending\n\n```python\ndef scan_unclaimed_tasks() -> list:\n    TASKS_DIR.mkdir(exist_ok=True)\n    unclaimed = []\n    for f in sorted(TASKS_DIR.glob(\"task_*.json\")):\n        task = json.loads(f.read_text())\n        if (task.get(\"status\") == \"pending\"\n                and not task.get(\"owner\")\n                and not task.get(\"blockedBy\")):\n            unclaimed.append(task)\n    return unclaimed\n\ndef claim_task(task_id: int, owner: str):\n    path = TASKS_DIR / f\"task_{task_id}.json\"\n    task = json.loads(path.read_text())\n    task[\"status\"] = \"in_progress\"\n    task[\"owner\"] = owner\n    path.write_text(json.dumps(task, indent=2))\n```\n\n4. ()\n\n```python\ndef make_identity_block(name, role, team_name):\n    return {\"role\": \"user\",\n            \"content\": f\"<identity>You are '{name}', \"\n                       f\"role: {role}, team: {team_name}. \"\n                       f\"Continue your work.</identity>\"}\n\n# Before resuming work after idle:\nif len(messages) <= 3:\n    messages.insert(0, make_identity_block(\n        name, role, team_name))\n    messages.insert(1, {\"role\": \"assistant\",\n        \"content\": f\"I am {name}. Continuing.\"})\n```\n\n5. `idle`\n\n```python\n{\"name\": \"idle\",\n \"description\": \"Signal that you have no more work. \"\n                \"Enters idle polling phase.\",\n \"input_schema\": {\"type\": \"object\", \"properties\": {}}},\n```\n\n## \n\n(`agents/s11_autonomous_agents.py`):\n\n```python\ndef _loop(self, name, role, prompt):\n    while True:\n        # WORK PHASE\n        for _ in range(50):\n            response = client.messages.create(...)\n            if response.stop_reason != \"tool_use\":\n                break\n            for block in response.content:\n                if block.name == \"idle\":\n                    idle_requested = True\n            if idle_requested:\n                break\n\n        # IDLE PHASE\n        self._set_status(name, \"idle\")\n        for _ in range(IDLE_TIMEOUT // POLL_INTERVAL):\n            time.sleep(POLL_INTERVAL)\n            inbox = BUS.read_inbox(name)\n            if inbox: resume = True; break\n            unclaimed = scan_unclaimed_tasks()\n            if unclaimed:\n                claim_task(unclaimed[0][\"id\"], name)\n                resume = True; break\n        if not resume:\n            self._set_status(name, \"shutdown\")\n            return\n        self._set_status(name, \"working\")\n```\n\n## s10\n\n| Component      | Before (s10)     | After (s11)                |\n|----------------|------------------|----------------------------|\n| Tools          | 12               | 14 (+idle, +claim_task)    |\n| Autonomy       | Lead-directed    | Self-organizing            |\n| Idle phase     | None             | Poll inbox + task board    |\n| Task claiming  | Manual only      | Auto-claim unclaimed tasks |\n| Identity       | System prompt    | + re-injection after compress|\n| Timeout        | None             | 60s idle -> auto shutdown  |\n\n## \n\n +  -- \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s11_autonomous_agents.py\n```\n\n:\n\n1. `Create 3 tasks on the board, then spawn alice and bob. Watch them auto-claim.`\n2. `Spawn a coder teammate and let it find work from the task board itself`\n3. `Create tasks with dependencies. Watch teammates respect the blocked order.`\n4. `/tasks`\n5. `/team`\n"
  },
  {
    "version": "s12",
    "locale": "ja",
    "title": "s12: Worktree + Task Isolation",
    "content": "# s12: Worktree + Task Isolation\n\n> ID -- () worktree()\n\n## \n\ns11 3\n\n `src/auth.py` `git diff` 2\n\n1. : \n2. : \n3. : \n\n\n\n## \n\n```\nControl Plane (.tasks/)          Execution Plane (.worktrees/)\n+---------------------+         +------------------------+\n| task_1.json         |         | auth-refactor/         |\n|   status: in_progress|  bind  |   branch: wt/auth-ref  |\n|   worktree: auth-ref|-------->|   cwd for commands     |\n+---------------------+         +------------------------+\n| task_2.json         |         | ui-login/              |\n|   status: pending   |  bind   |   branch: wt/ui-login  |\n|   worktree: ui-login|-------->|   cwd for commands     |\n+---------------------+         +------------------------+\n        |                                |\n        v                                v\n  \"what to do\"                   \"where to execute\"\n\nEvents (.worktrees/events.jsonl)\n  worktree.create.before -> worktree.create.after\n  worktree.remove.before -> worktree.remove.after\n  task.completed\n```\n\n## \n\n1. 3 worktree 1\n\n```text\n    (.tasks/task_*.json)        -> id/subject/status/owner/worktree\n    (.worktrees/index.json)     -> name/path/branch/task_id/status\n ()                    -> current_task/current_worktree/error\n```\n\n2. Task  worktree \n\n```text\nTask:     pending -> in_progress -> completed\nWorktree: absent  -> active      -> removed | kept\n```\n\n3. `task_create` worktree \n\n```python\ntask = {\n    \"id\": self._next_id,\n    \"subject\": subject,\n    \"status\": \"pending\",\n    \"owner\": \"\",\n    \"worktree\": \"\",\n    \"created_at\": time.time(),\n    \"updated_at\": time.time(),\n}\nself._save(task)\n```\n\n4. `worktree_create(name, task_id?)` `task_id`  `pending`  `in_progress` \n\n```python\nentry = {\n    \"name\": name,\n    \"path\": str(path),\n    \"branch\": branch,\n    \"task_id\": task_id,\n    \"status\": \"active\",\n    \"created_at\": time.time(),\n}\nidx[\"worktrees\"].append(entry)\nself._save_index(idx)\n\nif task_id is not None:\n    self.tasks.bind_worktree(task_id, name)\n```\n\n5. `worktree_run(name, command)` `cwd=worktree_path` enter\n\n```python\nr = subprocess.run(\n    command,\n    shell=True,\n    cwd=path,\n    capture_output=True,\n    text=True,\n    timeout=300,\n)\n```\n\n6.  `keep`  `remove` `worktree_remove(name, complete_task=true)` \n\n```python\ndef remove(self, name: str, force: bool = False, complete_task: bool = False) -> str:\n    self._run_git([\"worktree\", \"remove\", wt[\"path\"]])\n    if complete_task and wt.get(\"task_id\") is not None:\n        self.tasks.update(wt[\"task_id\"], status=\"completed\")\n        self.tasks.unbind_worktree(wt[\"task_id\"])\n        self.events.emit(\"task.completed\", ...)\n```\n\n7. `.worktrees/events.jsonl`  append-only  `before / after / failed` \n\n```json\n{\n  \"event\": \"worktree.remove.after\",\n  \"task\": {\"id\": 7, \"status\": \"completed\"},\n  \"worktree\": {\"name\": \"auth-refactor\", \"path\": \"...\", \"status\": \"removed\"},\n  \"ts\": 1730000000\n}\n```\n\ntask/worktree \n\n## \n\n worktree (`agents/s12_worktree_task_isolation.py` 182-191):\n\n```python\ndef bind_worktree(self, task_id: int, worktree: str, owner: str = \"\") -> str:\n    task = self._load(task_id)\n    task[\"worktree\"] = worktree\n    if owner:\n        task[\"owner\"] = owner\n    if task[\"status\"] == \"pending\":\n        task[\"status\"] = \"in_progress\"\n    task[\"updated_at\"] = time.time()\n    self._save(task)\n    return json.dumps(task, indent=2)\n```\n\nWorktree (`agents/s12_worktree_task_isolation.py` 283-334):\n\n```python\ndef create(self, name: str, task_id: int = None, base_ref: str = \"HEAD\") -> str:\n    self._validate_name(name)\n    if self._find(name):\n        raise ValueError(f\"Worktree '{name}' already exists in index\")\n\n    path = self.dir / name\n    branch = f\"wt/{name}\"\n    self.events.emit(\"worktree.create.before\",\n        task={\"id\": task_id} if task_id is not None else {},\n        worktree={\"name\": name, \"base_ref\": base_ref})\n    try:\n        self._run_git([\"worktree\", \"add\", \"-b\", branch, str(path), base_ref])\n        entry = {\n            \"name\": name, \"path\": str(path), \"branch\": branch,\n            \"task_id\": task_id, \"status\": \"active\",\n            \"created_at\": time.time(),\n        }\n        idx = self._load_index()\n        idx[\"worktrees\"].append(entry)\n        self._save_index(idx)\n        if task_id is not None:\n            self.tasks.bind_worktree(task_id, name)\n        self.events.emit(\"worktree.create.after\", ...)\n        return json.dumps(entry, indent=2)\n    except Exception as e:\n        self.events.emit(\"worktree.create.failed\", ..., error=str(e))\n        raise\n```\n\n(`agents/s12_worktree_task_isolation.py` 535-552):\n\n```python\nTOOL_HANDLERS = {\n    \"bash\": lambda **kw: run_bash(kw[\"command\"]),\n    \"read_file\": lambda **kw: run_read(kw[\"path\"], kw.get(\"limit\")),\n    \"write_file\": lambda **kw: run_write(kw[\"path\"], kw[\"content\"]),\n    \"edit_file\": lambda **kw: run_edit(kw[\"path\"], kw[\"old_text\"], kw[\"new_text\"]),\n    \"task_create\": lambda **kw: TASKS.create(kw[\"subject\"], kw.get(\"description\", \"\")),\n    \"task_list\": lambda **kw: TASKS.list_all(),\n    \"task_get\": lambda **kw: TASKS.get(kw[\"task_id\"]),\n    \"task_update\": lambda **kw: TASKS.update(kw[\"task_id\"], kw.get(\"status\"), kw.get(\"owner\")),\n    \"task_bind_worktree\": lambda **kw: TASKS.bind_worktree(kw[\"task_id\"], kw[\"worktree\"], kw.get(\"owner\", \"\")),\n    \"worktree_create\": lambda **kw: WORKTREES.create(kw[\"name\"], kw.get(\"task_id\"), kw.get(\"base_ref\", \"HEAD\")),\n    \"worktree_list\": lambda **kw: WORKTREES.list_all(),\n    \"worktree_status\": lambda **kw: WORKTREES.status(kw[\"name\"]),\n    \"worktree_run\": lambda **kw: WORKTREES.run(kw[\"name\"], kw[\"command\"]),\n    \"worktree_keep\": lambda **kw: WORKTREES.keep(kw[\"name\"]),\n    \"worktree_remove\": lambda **kw: WORKTREES.remove(kw[\"name\"], kw.get(\"force\", False), kw.get(\"complete_task\", False)),\n    \"worktree_events\": lambda **kw: EVENTS.list_recent(kw.get(\"limit\", 20)),\n}\n```\n\n## s11 \n\n|  | s11 | s12 |\n|---|---|---|\n|  | Task board (`owner/status`) | Task board + `worktree`  |\n|  |  |  |\n|  |  |  + worktree index |\n|  |  |  +  keep/remove  |\n|  |  | `.worktrees/events.jsonl`  |\n\n## \n\nworktree `worktree_keep` / `worktree_remove`  `before / after / failed`  `.tasks/` + `.worktrees/index.json` \n\n## \n\n```sh\ncd learn-claude-code\npython agents/s12_worktree_task_isolation.py\n```\n\n:\n\n1. `Create tasks for backend auth and frontend login page, then list tasks.`\n2. `Create worktree \"auth-refactor\" for task 1, create worktree \"ui-login\", then bind task 2 to \"ui-login\".`\n3. `Run \"git status --short\" in worktree \"auth-refactor\".`\n4. `Keep worktree \"ui-login\", then list worktrees and inspect worktree events.`\n5. `Remove worktree \"auth-refactor\" with complete_task=true, then list tasks/worktrees/events.`\n"
  }
]